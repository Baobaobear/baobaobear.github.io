[{"authors":["admin"],"categories":null,"content":"一个喜欢折腾和研究算法的大学生\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"一个喜欢折腾和研究算法的大学生","tags":null,"title":"抱抱熊","type":"authors"},{"authors":null,"categories":["研究"],"content":"这次主要介绍伪随机数生成算法，顺便介绍一个在2018-2019年的伪随机数研究成果，就是 xoshiro/xoroshiro 随机数生成算法。\n历史 在较早的时候，甚至到现在，伪随机数的生成元老级别算法“线性同余伪随机数生成算法”可谓无处不在，像现在的C/C++的rand函数就是使用线性同余实现的伪随机数生成。所谓的线性同余法，就是这个迭代方程 $S_n = (aS_{n-1} + c)\\mod m$，其中，$S_0$ 称为这个随机序列的种子，a,c,m是三个常数，不过这三个数不能随意选，m的大小决定随机数的周期，最大周期等于m，为了便于在计算机里实现，通常m选取$2^{32}$或$2^{64}$。在m已经确定为这两的时候，为了让周期尽可能大，常数a,c还至少要满足以下条件：\n 若 c 非 0，那么 c 与 m 互质；若 c 为 0，那么 a 与 m 互质 m 所有的素因子均能整除 a-1 若 m 是4的倍数，那么 a-1 也是 4 的倍数 a 和 c 都是正整数且小于 m  一些典型的常数取值可以参见wiki上的线性同余条目。\n更高的需求 我们之所以使用线性同余，就是因为它实现简单，在对随机数质量要求较低的时候，例如用来作为treap的随机数，那么线性同余完全够用，但建议不要使用rand，因为在windows下不少编译器的最大值太小了，导致效果下降，自己写一个用参数a=69069,c=1,m=2^32比rand好，我在那篇关于treap的文章就是用了这组参数。线性同余法最大的缺陷是低位随机性特别差，如果使用类似next() % k的方式来获得区间在$[0,k-1]$的随机数，那么当线性同余迭代方程的m是2的幂且k也是2的幂的时候，灾难就发生了，特别地当k是2的时候，你将得到一个0101的循环序列。为了避免这种情况，通常会取线性同余结果的高位，而且低位去掉得越多，%2的周期就越长。例如结果是64位，取高32位作为最终结果，那么%2的周期就是 $2^{33}$ ，但这样会导致有效位减少，而且问题也没有根本地解决。另一种解决办法是选取一个素数作为m，例如2147483647正是一个素数，但如此一来，线性同余的计算速度就会慢不少，周期也没有前一个的长。两种基本实现如下：\nstruct LCG32 : public RNG_base\u0026lt;uint32_t\u0026gt; { uint32_t s; static inline uint16_t rotl(const uint16_t x, int k) { return (x \u0026lt;\u0026lt; k) | (x \u0026gt;\u0026gt; (16 - k)); } LCG32() { seed(); } LCG32(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { s = seed1; } result_type operator()() { s = s * 214013UL + 2531011UL; return s; } }; struct MCG : public RNG_base\u0026lt;uint32_t, 0x7FFFFFFEULL\u0026gt; { uint64_t s; MCG() { seed(); } MCG(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { s = seed1; } result_type operator()() { s = s * 48271 % 0x7FFFFFFF; return (result_type)s; } };  其中基类RNG_base的定义在下文代码中有。第一个是32位的实现，所以叫做LCG32，如果是64位里面取高32位，那么就叫做LCG64/32。第二个实现没有加法操作，即c=0，这种特例叫做MCG。\n随机数的质量和周期 如果对生成的随机数质量要求高，例如写一个扑克游戏，如果是52张牌，所有的排列就是 $52!$ （约为$2^{225.5}$），那么我们需要周期比排列数多得多的随机数生成算法以期望所有可能的排列都有机会出现，那到底需要多大呢？这里我们假设平均每16位生成一个8位有效的随机数，我们需要d个随机数得到的排列，即16d个位的所有可能性，都要有可能出现，若满周期的随机数生成器的周期是 $2^{n}$，输出长度为m位，那么我们只要知道$n/m$个输出就能唯一确定生成器的状态，同时这$n/m$个输出的所有可能都会一一出现，即长度为$n$的二进制必定在序列中出现。所以在这种情况下只要$n\\geq16d$就能保证所需排列必定会出现。而在前面提到的扑克游戏里，d=52，那么需要的最小周期就是$2^{832}$，总之，只要生成器的周期的$2^{n}$中的n，比你需要生成的排列所需要的二进制流长度要大，那就保证能得到任意一个排列。这时候就最佳选择之一就是梅森旋转，在C++11里的随机数实现默认就是使用它，而且我们一般特指MT19937，即它的周期是 $2^{19937}-1$，如果输出为64位，那么任意长度小于19904位的数据都会在其生成序列中出现（之所以不是19937只是因为它不是输出长度的整数倍），但你要是用这个算法大量生成随机数那是会稍慢一些的，而且这个算法也并没有通过BigCrush的所有测试。我们还存在一种情况，就是需要大量生成随机数，同时质量也有一定要求，速度如果比线性同余还快就更好。\n线性同余的改进 输出质量 线性同余法的均匀性非常好，算法也简单，可惜分布性差，有多差呢，咱们用LCG16(0x43FD,0x9EC3)的输出画黑底白点图，相邻两次输出的高9位作为左半图的坐标，低9位作为右半图的坐标，连续采样524288个点，同一坐标出现次数越多亮度越高，于是得到下图\n左边与右边的都有明显的斜线模式。与以下专业的PCG32生成器做个比较，关注点是亮度比较平均，基本没有特别亮的点，也没有比较多暗点。\n于是也就有不少人想方设法去改进。首先的改进，便是前面所提及的截取高位作为输出，那么内部数据为64位，输出是32位的，就叫做LCG64/32，同理内部数据为32位，输出是16位的，就叫做LCG32/16，这样一来，随机数质量大幅度提升。基于此实现的版本如下：\nstruct LCG32_16 : public RNG_base\u0026lt;uint16_t\u0026gt; { uint32_t s; LCG32_16() { seed(); } LCG32_16(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { s = seed1; for (int i = 0; i \u0026lt; init_iter; ++i) (*this)(); } result_type operator()() { s = s * 214013UL + 2531011UL; return s \u0026gt;\u0026gt; 16; } };  这个代码得到的图形如下\n这样生成的随机数质量就有了一个很大的飞跃。另外，LCG结果的低位，周期性特别短，而LCG结果的高位，对下一个数的影响又特别小，那能不能对这个特性加以利用呢？既然高位对下一个数的影响特别小，我们就创造影响，让高位单独参与计算；既然低位的结果差，那就直接舍弃，同时当高位作为下一个数的位旋转参数，这样避免了最低位的固定 $2^{16}$ 周期的问题。所以可以改写如下：\nstruct LCG32_16ro : public RNG_base\u0026lt;uint16_t\u0026gt; { uint32_t s; LCG32_16ro() { seed(); } LCG32_16ro(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { s = seed1; for (int i = 0; i \u0026lt; init_iter; ++i) (*this)(); } result_type operator()() { uint32_t x = s; s = s * 214013UL + 2531011UL; return rotl16((uint16_t)(x \u0026gt;\u0026gt; 16u), x \u0026gt;\u0026gt; 28u); } };  结果反而明显变差了，原因是作为参数的高4位也是输出的一部分，导致那高4位在最终出现的位置是固定的16种情况，解决方法1是不取那4位，取4到11位，方法2是把高16位与低16位做异或运算后再做旋转，两种方案均可解决这个问题，后面的测试使用的是第二种方案，具体代码就不重复了。\n输出周期 然后再来看周期，单独一个LCG周期只有 $2^{32}$ 或 $2^{64}$ ，那我们有没有可能通过两个或以上的随机数生成器构造出周期是它们周期之积的的生成器呢？也许一时半会不容易想出来，我们先考虑怎么让一个LCG生成器周期变长。\n要注意的是我们不能瞎改，必须是一个满周期的生成器，乱改的话在绝大多数情况下都达不到满周期从而导致返回值的分布不均匀。假如我们手上有一个LCG，周期是p，如果单纯只要周期变长，那我们有一个足够简单的方法，我们增加一个参数x，在原本的LCG输出的结果基础上 xor x 再输出，然后当原来的LCG生成了p次，就让参数x自增1，于是又能生成p个整体与原来不重叠的数，如此循环，于是x的自增周期是p2的话，总周期便是 $p\\times{p_2}$ 。可是这明显能感觉到质量可能很糟糕，那解决办法就是，那个x改成另一个LCG来生成即可。这样我们便得到把两个LCG合并得到更大周期的办法。不过，问题是我们为了记录生成次数，似乎还要多定义一个变量来记录生成的次数，这个变量是会影响生成器的状态的，为了避免增加新的变量，在这里我们换个办法，不必生成p次，只要生成结果是某个设定值例如0，就更新第二个LCG，这样就节省了一个变量，于是可以写出以下的代码，为了方便说明，使用的是LCG16，周期是65536。\nstruct LCG16_1 : public RNG_base\u0026lt;uint16_t\u0026gt; { uint16_t s, a; LCG16_1() { seed(); } LCG16_1(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { s = (uint16_t)seed1; a = (uint16_t)(seed1 \u0026gt;\u0026gt; 16); } result_type operator()() { if (s == 0) a = a * (uint16_t)0x101 + (uint16_t)0x9527; s = s * (uint16_t)0x43FD + (uint16_t)0x9EC3; return a ^ s; } };  这样把两个 $2^{16}$ 周期的LCG组合起来，确实得到了 $2^{32}$ 周期的LCG，不过之所以用周期这么小的，是为了能发现问题，我们能穷举这个LCG的生成序列，我们能轻易找出多处大段大段的随机数完全相同，有多大段呢，1千到3万个不等，即之前生成的数千个随机数，后面某处又重现了这个序列，而且在 $2^{32}$ 周期内发生。这说明单纯这样组合，结果是糟糕的。具体图形如下：\n所以我们加上前面的位旋转，以期望减少这种情况的出现：\nstruct LCG16_2 : public RNG_base\u0026lt;uint16_t\u0026gt; { uint16_t s, a; LCG16_2() { seed(); } LCG16_2(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { s = (uint16_t)seed1; a = (uint16_t)(seed1 \u0026gt;\u0026gt; 16); } result_type operator()() { uint16_t x = s; if (s == 0) a = a * (uint16_t)0x101 + (uint16_t)0x9527; s = s * (uint16_t)0x43FD + (uint16_t)0x9EC3; return a ^ rotl16(x, x \u0026gt;\u0026gt; 12); } };  出现这个情况的原因前面有解释，正是高4位导致的。对此，为了把高4位的模式抹除，改为rotl16(x ^ (x \u0026lt;\u0026lt; k), x \u0026gt;\u0026gt; 12)，只要k大于等于4，这个模式就迅速消失。取k为7得到代码：\nstruct LCG16_3 : public RNG_base\u0026lt;uint16_t\u0026gt; { uint16_t s, a; LCG16_3() { seed(); } LCG16_3(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { s = (uint16_t)seed1; a = (uint16_t)(seed1 \u0026gt;\u0026gt; 16); } result_type operator()() { uint16_t x = s; if (s == 0) a = a * (uint16_t)0x101 + (uint16_t)0x9527; s = s * (uint16_t)0x43FD + (uint16_t)0x9EC3; return a ^ rotl16(x ^ (x \u0026lt;\u0026lt; 7), x \u0026gt;\u0026gt; 12); } };  我们还可以再考虑一个问题，之前都是用高位的旋转参数对自己旋转，那可不可以错开，改为旋转下一个数呢？答案是可以的，生成的结果仍然是满周期的，也不存在高4位位置固定的问题，得到的代码和图形是\nstruct LCG16_4 : public RNG_base\u0026lt;uint16_t\u0026gt; { uint16_t s, a; LCG16_4() { seed(); } LCG16_4(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { s = (uint16_t)seed1; a = (uint16_t)(seed1 \u0026gt;\u0026gt; 16); } result_type operator()() { uint16_t x = s; if (s == 0) a = a * (uint16_t)0x101 + (uint16_t)0x9527; s = s * (uint16_t)0x43FD + (uint16_t)0x9EC3; return a ^ rotl16(s, x \u0026gt;\u0026gt; 12); } };  于是我们确实得到了一个看起来更随机的生成器，但3和4的图仔细观察仍然能发现左边的图有规律的线条模式，和专业算法比较还是能看出差距，不过这个问题之后再去解决。那如果我们需要任意加大周期要怎么做呢，如果单纯按这个思路，那么增加了n级，就会导致输出要异或n次，代码也难写。这里要换一个思路，我们把扩展状态做成一个数组，每次只与数组中其中一个元素来异或运算，而选择的方法利用LCG的低位是循环的特性，具体代码如下：\ntemplate \u0026lt;uint16_t ext_bit = 2\u0026gt; struct LCG16s : public RNG_base\u0026lt;uint16_t\u0026gt; { static const uint16_t ext_size = 1 \u0026lt;\u0026lt; ext_bit, ext_mask = ext_size - 1; uint16_t s, a[ext_size]; LCG16s() { seed(); } LCG16s(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { s = (uint16_t)seed1; a[0] = (uint16_t)(seed1 \u0026gt;\u0026gt; 16); if (ext_size \u0026gt; 1) a[1] = (uint16_t)(seed1 \u0026gt;\u0026gt; 32); if (ext_size \u0026gt; 2) a[2] = (uint16_t)(seed1 \u0026gt;\u0026gt; 48); for (uint16_t i = 3; i \u0026lt; ext_size; ++i) { a[i] = rotl16(a[i - 1] * (uint16_t)0x43FD + (uint16_t)0x9EC3, a[i-3] \u0026amp; 15) ^ a[i - 2]; } } result_type operator()() { uint16_t x = s; if (s == 0) { for (uint16_t i = 0; i \u0026lt; ext_size; ++i) { a[i] = (a[i] * (uint16_t)0x101 + (uint16_t)0x9527); if (a[i]) break; } } s = s * (uint16_t)0x43FD + (uint16_t)0x9EC3; return rotl16(s, x \u0026gt;\u0026gt; 12) ^ a[x \u0026amp; ext_mask]; } };  从图上就能直观看出这东西有问题，问题在哪呢？以上这个生成器的周期在模板参数假设是n，那么其周期为 $ 2^{16 \\times (2^n + 1)}$，可以任意加大周期。可是就在这个时候就出现问题了，我们假设参数是8，那么数组大小为256，那当s为0的时候，大多数情况下只有a[0]发生改变，那导致的结果就是在下一个短周期里，每256个数有255个与前一个短周期完全一样，所以我们要做修改，每次s为0的时候，a数组每一个数都得至少更新一次，且如果a[i]为0，那a[i+1]就更新两遍，这样可以改写如下：\ntemplate \u0026lt;uint16_t ext_bit = 2\u0026gt; struct LCG16_ext : public RNG_base\u0026lt;uint16_t\u0026gt; { static const uint16_t ext_size = 1 \u0026lt;\u0026lt; ext_bit, ext_mask = ext_size - 1; uint16_t s, a[ext_size]; LCG16_ext() { seed(); } LCG16_ext(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { s = (uint16_t)seed1; a[0] = (uint16_t)(seed1 \u0026gt;\u0026gt; 16); if (ext_size \u0026gt; 1) a[1] = (uint16_t)(seed1 \u0026gt;\u0026gt; 32); if (ext_size \u0026gt; 2) a[2] = (uint16_t)(seed1 \u0026gt;\u0026gt; 48); for (uint16_t i = 3; i \u0026lt; ext_size; ++i) { a[i] = rotl16(a[i - 1] * (uint16_t)0x43FD + (uint16_t)0x9EC3, a[i-3] \u0026amp; 15) ^ a[i - 2]; } } result_type operator()() { uint16_t x = s; if (s == 0) { for (uint16_t i = 0, carry = 0; i \u0026lt; ext_size; ++i) { if (carry) carry = (a[i] = (a[i] * (uint16_t)0x101 + (uint16_t)0x9527)) == 0; carry |= (a[i] = (a[i] * (uint16_t)0x101 + (uint16_t)0x9527)) == 0; } } s = s * (uint16_t)0x43FD + (uint16_t)0x9EC3; return rotl16(s, x \u0026gt;\u0026gt; 12) ^ a[x \u0026amp; ext_mask]; } };  以上这个版本经过一些简单的测试，符合满周期且概率均等。当然这个uint16有点太小，于是仍然能从图里看出分布有点问题，左边的图存在明暗间隔的竖条和横条，即问题存在于高位。所以本节的最后提供一个LCG64_32_ext的完整实现，参数ext_bit为n，那么其周期为 $ 2^{32 \\times (2^n + 2)}$\ntemplate \u0026lt;uint16_t ext_bit = 2\u0026gt; struct LCG64_32_ext : public RNG_base\u0026lt;uint32_t\u0026gt; { static const uint64_t ext_size = 1ULL \u0026lt;\u0026lt; ext_bit, ext_mask = ext_size - 1; const int init_iter = 256 * 256; uint64_t s; uint32_t a[ext_size]; LCG64_32_ext() { seed(); } LCG64_32_ext(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { seed(seed1, seed1 * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2) { s = seed1; a[0] = (uint32_t)(seed1 \u0026gt;\u0026gt; 32); if (ext_size \u0026gt; 1) a[1] = (uint32_t)seed2; if (ext_size \u0026gt; 2) a[2] = (uint32_t)(seed2 \u0026gt;\u0026gt; 32); for (uint32_t i = 3; i \u0026lt; ext_size; ++i) { a[i] = rotl32((uint32_t)(a[i - 1] * seed_mul + 1), a[i - 2] \u0026amp; 15) ^ a[i - 2]; } for (int i = 0; i \u0026lt; init_iter; ++i) (*this)(); } result_type operator()() { uint64_t x = s; if (s == 0) { for (uint64_t i = 0, carry = 0; i \u0026lt; ext_size; ++i) { if (carry) carry = (a[i] = (a[i] * 2891336453u + 887987685u)) == 0; carry |= (a[i] = (a[i] * 2891336453u + 887987685u)) == 0; } } s = s * 3935559000370003845ULL + 1442695040888963407ULL; return rotr32((uint32_t)(s \u0026gt;\u0026gt; 32), x \u0026gt;\u0026gt; 59) ^ a[x \u0026amp; ext_mask]; } };  这个图已经能与PCG的图看不出明显的差异，而且能通过BigCrash测试。当然，这样的实现还没有经过严格的随机性测试，这里只是给大家思路，以上代码建议不要用于实际使用场景。另外，以上思路参考自PCG算法。\nlua的修改 通过参阅lua的源代码，最早的时候，它还是直接使用的C语言内置的rand，后来被诟病随机数范围太小、生成的质量太差。所以后来做了一番改进，在2018年之前，使用的是TausWorthe的一个随机数算法，周期为 $2^{223}-1$ ，所以又叫做 TausWorthe 223 或 TW223，代码参见后文的taus_worthe223。这里要介绍的是lua在2018年之后更换的新随机数算法。\nxoshiro/xoroshiro 而在2018年，新出现的xoshiro/xoroshiro算法以其周期更大、质量更高、速度更快的特性，很快lua的实现便改用它，而且官方还提供了不同的实现，你可以自行在周期长度、随机数质量、运行速度间自行取舍，这个算法改进自Xorshift，同样属于LFSR。不过xoshiro/xoroshiro提供的版本实在是太多了，怎么取舍呢？我通过阅读paper，选出了三个建议的版本，分别是xoroshiro128++，xoshiro256**，xoroshiro1024**，名字后面的数字表示周期，例如xoshiro256**的周期是 $2^{256}-1$，而后面的加号和乘号表示生成时所用的运算符，所对应的类名分别是xoroshiro128pp，xoshiro256ss，xoroshiro1024ss。\n其生成速度之快超越线性同余法（限64位平台）。而xoshiro256**大多数场合足够使用，且lua所选择的实现也是它，除非你特别看它不爽非要特别大的周期，那就上xoroshiro1024**吧。而在需要快速产生大量浮点数的场合，官方建议使用xoroshiro128+或xoroshiro256+，但如果生成整数，那请不要选择只有一个+的版本，要选择++或**的版本。\nxoshiro/xoroshiro还有一个非常特别的功能，它有个jump和long jump功能，例如对于xoshiro256**，一次jump调用相当于迭代了 $2^{128}$ 次，这样生成的新状态与原来的状态距离非常大，然后用于两个线程，这样就能保证生成的序列不产生重叠，而long jump则相当于迭代 $2^{192}$ 次，这样能生成出4个状态用于4线程，这个特色功能是其它随机数生成器所不具备的。不过以下模板并不包含这部分，有需要的话自己上官网那把代码复制过来用就行。\n模板 这里的实现除了以上所提及的，还包括常见的rand48，taus88，PCG32，well512等等。编译以下代码需要C++11支持，如果要在不支持的编译器上编译就稍微改改就行。\n   点击展开  \ntemplate \u0026lt;typename _res_type, uint64_t ret_max = 0xFFFFFFFFFFFFFFFFULL\u0026gt; struct RNG_base { typedef _res_type result_type; static constexpr result_type min() { return 0; } static constexpr result_type max() { return (result_type)ret_max; } const uint64_t seed_mul = 6364136223846793005ULL; const int init_iter = 16; uint64_t new_seed() { std::random_device rd; return ((uint64_t)rd() \u0026lt;\u0026lt; 32) | rd(); } uint64_t def_seed() { static uint64_t seed = new_seed(); seed *= 3935559000370003845ULL; return ++seed; } static inline uint64_t rotl64(const uint64_t x, int k) { return (x \u0026lt;\u0026lt; k) | (x \u0026gt;\u0026gt; (64 - k)); } static inline uint64_t rotr64(const uint64_t x, int k) { return (x \u0026gt;\u0026gt; k) | (x \u0026lt;\u0026lt; (64 - k)); } static inline uint32_t rotl32(const uint32_t x, int k) { return (x \u0026lt;\u0026lt; k) | (x \u0026gt;\u0026gt; (32 - k)); } static inline uint32_t rotr32(const uint32_t x, int k) { return (x \u0026gt;\u0026gt; k) | (x \u0026lt;\u0026lt; (32 - k)); } static inline uint16_t rotl16(const uint16_t x, int k) { return (x \u0026lt;\u0026lt; k) | (x \u0026gt;\u0026gt; (16 - k)); } static inline uint16_t rotr16(const uint16_t x, int k) { return (x \u0026gt;\u0026gt; k) | (x \u0026lt;\u0026lt; (16 - k)); } }; struct PCG32 : public RNG_base\u0026lt;uint32_t\u0026gt; // XSH RR { const int init_iter = 1; // min 1 uint64_t s; PCG32() { seed(); } PCG32(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { s = seed1; for (int i = 0; i \u0026lt; init_iter; ++i) (*this)(); } result_type operator()() { uint64_t x = s; s = s * 6364136223846793005ULL + 1442695040888963407ULL; return rotr32((uint32_t)((x ^ (x \u0026gt;\u0026gt; 18)) \u0026gt;\u0026gt; 27), x \u0026gt;\u0026gt; 59); } }; struct rand48 : public RNG_base\u0026lt;uint32_t\u0026gt; { uint16_t s[3]; static const uint16_t RAND48_A0 = 0xE66D; static const uint16_t RAND48_A1 = 0xDEEC; static const uint16_t RAND48_A2 = 0x0005; static const uint16_t RAND48_C0 = 0x000B; rand48() { seed(); } rand48(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { s[0] = (uint16_t)seed1; s[1] = (uint16_t)(seed1 \u0026gt;\u0026gt; 16); s[2] = (uint16_t)(seed1 \u0026gt;\u0026gt; 32); } inline void do_rand48() { const uint32_t x0 = s[0]; const uint32_t x1 = s[1]; const uint32_t x2 = s[2]; uint32_t a = RAND48_A0 * x0 + RAND48_C0; s[0] = static_cast\u0026lt;uint16_t\u0026gt;(a \u0026amp; 0xFFFF); a \u0026gt;\u0026gt;= 16; a += RAND48_A0 * x1 + RAND48_A1 * x0; s[1] = static_cast\u0026lt;uint16_t\u0026gt;(a \u0026amp; 0xFFFF); a \u0026gt;\u0026gt;= 16; a += RAND48_A0 * x2 + RAND48_A1 * x1 + RAND48_A2 * x0; s[2] = static_cast\u0026lt;uint16_t\u0026gt;(a \u0026amp; 0xFFFF); } result_type operator()() { do_rand48(); return ((uint32_t)s[2] \u0026lt;\u0026lt; 16) + s[1]; } }; struct taus88 : public RNG_base\u0026lt;uint32_t\u0026gt; { uint32_t s[3]; const int init_iter = 0; taus88() { seed(); } taus88(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { seed(seed1, seed1 * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2) { s[0] = (uint32_t)seed1; s[1] = (uint32_t)(seed1 \u0026gt;\u0026gt; 32); s[2] = (uint32_t)(seed2 \u0026gt;\u0026gt; 32); for (int i = 0; i \u0026lt; init_iter; ++i) (*this)(); } inline uint32_t tausworthe(uint32_t arg, uint32_t stage1, uint32_t stage2, uint32_t stage3, uint32_t limit) { return ((arg \u0026amp; limit) \u0026lt;\u0026lt; stage1) ^ (((arg \u0026lt;\u0026lt; stage2) ^ arg) \u0026gt;\u0026gt; stage3); } result_type operator()() { s[0] = tausworthe(s[0], 12, 13, 19, 4294967294UL); s[1] = tausworthe(s[1], 4, 2, 25, 4294967288UL); s[2] = tausworthe(s[2], 17, 3, 11, 4294967280UL); return (s[0] ^ s[1] ^ s[2]); } }; struct taus_worthe223 : public RNG_base\u0026lt;uint64_t\u0026gt; { //const int init_iter = 1; // min 1 uint64_t gen[4]; taus_worthe223() { seed(); } taus_worthe223(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { seed(seed1, seed1 * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2) { seed(seed1, seed2, seed2 * seed_mul + 1, (seed1 ^ seed2) * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2, uint64_t seed3, uint64_t seed4) { gen[0] = seed1; gen[1] = seed2; gen[2] = seed3; gen[3] = seed4; for (int i = 0; i \u0026lt; init_iter; ++i) (*this)(); } #define taus_worthe(i,k,q,s) z = gen[i]; \\ z = (((z \u0026lt;\u0026lt; q) ^ z) \u0026gt;\u0026gt; (k - s)) ^ ((z\u0026amp;((uint64_t)(int64_t)-1 \u0026lt;\u0026lt; (64 - k))) \u0026lt;\u0026lt; s); \\ r ^= z; gen[i] = z result_type operator()() { uint64_t r = 0, z; taus_worthe(0, 63, 31, 18); taus_worthe(1, 58, 19, 28); taus_worthe(2, 55, 24, 7); taus_worthe(3, 47, 21, 8); return r; } #undef taus_worthe }; struct well512 : public RNG_base\u0026lt;uint32_t\u0026gt; { // http://lomont.org/papers/2008/Lomont_PRNG_2008.pdf // const int init_iter = 0; // min 0 const uint64_t seed_mul = 134775813; uint32_t s[16]; uint32_t index; well512() { seed(); } well512(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { seed(seed1, seed1 * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2) { seed(seed1, seed2, seed2 * seed_mul + 1, (seed1 ^ seed2) * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2, uint64_t seed3, uint64_t seed4) { s[0] = (uint32_t)(seed1); s[1] = (uint32_t)(seed1 \u0026gt;\u0026gt; 32); s[2] = (uint32_t)(seed2); s[3] = (uint32_t)(seed2 \u0026gt;\u0026gt; 32); s[4] = (uint32_t)(seed3); s[5] = (uint32_t)(seed3 \u0026gt;\u0026gt; 32); s[6] = (uint32_t)(seed4); s[7] = (uint32_t)(seed4 \u0026gt;\u0026gt; 32); uint8_t* t = (uint8_t*)s; for (int i = 32, j = 0; i \u0026lt; 64; ++i, ++j) { if (i % 4 == 0) { for (int k = i / 8; k \u0026lt; 16; ++k) s[k] = s[k - 1] * (uint32_t)seed_mul + 1; break; } t[i] = t[j] * (uint8_t)5 + ~t[i - 1]; } index = 0; for (int i = 0; i \u0026lt; init_iter; ++i) (*this)(); } result_type operator()() { uint32_t a, b, c, d; a = s[index]; c = s[(index + 13) \u0026amp; 15]; b = a ^ c ^ (a \u0026lt;\u0026lt; 16) ^ (c \u0026lt;\u0026lt; 15); c = s[(index + 9) \u0026amp; 15]; c ^= (c \u0026gt;\u0026gt; 11); a = s[index] = b ^ c; d = a ^ ((a \u0026lt;\u0026lt; 5) \u0026amp; 0xDA442D24); index = (index + 15) \u0026amp; 15; a = s[index]; s[index] = a ^ b ^ d ^ (a \u0026lt;\u0026lt; 2) ^ (b \u0026lt;\u0026lt; 18) ^ (c \u0026lt;\u0026lt; 28); return s[index]; } }; struct splitmix64 : public RNG_base\u0026lt;uint64_t\u0026gt; { //const int init_iter = 1; // min 1 uint64_t s; splitmix64() { seed(); } splitmix64(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { s = seed1; } result_type operator()() { uint64_t z = (s += 0x9e3779b97f4a7c15); z = (z ^ (z \u0026gt;\u0026gt; 30)) * 0xbf58476d1ce4e5b9; z = (z ^ (z \u0026gt;\u0026gt; 27)) * 0x94d049bb133111eb; return z ^ (z \u0026gt;\u0026gt; 31); } }; struct xoshiro64ss : public RNG_base\u0026lt;uint32_t\u0026gt; { //const int init_iter = 1; // min 1 uint32_t s[2]; xoshiro64ss() { seed(); } xoshiro64ss(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { s[0] = (uint32_t)seed1; s[1] = (uint32_t)(seed1 \u0026gt;\u0026gt; 32); for (int i = 0; i \u0026lt; init_iter; ++i) (*this)(); } result_type operator()() { const uint32_t s0 = s[0]; uint32_t s1 = s[1]; const uint32_t result = rotl32(s0 * 0x9E3779BB, 5) * 5; s1 ^= s0; s[0] = rotl32(s0, 26) ^ s1 ^ (s1 \u0026lt;\u0026lt; 9); s[1] = rotl32(s1, 13); return result; } }; struct xoroshiro128p : public RNG_base\u0026lt;uint64_t\u0026gt; { //const int init_iter = 1; // min 1 uint64_t s[2]; xoroshiro128p() { seed(); } xoroshiro128p(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { seed(seed1, seed1 * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2) { s[0] = seed1; s[1] = seed2; for (int i = 0; i \u0026lt; init_iter; ++i) (*this)(); } result_type operator()() { const uint64_t s0 = s[0]; uint64_t s1 = s[1]; const uint64_t result = s0 + s1; s1 ^= s0; s[0] = rotl64(s0, 24) ^ s1 ^ (s1 \u0026lt;\u0026lt; 16); s[1] = rotl64(s1, 37); return result; } }; struct xoroshiro128pp : public RNG_base\u0026lt;uint64_t\u0026gt; { //const int init_iter = 1; // min 1 uint64_t s[2]; xoroshiro128pp() { seed(); } xoroshiro128pp(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { seed(seed1, seed1 * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2) { s[0] = seed1; s[1] = seed2; for (int i = 0; i \u0026lt; init_iter; ++i) (*this)(); } result_type operator()() { const uint64_t s0 = s[0]; uint64_t s1 = s[1]; const uint64_t result = rotl64(s0 + s1, 17) + s0; s1 ^= s0; s[0] = rotl64(s0, 49) ^ s1 ^ (s1 \u0026lt;\u0026lt; 21); s[1] = rotl64(s1, 28); return result; } }; struct xoroshiro128ss : public RNG_base\u0026lt;uint64_t\u0026gt; { //const int init_iter = 1; // min 1 uint64_t s[2]; xoroshiro128ss() { seed(); } xoroshiro128ss(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { seed(seed1, seed1 * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2) { s[0] = seed1; s[1] = seed2; for (int i = 0; i \u0026lt; init_iter; ++i) (*this)(); } result_type operator()() { const uint64_t s0 = s[0]; uint64_t s1 = s[1]; const uint64_t result = rotl64(s0 * 5, 7) * 9; s1 ^= s0; s[0] = rotl64(s0, 24) ^ s1 ^ (s1 \u0026lt;\u0026lt; 16); s[1] = rotl64(s1, 37); return result; } }; struct xoshiro256p : public RNG_base\u0026lt;uint64_t\u0026gt; { //const int init_iter = 0; // min 0 uint64_t s[4]; xoshiro256p() { seed(); } xoshiro256p(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { seed(seed1, seed1 * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2) { seed(seed1, seed2, seed2 * seed_mul + 1, (seed1 ^ seed2) * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2, uint64_t seed3, uint64_t seed4) { s[0] = seed1; s[1] = seed2; s[2] = seed3; s[3] = seed4; for (int i = 0; i \u0026lt; init_iter; ++i) (*this)(); } result_type operator()() { const uint64_t result = s[0] + s[3]; const uint64_t t = s[1] \u0026lt;\u0026lt; 17; s[2] ^= s[0]; s[3] ^= s[1]; s[1] ^= s[2]; s[0] ^= s[3]; s[2] ^= t; s[3] = rotl64(s[3], 45); return result; } }; struct xoshiro256pp : public RNG_base\u0026lt;uint64_t\u0026gt; { //const int init_iter = 0; // min 0 uint64_t s[4]; xoshiro256pp() { seed(); } xoshiro256pp(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { seed(seed1, seed1 * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2) { seed(seed1, seed2, seed2 * seed_mul + 1, (seed1 ^ seed2) * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2, uint64_t seed3, uint64_t seed4) { s[0] = seed1; s[1] = seed2; s[2] = seed3; s[3] = seed4; for (int i = 0; i \u0026lt; init_iter; ++i) (*this)(); } result_type operator()() { const uint64_t result = rotl64(s[0] + s[3], 23) + s[0]; const uint64_t t = s[1] \u0026lt;\u0026lt; 17; s[2] ^= s[0]; s[3] ^= s[1]; s[1] ^= s[2]; s[0] ^= s[3]; s[2] ^= t; s[3] = rotl64(s[3], 45); return result; } }; struct xoshiro256ss : public RNG_base\u0026lt;uint64_t\u0026gt; { //const int init_iter = 0; // min 0 uint64_t s[4]; xoshiro256ss() { seed(); } xoshiro256ss(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { seed(seed1, seed1 * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2) { seed(seed1, seed2, seed2 * seed_mul + 1, (seed1 ^ seed2) * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2, uint64_t seed3, uint64_t seed4) { s[0] = seed1; s[1] = seed2; s[2] = seed3; s[3] = seed4; for (int i = 0; i \u0026lt; init_iter; ++i) (*this)(); } result_type operator()() { const uint64_t result = rotl64(s[1] * 5, 7) * 9; const uint64_t t = s[1] \u0026lt;\u0026lt; 17; s[2] ^= s[0]; s[3] ^= s[1]; s[1] ^= s[2]; s[0] ^= s[3]; s[2] ^= t; s[3] = rotl64(s[3], 45); return result; } }; struct xoshiro1024ss : public RNG_base\u0026lt;uint64_t\u0026gt; { //const int init_iter = 0; // min 0 uint64_t s[16]; int p; xoshiro1024ss() { seed(); } xoshiro1024ss(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { seed(seed1, seed1 * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2) { seed(seed1, seed2, seed2 * seed_mul + 1, (seed1 ^ seed2) * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2, uint64_t seed3, uint64_t seed4) { s[0] = seed1; s[1] = seed2; s[2] = seed3; s[3] = seed4; uint8_t* t = (uint8_t*)s; for (int i = 32, j = 0; i \u0026lt; 128; ++i, ++j) { if (i % 8 == 0) { for (int k = i / 8; k \u0026lt; 16; ++k) s[k] = s[k - 1] * seed_mul + 1; break; } t[i] = t[j] * (uint8_t)5 + ~t[i - 1]; } p = 0; for (int i = 0; i \u0026lt; init_iter; ++i) (*this)(); } void seed(uint8_t seed[], int size) { uint8_t* t = (uint8_t*)s; if (size \u0026gt; 128) size = 128; for (int i = 0; i \u0026lt; size; ++i) { t[i] = ((uint8_t*)seed)[i]; } if (size == 0) { size = 8; s[0] = 0x931197d8e3177f17ULL; } for (int i = size, j = 0; i \u0026lt; 128; ++i, ++j) { if (i % 8 == 0) { for (int k = i / 8; k \u0026lt; 16; ++k) s[k] = s[k - 1] * seed_mul + 1; break; } t[i] = t[j] * (uint8_t)5 + ~t[i - 1]; } p = 0; for (int i = 0; i \u0026lt; init_iter; ++i) (*this)(); } result_type operator()() { const int q = p; const uint64_t s0 = s[p = (p + 1) \u0026amp; 15]; uint64_t s15 = s[q]; const uint64_t result = rotl64(s0 * 5, 7) * 9; s15 ^= s0; s[q] = rotl64(s0, 25) ^ s15 ^ (s15 \u0026lt;\u0026lt; 27); s[p] = rotl64(s15, 36); return result; } }; struct xoshiro1024pp : public RNG_base\u0026lt;uint64_t\u0026gt; { //const int init_iter = 0; // min 0 uint64_t s[16]; int p; xoshiro1024pp() { seed(); } xoshiro1024pp(uint64_t seed1) { seed(seed1); } void seed() { seed(def_seed()); } void seed(uint64_t seed1) { seed(seed1, seed1 * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2) { seed(seed1, seed2, seed2 * seed_mul + 1, (seed1 ^ seed2) * seed_mul + 1); } void seed(uint64_t seed1, uint64_t seed2, uint64_t seed3, uint64_t seed4) { s[0] = seed1; s[1] = seed2; s[2] = seed3; s[3] = seed4; uint8_t* t = (uint8_t*)s; for (int i = 32, j = 0; i \u0026lt; 128; ++i, ++j) { if (i % 8 == 0) { for (int k = i / 8; k \u0026lt; 16; ++k) s[k] = s[k - 1] * seed_mul + 1; break; } t[i] = t[j] * (uint8_t)5 + ~t[i - 1]; } p = 0; for (int i = 0; i \u0026lt; init_iter; ++i) (*this)(); } void seed(uint8_t seed[], int size) { uint8_t* t = (uint8_t*)s; if (size \u0026gt; 128) size = 128; for (int i = 0; i \u0026lt; size; ++i) { t[i] = ((uint8_t*)seed)[i]; } if (size == 0) { size = 8; s[0] = 0x931197d8e3177f17ULL; } for (int i = size, j = 0; i \u0026lt; 128; ++i, ++j) { if (i % 8 == 0) { for (int k = i / 8; k \u0026lt; 16; ++k) s[k] = s[k - 1] * seed_mul + 1; break; } t[i] = t[j] * (uint8_t)5 + ~t[i - 1]; } p = 0; for (int i = 0; i \u0026lt; init_iter; ++i) (*this)(); } result_type operator()() { const int q = p; const uint64_t s0 = s[p = (p + 1) \u0026amp; 15]; uint64_t s15 = s[q]; const uint64_t result = rotl64(s0 + s15, 23) + s15; s15 ^= s0; s[q] = rotl64(s0, 25) ^ s15 ^ (s15 \u0026lt;\u0026lt; 27); s[p] = rotl64(s15, 36); return result; } };  \n效率测试 我们当然不能全信官方的数据，具体表现不同机器不同编译器也可能不相同，所以我们就来测试一下。测试所用的实现均为我个人实现的版本，不代表官方版本的运行效率，PCG32使用的是XSH-RR，PCG64使用的是XSL-RR\n在x86下测试标准是生成2亿个64位随机数的运行时间，如生成器生成的是32位，那么生成4亿个32位整数，即以相同输出位数的时间来做比较\nx86 在VS2015上以x86编译的运行时间\n   算法实现 毫秒     LCG32 394   LCG64_32 1502   LCG32_16_ext,4 2034   LCG64_32_ext,2 2579   PCG32 1819   PCG64 6705   PCG32_ext,2 2581   rand48 2221   taus88 1232   taus_worthe223 1844   well512 1794   splitmix64 2118   xorshift128 605   xorshift128p 882   xoshiro64ss 534   xoroshiro128p 1181   xoroshiro128pp 1194   xoroshiro128ss 1382   xoshiro256p 1279   xoshiro256pp 1856   xoshiro256ss 1513   xoshiro1024pp 1472   xoshiro1024ss 1585   std::mt19937 1651    在mingw32 gcc5.1.0 以-O2参数编译的结果\n   算法实现 毫秒     LCG32 398   LCG64_32 1219   LCG32_16_ext,4 1008   LCG64_32_ext,2 877   PCG32 1384   PCG64 3141   PCG32_ext,2 1439   rand48 1084   taus88 705   taus_worthe223 1757   well512 1173   splitmix64 1267   xorshift128 663   xorshift128p 919   xoshiro64ss 462   xoroshiro128p 821   xoroshiro128pp 951   xoroshiro128ss 1036   xoshiro256p 845   xoshiro256pp 1094   xoshiro256ss 1205   xoshiro1024pp 1067   xoshiro1024ss 1074   std::mt19937 1033    x64 在VS2015上以x64编译的运行时间\n   算法实现 毫秒     LCG32 396   LCG64_32 399   LCG32_16_ext,4 1207   LCG64_32_ext,2 609   PCG32 407   PCG64 670   PCG32_ext,2 988   rand48 1033   taus88 1147   taus_worthe223 759   well512 1821   splitmix64 212   xorshift128 516   xorshift128p 328   xoshiro64ss 515   xoroshiro128p 215   xoroshiro128pp 267   xoroshiro128ss 232   xoshiro256p 151   xoshiro256pp 182   xoshiro256ss 193   xoshiro1024pp 492   xoshiro1024ss 462   std::mt19937 1580    在centos7x64 gcc8.3.1 以-O2参数编译的结果\n   算法实现 毫秒     LCG32 426   LCG64_32 413   LCG32_16_ext,4 1115   LCG64_32_ext,2 505   PCG32 434   PCG64 392   PCG32_ext,2 511   rand48 839   taus88 707   taus_worthe223 448   well512 1009   splitmix64 186   xorshift128 525   xorshift128p 229   xoshiro64ss 476   xoroshiro128p 168   xoroshiro128pp 217   xoroshiro128ss 237   xoshiro256p 181   xoshiro256pp 191   xoshiro256ss 182   xoshiro1024pp 292   xoshiro1024ss 314   std::mt19937 2112    从以上数据来看，首先要区分架构，如果是32位的，++的更快，而在64位上则大多**稍快，而现在大多数系统都支持64位的情况下，优先考虑**的版本。而256与128的差距很小，不建议使用128，除非你确实要省这么点内存。综合最佳的是xoshiro256**，即表格里的xoshiro256ss，64位架构下比线性同余快，而且质量好得多，推荐使用它。而如果你需要同时考虑32位和64位，那选择xoshiro256++也是不错的。再者，如果你只需要生成浮点随机数，那么xoroshiro128p是速度最快的。不过老实说，大多数场合都没有必要对这么点差别纠结，选择一个合适的就行了，而且VS测试结果很迷，优化得让人猜不透，我认为以gcc的结果优先作为参考。以上数据仅供参考。\n随机性测试 使用 TestU01 1.2.3 版的 SmallCrash, Crash 和 BigCrash 进行测试（如SmallCrash未通过则不测试Crash，Crash未通过则不测试BigCrash），横线-表示通过测试，/表示不进行测试，?表示未测试\n   算法实现 状态空间(bits) 状态周期 SmallCrash未通过项 Crash未通过项 BigCrash未通过项     LCG32 32 $2^{32}$ MaxOft\u0026hellip;.[1] / /   LCG64_32 64 $2^{32}$ - CollisionOverBirthdaySpacings /   LCG32_16ro 32 $2^{32}$ - - MaxOft\u0026hellip;.[2]   LCG32_16_ext,0 48 $2^{48}$ - - SerialOver\u0026hellip;[3]   LCG32_16_ext,4 288 $2^{288}$ - - -   LCG64_32_ext,0 96 $2^{96}$ - - -   PCG16 32 $2^{32}$ - SerialOverMaxOft /   PCG32 64 $2^{64}$ - - -   PCG64 128 $2^{128}$ - - -   PCG32_ext,0 96 $2^{96}$ - - -   rand48 48 $2^{48}$ SimpPoker\u0026hellip;.[4] / /   taus88 96 $2^{88}-1$ - MatrixRankLinearComp /   taus_worthe223 256 $2^{223}-1$ - MaxOftMatrixRankLinearComp /   well512 512 $2^{512}-1$ - MatrixRankLinearComp /   splitmix64 64 $2^{64}$ - - -   xorshift64s 64 $2^{64}-1$ - - MatrixRank   xorshift128 128 $2^{128}-1$ MaxOft / /   xorshift128p 128 $2^{128}-1$ - - -[5]   xoshiro64ss 64 $2^{64}-1$ - A.S.[6] /   xoroshiro128p 128 $2^{128}-1$ - - -   xoroshiro128pp 128 $2^{128}-1$ - - -   xoroshiro128ss 128 $2^{128}-1$ - - -   xoshiro256p 256 $2^{256}-1$ - - -   xoshiro256pp 256 $2^{256}-1$ - - -   xoshiro256ss 256 $2^{256}-1$ - - -   xoshiro1024pp 1056 $2^{1024}-1$ - - -   xoshiro1024ss 1056 $2^{1024}-1$ - - -   std::mt19937 20032 $2^{19937}-1$ - LinearComp /    注解：\n LCG32未通过的项：BirthdaySpacings, Collision, Gap, SimpPoker, CouponCollector, MaxOft, WeightDistrib, MatrixRank, HammingIndep, RandomWalk1 LCG32_16ro的实现代码并不是本文中描述的有问题的版本，它是列表里唯一一个32位能通过SmallCrash和Crash测试的实现。BigCrash未通过的项：CouponCollector, Gap, MaxOft, WeightDistrib, SumCollector, LongestHeadRun, PeriodsInStrings LCG32_16ext,0在BigCrash未通过的项：SerialOver, CouponCollector, WeightDistrib, PeriodsInStrings rand48未通过的项：BirthdaySpacings, Gap, SimpPoker, WeightDistrib, CouponCollector 据wiki，xorshift128p输出reversed的情况下不能通过BigCrash测试 xoshiro64ss未通过的项：AppearanceSpacings  随机性测试的部分结果也会带有一定的随机性，多次测试的结果可能不同，测试结果仅供参考\n生成 $[0, 1.0)$ 范围的均匀分布浮点数 以上模板生成的都是无符号整数，如果要生成浮点数的话，以上的模板里除了MCG不能直接用以下函数外，其它的都可以直接使用（速度快），用来把生成的整数转换成对应的浮点数。又或者，你可以直接用STL的uniform_real_distribution（通用性好），以上全部模板支持STL的distribution系列。\nfloat rand_float(uint32_t rnd) { union { float f; uint32_t u; }x; x.u = ((rnd \u0026gt;\u0026gt; 9) | 0x3F800000UL); return x.f - 1.0f; } double rand_float(uint64_t rnd) { union { double d; uint64_t u; } x; x.u = ((rnd \u0026gt;\u0026gt; 12) | 0x3FF0000000000000UL); return x.d - 1.0; }  生成 $[0, n]$ 范围的均匀分布随机整数 很多人第一个方案就是 rnd % (n + 1) ，其实这是错误的，在你对随机数分布要求不高的时候可以这么用，否则只要n+1不是2的整数次幂，获得的随机数就不是均匀分布的，除了直接使用STL的uniform_int_distribution，自己写的话，除了MCG不能直接用以下函数外，其它的大多可以直接使用（条件是参数eg的随机引擎生成的随机数最大值必须大于等于n）\ntemplate\u0026lt;class _Eg\u0026gt; static uint64_t i64_distribution(_Eg\u0026amp; eg, uint64_t n) { ++n; if ((n \u0026amp; -n) == n) return (int64_t)eg() \u0026amp; (n-1); uint64_t m = n; while (m \u0026amp; (m - 1)) m += m \u0026amp; -m; --m; for (;;) { uint64_t r = (uint64_t)eg() \u0026amp; m; if (r \u0026lt; n) return r; } }  不过这样的缺点是如果n比较小，那随机数据的大部分都浪费了，为了能更大地利用随机数据，可以做如下的改进，按n的大小分为1，2，4，8字节，每次从随机数据里取1，2，4，8个字节，多余的部分留下次使用，这样既照顾了速度也照顾了数据利用率。如果你需要能生成任意大小，那么你需要把随机数引擎作为二进制流数据生成，然后再从二进制流读取 $log_2n$ 个bit来做以上操作，这样代码较为复杂，但在n较小的时候能最大限度的利用生成的数据，这里就不具体展开了，有这个需求的话直接使用 uniform_int_distribution 就足够了。以上全部模板支持直接调用。\n网上还有很多其它的错误生成方法，以下给大家带来一个视频，我觉得讲解得不错\n 后记 随机数生成是一个大坑，以上只是做个简单得不能再简单的介绍，我只是碰巧看到lua更新了这个顺便更新一波，写个普及文，要是自己去创造一个随机数算法，我觉得比写别的算法还困难不少，绝大多数的实现都经不起数学推敲。之后有时间再收集收集资料再做介绍。\nReferences 线性同余 LCG\nMCG\n梅森旋转\nLFSR\nxoshiro/xoroshiro\nPCG\nPCG pdf\nLCG Generator Parameters\nList of random number generators\n","date":1578097560,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578097560,"objectID":"22c9605eb974cdb014a743617be1908a","permalink":"/post/20200104-xoshiro/","publishdate":"2020-01-04T08:26:00+08:00","relpermalink":"/post/20200104-xoshiro/","section":"post","summary":"这次主要介绍伪随机数生成算法，顺便介绍一个在2018-2019年的伪随机数研究成果，就是 xoshiro/xoroshiro 随机数生成算法。\n历史 在较早的时候，甚至到现在，伪随机数的生成元老级别算法“线性同余伪随机数生成算法”可谓无处不在，像现在的C/C++的rand函数就是使用线性同余实现的伪随机数生成。所谓的线性同余法，就是这个迭代方程 $S_n = (aS_{n-1} + c)\\mod m$，其中，$S_0$ 称为这个随机序列的种子，a,c,m是三个常数，不过这三个数不能随意选，m的大小决定随机数的周期，最大周期等于m，为了便于在计算机里实现，通常m选取$2^{32}$或$2^{64}$。在m已经确定为这两的时候，为了让周期尽可能大，常数a,c还至少要满足以下条件：\n 若 c 非 0，那么 c 与 m 互质；若 c 为 0，那么 a 与 m 互质 m 所有的素因子均能整除 a-1 若 m 是4的倍数，那么 a-1 也是 4 的倍数 a 和 c 都是正整数且小于 m  一些典型的常数取值可以参见wiki上的线性同余条目。\n更高的需求 我们之所以使用线性同余，就是因为它实现简单，在对随机数质量要求较低的时候，例如用来作为treap的随机数，那么线性同余完全够用，但建议不要使用rand，因为在windows下不少编译器的最大值太小了，导致效果下降，自己写一个用参数a=69069,c=1,m=2^32比rand好，我在那篇关于treap的文章就是用了这组参数。线性同余法最大的缺陷是低位随机性特别差，如果使用类似next() % k的方式来获得区间在$[0,k-1]$的随机数，那么当线性同余迭代方程的m是2的幂且k也是2的幂的时候，灾难就发生了，特别地当k是2的时候，你将得到一个0101的循环序列。为了避免这种情况，通常会取线性同余结果的高位，而且低位去掉得越多，%2的周期就越长。例如结果是64位，取高32位作为最终结果，那么%2的周期就是 $2^{33}$ ，但这样会导致有效位减少，而且问题也没有根本地解决。另一种解决办法是选取一个素数作为m，例如2147483647正是一个素数，但如此一来，线性同余的计算速度就会慢不少，周期也没有前一个的长。两种基本实现如下：\n","tags":["算法","LCG","PCG","xoshiro/xoroshiro","随机数","模板","c++"],"title":"伪随机数生成算法","type":"post"},{"authors":null,"categories":["研究"],"content":"可持久化权值线段树，wiki上指出引入者名字叫黃嘉泰，名字缩写正好是某位主席名字，所以又叫做主席树。而本篇先介绍可持久化线段树，阅读本篇前你需要先了解线段树\n概念 所谓的可持久化，意思是你能得到所有的历史版本，为了达到这个效果，当然可以每次修改的时候，先整体复制再修改，结果自然就是会爆内存。而事实上，由于每次修改最多改一条链，而其它分支可以重用。我们先拿链表做例子，如果有个链表内容是 1-\u0026gt;2-\u0026gt;3-\u0026gt;4-\u0026gt;5 ，现在我们把3修改成6，得到 1-\u0026gt;2-\u0026gt;6-\u0026gt;4-\u0026gt;5 ，但是后面的元素没有改动，所以我们可以把后面的元素直接重叠在一起使用，如下图：\ngraph LR; 1--\u0026gt;2 2--\u0026gt;3 3--\u0026gt;4 4--\u0026gt;5 1'--\u0026gt;2' 2'--\u0026gt;6 6--\u0026gt;4  这样，完全可以当成两条不同的链表使用，同时节省空间。而可持久化线段树做法与这一样，就是没变的部分还使用原来节点，所以这个实现不能使用之前介绍的堆式储存，要和平衡树一样动态开节点。\n数据结构 假设我们的数据是以下这样\n   下标 1 2 3 4     数据 1 0 5 2    构建线段树后结果如下\ngraph TD; 1,4:8--\u0026gt;1,2:1 1,4:8--\u0026gt;3,4:7 1,2:1--\u0026gt;1,1:1 1,2:1--\u0026gt;2,2:0 3,4:7--\u0026gt;3,3:5 3,4:7--\u0026gt;4,4:2  冒号前面的两个数表示一条线段，冒号后表示的是数据，这个数据表示的是这个区间的和。\n然后我们要把第3个元素从5改为1，构造第二棵线段树，首先复制一个root，包括儿子的指向也复制，得到\ngraph TD; 1,4:8--\u0026gt;1,2:1 1,4:8--\u0026gt;3,4:7 1,2:1--\u0026gt;1,1:1 1,2:1--\u0026gt;2,2:0 3,4:7--\u0026gt;3,3:5 3,4:7--\u0026gt;4,4:2 1,4':8--\u0026gt;1,2:1 1,4':8--\u0026gt;3,4:7  然后，要更新的节点在右儿子那，所以把右儿子复制出来，得到\ngraph TD; 1,4:8--\u0026gt;1,2:1 1,4:8--\u0026gt;3,4:7 1,2:1--\u0026gt;1,1:1 1,2:1--\u0026gt;2,2:0 3,4:7--\u0026gt;3,3:5 3,4:7--\u0026gt;4,4:2 1,4':8--\u0026gt;1,2:1 1,4':8--\u0026gt;3,4':7 3,4':7--\u0026gt;3,3:5 3,4':7--\u0026gt;4,4:2  最后，在区间$[3,4]$要更新的节点在左儿子那，所以把左儿子复制出来，同时由于这是最后的节点，再从底向上更新sum，得到\ngraph TD; 1,4:8--\u0026gt;1,2:1 1,4:8--\u0026gt;3,4:7 1,2:1--\u0026gt;1,1:1 1,2:1--\u0026gt;2,2:0 3,4:7--\u0026gt;3,3:5 3,4:7--\u0026gt;4,4:2 1,4':4--\u0026gt;1,2:1 1,4':4--\u0026gt;3,4':3 3,4':3--\u0026gt;L3,3':1 3,4':3--\u0026gt;4,4:2  上图中L3,3':1是3,4':3的左儿子。这样就是可持久化线段树的构造过程\n静态区间范围查询 现在给出区间$[L,R]$和范围$[a,b]$，求数组中在区间$[L,R]$里有多少个元素在范围$[a,b]$里。这种查询普通的线段树并不好办，那可持久化线段树有什么方法来解呢，首先我们先构造一棵空线段树，然后对数组元素做离散化，按大小映射到$[0,n-1]$，然后对离散化后的数组，按下标次序，一个一个加入到可持久化线段树里，例如数字2，那么我们就要在线段树里对2号元素+1，所以这就是可持久化权值线段树，即主席树。如此这般加入后，由于我们是按下标次序加入的，所以我们非常容易地得到表示区间$[0,R]$的线段树，那么在范围$[a,b]$里的元素数量，正好就是$[a,b]$区间和。但如果要求的是区间$[L,R]$里有多少个元素在范围$[a,b]$里，那我们除了要求出区间$[0,R]$，还要求出区间$[0,L-1]$，然后两者的$[a,b]$区间和的差，就是我们所要的答案\n基础模板 以下基础模板只支持区间求和，即求区间$[0,R]$里有多少个元素在范围$[a,b]$里\nstruct persistent_seg_tree { struct data { int sum; data() :sum(0) {} }; struct node { int l, r; data d; node() :l(0), r(0) {} }; vector\u0026lt;node\u0026gt; nodes; vector\u0026lt;int\u0026gt; roots; int sz; void up(int id) { nodes[id].d.sum = nodes[nodes[id].l].d.sum + nodes[nodes[id].r].d.sum; } int newnode(int cpy) { int id = (int)nodes.size(); node tmp = nodes[cpy]; nodes.push_back(tmp); return id; } int add(int tp, int tl, int tr, int i, int v) { int id = newnode(tp); if (tl + 1 \u0026gt;= tr) { nodes[id].d.sum += v; return id; } int tmid = (tl + tr) / 2; if (i \u0026lt; tmid) { int nid = add(nodes[id].l, tl, tmid, i, v); nodes[id].l = nid; } else { int nid = add(nodes[id].r, tmid, tr, i, v); nodes[id].r = nid; } up(id); return id; } int getsum(int tp, int tl, int tr, int l, int r) { if (l \u0026lt;= tl \u0026amp;\u0026amp; tr \u0026lt;= r) { return nodes[tp].d.sum; } int tmid = (tl + tr) / 2; int sum = 0; if (l \u0026lt; tmid) { sum += getsum(nodes[tp].l, tl, tmid, l, r); } if (r \u0026gt; tmid) { sum += getsum(nodes[tp].r, tmid, tr, l, r); } return sum; } // interface void init(int range, int root_size) // 数组大小[0, range)，操作次数 { sz = range; nodes.clear(); roots.clear(); nodes.reserve(root_size * (int)(log(sz * 2.0) / log(2.0) + 1.01)); nodes.push_back(node()); roots.reserve(root_size + 1); roots.push_back(0); } void add(int pos, int v) { int last = roots.back(); roots.push_back(add(last, 0, sz, pos, v)); } int getsum(int t, int l, int r) { if (t \u0026lt;= 0) return 0; if (r \u0026lt; l) return 0; if (t \u0026gt;= (int)roots.size()) t = (int)roots.size() - 1; return getsum(roots[t], 0, sz, l, r + 1); } };  使用说明，先调用init，参数分别是离散化后的值域大小，和数组大小（对应的就是操作完后根的个数，所以名字是root_size），然后循环 add(pos, 1)，最后查询时，调用getsum(R, a, b) - getsum(L - 1, a, b)，LR就是区间，ab就是值域范围。\n静态区间第k大 此问题解法较多，本篇主要介绍使用主席树的解法，同样也是先建立一棵可持久化权值线段树，对于查询区间为$[0,R]$的第k大，这个问题很简单，就是找出前缀和大于等于k的区间$[0,m]$所对应的最小的m值，所以只要对$[0,R]$所对应的线段树做查找，如果左子树的sum小于等于k，那么进入左子树查询k，否则进入右子树查询k-sum即可。但对于查询区间$[L,R]$，我们需要找出$[0,R]$和$[0,L-1]$这两棵线段树，它们的$[a,b]$区间和表示在$[L,R]$里有多少个数的值域在$[a,b]$之间，所以我们就同时对这两棵线段树做查找，设 $[0,R]$左子树的sum 减去 $[0,L-1]$左子树的sum 为S，那么如果S小于等于k，那么进入左子树查询k，否则进入右子树查询k-S，实现代码如下\nint kth(int tpl, int tpr, int tl, int tr, int k) { if (tl + 1 \u0026gt;= tr) return tl; int tmid = (tl + tr) / 2; int num = nodes[nodes[tpr].l].d.sum - nodes[nodes[tpl].l].d.sum; if (k \u0026lt;= num) return kth(nodes[tpl].l, nodes[tpr].l, tl, tmid, k); else return kth(nodes[tpl].r, nodes[tpr].r, tmid, tr, k - num); }  区间第k大模板 struct persistent_seg_tree { struct data { int sum; data() :sum(0) {} }; struct node { int l, r; data d; node() :l(0), r(0) {} }; vector\u0026lt;node\u0026gt; nodes; vector\u0026lt;int\u0026gt; roots; int sz; void up(int id) { nodes[id].d.sum = nodes[nodes[id].l].d.sum + nodes[nodes[id].r].d.sum; } int newnode(int cpy) { int id = (int)nodes.size(); node tmp = nodes[cpy]; nodes.push_back(tmp); return id; } int add(int tp, int tl, int tr, int i, int v) { int id = newnode(tp); if (tl + 1 \u0026gt;= tr) { nodes[id].d.sum += v; return id; } int tmid = (tl + tr) / 2; if (i \u0026lt; tmid) { int nid = add(nodes[id].l, tl, tmid, i, v); nodes[id].l = nid; } else { int nid = add(nodes[id].r, tmid, tr, i, v); nodes[id].r = nid; } up(id); return id; } int kth(int tpl, int tpr, int tl, int tr, int k) { if (tl + 1 \u0026gt;= tr) return tl; int tmid = (tl + tr) / 2; int num = nodes[nodes[tpr].l].d.sum - nodes[nodes[tpl].l].d.sum; if (k \u0026lt;= num) return kth(nodes[tpl].l, nodes[tpr].l, tl, tmid, k); else return kth(nodes[tpl].r, nodes[tpr].r, tmid, tr, k - num); } // interface void init(int range, int root_size) // 数组大小[0, range)，操作次数 { sz = range; nodes.clear(); roots.clear(); nodes.reserve(root_size * (int)(log(sz * 2.0) / log(2.0) + 1.01)); nodes.push_back(node()); roots.reserve(root_size + 1); roots.push_back(0); } void add(int i, int v) { int last = roots.back(); roots.push_back(add(last, 0, sz, i, v)); } int kth(int tpl, int tpr, int k) { return kth(roots[tpl - 1], roots[tpr], 0, sz, k); } };  其它说明 其它的可持久化数据结构大同小异，如可持久化的trie，构造方法也是一样的\n以上只介绍了静态区间的范围查询和第k大查询，还不支持动态修改并查询，这个会在之后再做介绍。\n习题：静态区间范围查询hdu 4417，静态区间第k大POJ 2104\n","date":1577751960,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577751960,"objectID":"9c8603324d8e0c96646ee34a331a097c","permalink":"/post/20191231-persistent_segtree/","publishdate":"2019-12-31T08:26:00+08:00","relpermalink":"/post/20191231-persistent_segtree/","section":"post","summary":"可持久化权值线段树，wiki上指出引入者名字叫黃嘉泰，名字缩写正好是某位主席名字，所以又叫做主席树。而本篇先介绍可持久化线段树，阅读本篇前你需要先了解线段树\n概念 所谓的可持久化，意思是你能得到所有的历史版本，为了达到这个效果，当然可以每次修改的时候，先整体复制再修改，结果自然就是会爆内存。而事实上，由于每次修改最多改一条链，而其它分支可以重用。我们先拿链表做例子，如果有个链表内容是 1-\u0026gt;2-\u0026gt;3-\u0026gt;4-\u0026gt;5 ，现在我们把3修改成6，得到 1-\u0026gt;2-\u0026gt;6-\u0026gt;4-\u0026gt;5 ，但是后面的元素没有改动，所以我们可以把后面的元素直接重叠在一起使用，如下图：\ngraph LR; 1--\u0026gt;2 2--\u0026gt;3 3--\u0026gt;4 4--\u0026gt;5 1'--\u0026gt;2' 2'--\u0026gt;6 6--\u0026gt;4  这样，完全可以当成两条不同的链表使用，同时节省空间。而可持久化线段树做法与这一样，就是没变的部分还使用原来节点，所以这个实现不能使用之前介绍的堆式储存，要和平衡树一样动态开节点。\n数据结构 假设我们的数据是以下这样\n   下标 1 2 3 4     数据 1 0 5 2    构建线段树后结果如下\ngraph TD; 1,4:8--\u0026gt;1,2:1 1,4:8--\u0026gt;3,4:7 1,2:1--\u0026gt;1,1:1 1,2:1--\u0026gt;2,2:0 3,4:7--\u0026gt;3,3:5 3,4:7--\u0026gt;4,4:2  冒号前面的两个数表示一条线段，冒号后表示的是数据，这个数据表示的是这个区间的和。\n然后我们要把第3个元素从5改为1，构造第二棵线段树，首先复制一个root，包括儿子的指向也复制，得到\ngraph TD; 1,4:8--\u0026gt;1,2:1 1,4:8--\u0026gt;3,4:7 1,2:1--\u0026gt;1,1:1 1,2:1--\u0026gt;2,2:0 3,4:7--\u0026gt;3,3:5 3,4:7--\u0026gt;4,4:2 1,4':8--\u0026gt;1,2:1 1,4':8--\u0026gt;3,4:7 ","tags":["数据结构","线段树","可持久化","模板","c++"],"title":"可持久化线段树","type":"post"},{"authors":null,"categories":["研究"],"content":"KMP已经介绍过了，这次主要介绍的是Manacher\n最长回文子串 Manacher算法要解决的问题就是求最长回文子串，用到的思维和扩展KMP实在是像，不过理解起来比扩展KMP简单。\n先定义数组v，v[i]表示以第i个字符为中心，到回文串一端的距离，我们以字符串\u0026quot;acabacab\u0026quot;为例，如下表（index是下标）\n   string a c a b a c a b \\0     index 0 1 2 3 4 5 6 7 8   m    ^        i    ^        e        ^    v 1 2 1 4         i是当前要计算的指针，m是上次计算的指针，e是下一个要比较的位置的指针\n然后++i，注意这时候，由于以字符b两边是对称的，所以在求v[4]的值的时候，可以先查v[2]的值，是1，所以v[4]也是1\n   string a c a b a c a b \\0     index 0 1 2 3 4 5 6 7 8   m    ^        i     ^       e        ^    v 1 2 1 4 1        再继续++i，同样的，在求v[5]的值的时候，可以先查v[1]的值，是2，但是，这个长度达到了e指针的位置，即i+2\u0026gt;=e，这时候就更新指针m，并扩展e的位置，即比较str[7]与str[3]，找到以下标5为中心的回文串边界。\n   string a c a b a c a b \\0     index 0 1 2 3 4 5 6 7 8   m      ^      i      ^      e         ^   v 1 2 1 4 1 3       然后，v[5]的值就是e-i，再接着，求v[6]的值就查v[4]的\n   string a c a b a c a b \\0     index 0 1 2 3 4 5 6 7 8   m      ^      i       ^     e         ^   v 1 2 1 4 1 3 1      再接着，求v[7]的值就查v[3]的，不过v[3]的值是4，而i+4\u0026gt;=e又满足了，就再次更新指针m，并扩展e\n   string a c a b a c a b \\0     index 0 1 2 3 4 5 6 7 8   m        ^    i        ^    e         ^   v 1 2 1 4 1 3 1 1     最后得到的v数组最大值乘以2减1就是答案，以上指针在算法里只增不减，所以时间复杂度是 $O(n)$ 。但问题是，这只能求出奇数长度的回文串，所以，这里用到一个技巧，把原来的字符串\u0026quot;acabacab\u0026quot;转成\u0026quot;a#c#a#b#a#c#a#b\u0026quot;，其中#号是任意一个在原字符串中不会出现的字符，这样一来，任意原串的回文串都存在中心字符了。\n还有一个细节，如果要计算的串是\u0026quot;a\u0026quot;，那么回文串的长度应该是1，但是，在这个算法里，会产生越界访问，因为要判断字符a后面的'\\0'是不是与a前面的字符相同，如果正好都是'\\0'，就会导致计算错误。所以，计算的时候还要对原来的字符串在最前面添加第二个在原字符串中不会出现的字符，例如转成\u0026quot;$a#c#a#b#a#c#a#b\u0026quot;\n扩展KMP模板和Manacher模板对比 代码高度相似，你看看就知道了\nvoid extkmp_z(const char* str, int z[]) { int s_len = strlen(str); z[0] = s_len; for (int i = 1, p = 1, e = 1; i \u0026lt; s_len; ++i) { if (i + z[i - p] \u0026gt;= e) { e = std::max(i, e); p = i; while (e \u0026lt; s_len \u0026amp;\u0026amp; str[e] == str[e - i]) ++e; z[i] = e - i; } else z[i] = z[i - p]; } } void extkmp_ext(const char* str, int ext[], const char* pattern, int z[]) { int s_len = strlen(str); extkmp_z(pattern, z); for (int i = 0, p = 0, e = 0; i \u0026lt; s_len; ++i) { if (i + z[i - p] \u0026gt;= e) { e = std::max(i, e); p = i; while (e \u0026lt; s_len \u0026amp;\u0026amp; str[e] == pattern[e - i]) ++e; ext[i] = e - i; } else ext[i] = z[i - p]; } } void init_str(const char* str, char* t) { int len = strlen(str); t[0] = '$'; t[1] = '#'; for (int i = 0; str[i]; ++i) { t[(i + 1) \u0026lt;\u0026lt; 1] = str[i]; t[((i + 1) \u0026lt;\u0026lt; 1) + 1] = '#'; } t[(len + 1) \u0026lt;\u0026lt; 1] = 0; } int manacher(const char* s, int v[]) { int len = strlen(s); int max_len = 0; v[0] = 1; v[1] = 1; for (int i = 1, m = 1, e = 1; i \u0026lt; len; ++i) { if (i + v[m - (i - m)] \u0026gt;= e) { e = std::max(i, e); m = i; while (e \u0026lt; len \u0026amp;\u0026amp; s[e] == s[i - (e - i)]) ++e; v[i] = e - i; } else v[i] = v[m - (i - m)]; max_len = std::max(max_len, v[i]); } return max_len - 1; }  以上是第一种写法的模板，再对比写法二\nvoid extkmp_ext(const char* str, int ext[], const char* pattern, int z[]) { int s_len = strlen(str); extkmp_z(pattern, z); for (int i = 0, l = 0, r = 0; i \u0026lt; s_len; ++i) { if (i \u0026lt; r) { ext[i] = std::min(r - i, z[i - l]); } else { ext[i] = 0; } while (i + ext[i] \u0026lt; s_len \u0026amp;\u0026amp; str[i + ext[i]] == pattern[ext[i]]) { ++ext[i]; } if (i + ext[i] \u0026gt; r) { r = i + ext[i]; l = i; } } } int manacher(const char* s, int v[]) { int len = strlen(s); int max_len = 0; for (int i = 1, m = 1, r = 1; i \u0026lt; len; ++i) { if (i \u0026lt; r) { v[i] = std::min(v[m - (i - m)], r - i); } else { v[i] = 1; } while (s[i + v[i]] == s[i - v[i]]) { ++v[i]; } if (i + v[i] \u0026gt; r) { r = i + v[i]; m = i; } max_len = std::max(max_len, v[i]); } return max_len - 1; }  其它解法 用后缀数组来解回文串也是可以的，原串是s的话，把s反向，得到s1，然后构造S = s + '#' + s1，对S求后缀数组后，要注意的是并不是只找height的最大值即可，网上很多文章在这里的算法是错误的，反例是abcdefba，单纯枚举相邻的sa是不正确的。\n正确做法是枚举i从1到len(s)/2，分别针对奇数长度和偶数长度要分别计算LCP（最长公共前缀），奇数长度时它的对称位置就是j=len-i+1，偶数长度时对称位置是j=len-i或j=len-i+2，然后对height数组求从rank[i]+1到rank[j]的最小值。最小值维护用ST表，由于ST表的构造是 $O(nlogn)$ ，而查询是 $O(1)$ ，所以生成后缀数组后的计算的总时间复杂度是 $O(nlogn)$\n示例代码URAL 1297\nint st[12][2048]; void init_st(int a[], int n) { for (int i = 0; i \u0026lt; n; i++) st[0][i] = a[i]; for (int k = 1; (1 \u0026lt;\u0026lt; k) \u0026lt; n; k++) for (int i = 0, m = 1 \u0026lt;\u0026lt; (k - 1); i \u0026lt; n; i++) if (i + m \u0026lt; n) st[k][i] = min(st[k - 1][i], st[k - 1][i + m]); } int st_query(int l, int r) // [l, r) { if (l \u0026gt; r)swap(l, r); int k = (int)(log(r - l - 0.1) / log(2)); return min(st[k][l], st[k][r - (1 \u0026lt;\u0026lt; k)]); } int main() { int n, t; char s[2100], s1[1010]; scanf(\u0026quot;%s\u0026quot;, s1); strcpy(s, s1); strcat(s, \u0026quot;#\u0026quot;); strcat(s, strrev(s1)); SA_2_sort sa; sa.init(s); int len = sa.size(); int maxh = 0, spos = 0; init_st(\u0026amp;*sa.ht.begin(), len + 1); for(int i = 1; i \u0026lt;= len / 2; ++i) { int j = len - i + 1; int lcp = st_query(sa.rk[i] + 1, sa.rk[j] + 1); if (lcp * 2 - 1 \u0026gt; maxh) { spos = i - lcp; maxh = lcp * 2 - 1; } if (i \u0026gt; 1) { j = len - i + 2; lcp = st_query(sa.rk[i] + 1, sa.rk[j] + 1); if (lcp * 2 \u0026gt; maxh) { spos = i - lcp - 1; maxh = lcp * 2; } } } strncpy(s1, s + spos, maxh); s1[maxh] = 0; puts(s1); return 0; }  注：后缀数组模板请从之前的文章里复制；函数st_query是左闭右开区间，即求的是[l, r-1]的最小值，采用半开半闭区间目的是为了能直接swap\n","date":1576491780,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576491780,"objectID":"3357f46a9cb119e3c61c3f5487652fe1","permalink":"/post/20191216-kmp-manacher/","publishdate":"2019-12-16T18:23:00+08:00","relpermalink":"/post/20191216-kmp-manacher/","section":"post","summary":"KMP已经介绍过了，这次主要介绍的是Manacher\n最长回文子串 Manacher算法要解决的问题就是求最长回文子串，用到的思维和扩展KMP实在是像，不过理解起来比扩展KMP简单。\n先定义数组v，v[i]表示以第i个字符为中心，到回文串一端的距离，我们以字符串\u0026quot;acabacab\u0026quot;为例，如下表（index是下标）\n   string a c a b a c a b \\0     index 0 1 2 3 4 5 6 7 8   m    ^        i    ^        e        ^    v 1 2 1 4         i是当前要计算的指针，m是上次计算的指针，e是下一个要比较的位置的指针\n然后++i，注意这时候，由于以字符b两边是对称的，所以在求v[4]的值的时候，可以先查v[2]的值，是1，所以v[4]也是1\n   string a c a b a c a b \\0     index 0 1 2 3 4 5 6 7 8   m    ^        i     ^       e        ^    v 1 2 1 4 1        再继续++i，同样的，在求v[5]的值的时候，可以先查v[1]的值，是2，但是，这个长度达到了e指针的位置，即i+2\u0026gt;=e，这时候就更新指针m，并扩展e的位置，即比较str[7]与str[3]，找到以下标5为中心的回文串边界。\n","tags":["算法","模式匹配","KMP","Manacher","模板","c"],"title":"扩展KMP与Manacher","type":"post"},{"authors":null,"categories":["研究"],"content":"讲完了treap和splaytree，接下来讲把这两的思想混合在一起的 FHQ Treap，据说作者是范浩强。\nsplay其实还有两个操作split和merge没有介绍，我打算把这两放在这里一并介绍\nSplit和Merge Split就是把树按某个条件划分成两棵子树，如果是查找树，就按某个值划分为小于它的以及大于等于它的（等于号取哪边怎么好写怎么来就是），如果是序列维护，那就按照rank来划分。而merge操作则正好相反，把两棵子树合并成为一棵。所以，如果我们需要对某个区间做操作，那么我们就把那个区间Split出来，操作好了后（打懒惰标记，或取出结果）再Merge回去就行了，与splay操作的思路是差不多的。不过为了在split再merge后能间接对树的平衡性优化，我们不能简单地merge，要套用Treap的随机数法，我们先来看怎么split。\n先定义好接口void split(int tp, int k, int \u0026amp;x, int \u0026amp;y)，x是返回的左子树，y是返回的右子树，接着我们需要递归split，如果划分点在左子树，那么y一定是根，反之划分点在右子树，那么x一定是根。确定了其中一个，在递归调用的时候，假如y确定了，于是还没确定的，就是x以及根节点的左子树的指向，所以把这两传参就行了，时间复杂度 $O(logn)$ ，具体代码如下：\n// 维护序列的实现 void split(int tp, int k, int \u0026amp;x, int \u0026amp;y) { if (!tp) { x = y = 0; return; } pushdown(tp); if (k \u0026lt;= nodes[ch(tp, 0)].sz) { y = tp; split(ch(tp, 0), k, x, ch(tp, 0)); update(y); } else { x = tp; split(ch(tp, 1), k - nodes[ch(tp, 0)].sz - 1, ch(tp, 1), y); update(x); } }  接下来讲讲merge，我们不能直接把右子树直接接在左子树的最后一个元素后，这样会导致树高度太大。在Treap里面，引入了一个随机值，来决定谁来做根节点，所以，我们就对比这个值，如果左子树的小，那么就让左子树的右儿子与右子树merge，否则就让右子树的左儿子与左子树merge，递归调用就是了，时间复杂度 $O(logn)$\nint merge(int tl, int tr) { if (!tl) return tr; else if (!tr) return tl; if (nodes[tl].k \u0026lt; nodes[tr].k) { pushdown(tl); ch(tl, 1) = merge(ch(tl, 1), tr); return update(tl); } else { pushdown(tr); ch(tr, 0) = merge(tl, ch(tr, 0)); return update(tr); } }  基本模板 这么快就给模板了？没错，你在理解了Treap以后，再去学习FHQ-Treap那是相当简单的，最复杂的两个操作已经讲完了，相比Treap，它不需要旋转操作，而通过merge操作来让树平衡，而且这组操作让其它的操作相比Treap都来得简单，最不容易写出BUG，代码也是最短的一个，常数也比splaytree小，所有操作的期望时间复杂度都是 $O(logn)$ 。\ntemplate\u0026lt;typename T\u0026gt; struct FHQ_Treap { struct data { T v; data(int _v = 0) :v(_v) {} data operator + (const data\u0026amp; d) const { data r; r.v = v + d.v; return r; } data operator * (int t) const { data r; r.v = v * t; return r; } operator bool() const { return v != 0; } operator T() const { return v; } }; struct node { int ch[2], sz; unsigned k; data d, sum, lz_add; node(int z = 1) :sz(z), k(rnd()) { ch[0] = ch[1] = 0; } static unsigned rnd() { static unsigned r = 0x123; r = r * 69069 + 1; return r; } }; vector\u0026lt;node\u0026gt; nodes; int root; int recyc; int reserve_size; void reserve() { if (size() \u0026gt;= reserve_size) nodes.reserve((reserve_size *= 2) + 1); } inline int\u0026amp; ch(int tp, int r) { return nodes[tp].ch[r]; } int new_node(const data\u0026amp; d) { int id = (int)nodes.size(); if (recyc) { id = recyc; if (ch(recyc, 0) \u0026amp;\u0026amp; ch(recyc, 1)) recyc = merge(ch(recyc, 0), ch(recyc, 1)); else recyc = ch(recyc, 0) ? ch(recyc, 0) : ch(recyc, 1); nodes[id] = node(); } else nodes.push_back(node()); nodes[id].d = d; nodes[id].sum = d; return id; } int update(int tp) { node\u0026amp; n = nodes[tp]; n.sz = 1 + nodes[n.ch[0]].sz + nodes[n.ch[1]].sz; n.sum = n.d + nodes[n.ch[0]].sum + nodes[n.ch[1]].sum; return tp; } void add(int tp, const data\u0026amp; d) { node\u0026amp; n = nodes[tp]; n.lz_add = n.lz_add + d; n.d = n.d + d; n.sum = n.sum + d * n.sz; } void pushdown(int tp) { node\u0026amp; n = nodes[tp]; if (n.lz_add) { add(n.ch[0], n.lz_add); add(n.ch[1], n.lz_add); n.lz_add = 0; } } int merge(int tl, int tr) { if (!tl) return tr; else if (!tr) return tl; if (nodes[tl].k \u0026lt; nodes[tr].k) { pushdown(tl); ch(tl, 1) = merge(ch(tl, 1), tr); return update(tl); } else { pushdown(tr); ch(tr, 0) = merge(tl, ch(tr, 0)); return update(tr); } } void split(int tp, int k, int \u0026amp;x, int \u0026amp;y) { if (!tp) { x = y = 0; return; } pushdown(tp); if (k \u0026lt;= nodes[ch(tp, 0)].sz) { y = tp; split(ch(tp, 0), k, x, ch(tp, 0)); update(y); } else { x = tp; split(ch(tp, 1), k - nodes[ch(tp, 0)].sz - 1, ch(tp, 1), y); update(x); } } void remove(int\u0026amp; tp) { if (recyc == 0) recyc = tp; else recyc = merge(recyc, tp); tp = 0; } // interface void init(int size) { nodes.clear(); nodes.reserve((size = max(size, 15)) + 1); nodes.push_back(node(0)); root = 0; recyc = 0; reserve_size = size + 1; } T get(int id) { return nodes[id].d; } int size() { return nodes[root].sz; } int kth(int k) { int x, y, z; split(root, k, y, z); split(y, k - 1, x, y); int id = y; root = merge(merge(x, y), z); return id; } void insert(int k, data v) { int l, r; split(root, k - 1, l, r); int tp = new_node(v); root = merge(merge(l, tp), r); } void erase(int l, int r) { int x, y, z; split(root, r, y, z); split(y, l - 1, x, y); remove(y); root = merge(x, z); } void range_add(int l, int r, data v) { int x, y, z; split(root, r, y, z); split(y, l - 1, x, y); add(y, v); root = merge(merge(x, y), z); } T getsum(int l, int r) { int x, y, z; split(root, r, y, z); split(y, l - 1, x, y); T ret = nodes[y].sum; root = merge(merge(x, y), z); return ret; } };  以上是个支持区间加、区间删和区间求和的模板。除了LCT，都交给这个数据结构解决吧。\n其它问题 如果你要问为什么不一开始就介绍这个，而先解释其它的树结构，那是因为那是基础啊，基础搞好了，那再搞这个就很简单了。\n","date":1576386600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576386600,"objectID":"6d50c147c8c7001a1cc278408161de2a","permalink":"/post/20191215-fhq-treap/","publishdate":"2019-12-15T13:10:00+08:00","relpermalink":"/post/20191215-fhq-treap/","section":"post","summary":"讲完了treap和splaytree，接下来讲把这两的思想混合在一起的 FHQ Treap，据说作者是范浩强。\nsplay其实还有两个操作split和merge没有介绍，我打算把这两放在这里一并介绍\nSplit和Merge Split就是把树按某个条件划分成两棵子树，如果是查找树，就按某个值划分为小于它的以及大于等于它的（等于号取哪边怎么好写怎么来就是），如果是序列维护，那就按照rank来划分。而merge操作则正好相反，把两棵子树合并成为一棵。所以，如果我们需要对某个区间做操作，那么我们就把那个区间Split出来，操作好了后（打懒惰标记，或取出结果）再Merge回去就行了，与splay操作的思路是差不多的。不过为了在split再merge后能间接对树的平衡性优化，我们不能简单地merge，要套用Treap的随机数法，我们先来看怎么split。\n先定义好接口void split(int tp, int k, int \u0026amp;x, int \u0026amp;y)，x是返回的左子树，y是返回的右子树，接着我们需要递归split，如果划分点在左子树，那么y一定是根，反之划分点在右子树，那么x一定是根。确定了其中一个，在递归调用的时候，假如y确定了，于是还没确定的，就是x以及根节点的左子树的指向，所以把这两传参就行了，时间复杂度 $O(logn)$ ，具体代码如下：\n// 维护序列的实现 void split(int tp, int k, int \u0026amp;x, int \u0026amp;y) { if (!tp) { x = y = 0; return; } pushdown(tp); if (k \u0026lt;= nodes[ch(tp, 0)].sz) { y = tp; split(ch(tp, 0), k, x, ch(tp, 0)); update(y); } else { x = tp; split(ch(tp, 1), k - nodes[ch(tp, 0)].sz - 1, ch(tp, 1), y); update(x); } } ","tags":["数据结构","Treap","FHQ Treap","模板","c++"],"title":"FHQ Treap","type":"post"},{"authors":null,"categories":["研究"],"content":"平衡树除了用来对存在偏序关系的数据进行维护，还能用于对序列维护，相当于一个数组。阅读本文你需要先看完上一篇关于treap的文章。\n序列维护 在之前的文章，我们介绍过使用树状数组，以及线段树来维护一个序列，可以做区间操作及区间求和，但它们都存在一个缺点，不能动态插入数据。那我们怎么样才能通过平衡树来维护序列呢，之前我们有一个size字段能快速找第k大（或树的中序遍历第k个元素），而旋转操作并不会改变元素之间的相对顺序，那么我们就通过它直接插入到第k个元素的前面，这样我们插入的时候就不再通过要插入的值本身的大小关系，而需要多加一个参数k决定插入的位置。当平衡树用于维护序列的时候，就不用考虑元素相等的问题了。这样我们把元素相等处理的代码删除并修改基本操作的代码就能得到第一个能维护序列的基本模板，以下模板使用Treap修改得来。\n基本模板 以下模板我实现成真·模板，就几乎可以作为数组使用了\ntemplate \u0026lt;typename T\u0026gt; struct treap_seq { struct data { T v; data(T _v = 0) :v(_v) {} operator bool() const { return v != 0; } operator T() const { return v; } }; struct node { int ch[2], sz; unsigned k; data d; node(int z = 1) :sz(z), k(rnd()) { d = ch[0] = ch[1] = 0; } void clone(const node\u0026amp; n) { d = n.d; } static unsigned rnd() { static unsigned r = 0x123; r = r * 69069 + 1; return r; } }; vector\u0026lt;node\u0026gt; nodes; vector\u0026lt;int\u0026gt; recycle; int root; int reserve_size; void reserve() { if (size() \u0026gt;= reserve_size) nodes.reserve((reserve_size *= 2) + 1); } int new_node() { int id = (int)nodes.size(); if (!recycle.empty()) { id = recycle.back(); recycle.pop_back(); nodes[id] = node(); } else nodes.push_back(node()); return id; } void update(int tp) { node\u0026amp; n = nodes[tp]; n.sz = 1 + nodes[n.ch[0]].sz + nodes[n.ch[1]].sz; } int insert(int\u0026amp; tp, int k, const data\u0026amp; d) { if (tp == 0) { tp = new_node(); nodes[tp].d = d; return tp; } node\u0026amp; n = nodes[tp]; int sz = nodes[n.ch[0]].sz + 1; int r = sz \u0026lt; k; int\u0026amp; s = n.ch[r]; int ret = insert(s, k - sz * r, d); update(s); if (nodes[s].k \u0026lt; n.k) rotate(tp, r); else update(tp); return ret; } void rotate(int\u0026amp; tp, int r) { node\u0026amp; n = nodes[tp]; int s = n.ch[r]; n.ch[r] = nodes[s].ch[r ^ 1]; nodes[s].ch[r ^ 1] = tp; update(tp); update(s); tp = s; } int erasefind(int\u0026amp; tp, int k) // return deleted { if (tp == 0) return 0; node\u0026amp; n = nodes[tp]; int sz = nodes[n.ch[0]].sz + 1; if (sz == k) { remove(tp); return 1; } int r = sz \u0026lt; k; int\u0026amp; s = n.ch[r]; int ret = erasefind(s, k - sz * r); if (ret) { update(tp); return 1; } return 0; } void remove(int\u0026amp; tp) { if (tp == 0) return; if (!nodes[tp].ch[0] || !nodes[tp].ch[1]) { recycle.push_back(tp); tp = nodes[tp].ch[!nodes[tp].ch[0]]; } else { int r = nodes[nodes[tp].ch[0]].k \u0026lt; nodes[nodes[tp].ch[1]].k; rotate(tp, r ^ 1); remove(nodes[tp].ch[r]); update(tp); } } int kth(int tp, int k) // return id { if (tp == 0) return tp; node n = nodes[tp]; int sz = nodes[n.ch[0]].sz; if (sz \u0026gt;= k) return kth(n.ch[0], k); if (sz + 1 \u0026gt;= k) return tp; return kth(n.ch[1], k - sz - 1); } // interface void init(int size) { nodes.clear(); recycle.clear(); nodes.reserve(size + 1); nodes.push_back(node(0)); root = 0; reserve_size = size; } T get(int id) { return nodes[id].d; } int size() { return nodes[root].sz; } int insert(int k, data v) { if (size() \u0026gt;= reserve_size) nodes.reserve((reserve_size *= 2) + 1); return insert(root, k, v); } int erase(int k) { return erasefind(root, k); } int kth(int k) { return kth(root, k); } // return id };  动态版本线段树 有了这个，我们就可以把它改成动态版本的线段树，就是每个根节点多维护一个sum字段，再加一个懒惰标记，就能实现区间加和区间求和。不过和线段树不同的是，线段树的子树的根只维护区间的结果，而平衡树的根本身就是一个元素，所以代码和线段树略有差别。以下我们实现一个支持区间加和区间求和且能动态增减数据的平衡树，实测与前面讲线段树文章的普通线段树模板，在解决同一问题的执行时间非常接近\ntemplate \u0026lt;typename T\u0026gt; struct treap_seq { struct data { T v; data(T _v = 0) :v(_v) {} data operator + (const data\u0026amp; d) const { data r; r.v = v + d.v; return r; } data operator * (int t) const { data r; r.v = v * t; return r; } operator bool() const { return v != 0; } operator T() const { return v; } }; struct node { int ch[2], sz; unsigned k; data d; data sum; data lz_add; node(int z = 1) :sz(z), k(rnd()) { sum = lz_add = d = ch[0] = ch[1] = 0; } void clone(const node\u0026amp; n) { d = n.d; sum = n.sum; } static unsigned rnd() { static unsigned r = 0x123; r = r * 69069 + 1; return r; } }; vector\u0026lt;node\u0026gt; nodes; vector\u0026lt;int\u0026gt; recycle; int root; int reserve_size; void reserve() { if (size() \u0026gt;= reserve_size) nodes.reserve((reserve_size *= 2) + 1); } int new_node() { int id = (int)nodes.size(); if (!recycle.empty()) { id = recycle.back(); recycle.pop_back(); nodes[id] = node(); } else nodes.push_back(node()); return id; } void _add(int tp, const data\u0026amp; d) { node\u0026amp; n = nodes[tp]; n.lz_add = n.lz_add + d; n.d = n.d + d; n.sum = n.sum + d * n.sz; } void pushdown(int tp) { node\u0026amp; n = nodes[tp]; if (n.lz_add) { _add(n.ch[0], n.lz_add); _add(n.ch[1], n.lz_add); n.lz_add = 0; } } void update(int tp) { node\u0026amp; n = nodes[tp]; n.sz = 1 + nodes[n.ch[0]].sz + nodes[n.ch[1]].sz; n.sum = n.d + nodes[n.ch[0]].sum + nodes[n.ch[1]].sum; } int insert(int\u0026amp; tp, int k, const data\u0026amp; d) { if (tp == 0) { tp = new_node(); nodes[tp].d = d; nodes[tp].sum = d; return tp; } node\u0026amp; n = nodes[tp]; pushdown(tp); int sz = nodes[n.ch[0]].sz + 1; int r = sz \u0026lt; k; int\u0026amp; s = n.ch[r]; int ret = insert(s, k - sz * r, d); update(s); if (nodes[s].k \u0026lt; n.k) rotate(tp, r); else update(tp); return ret; } void rotate(int\u0026amp; tp, int r) { node\u0026amp; n = nodes[tp]; pushdown(tp); int s = n.ch[r]; pushdown(s); n.ch[r] = nodes[s].ch[r ^ 1]; nodes[s].ch[r ^ 1] = tp; update(tp); update(s); tp = s; } int erasefind(int\u0026amp; tp, int k) // return deleted { if (tp == 0) return 0; node\u0026amp; n = nodes[tp]; pushdown(tp); int sz = nodes[n.ch[0]].sz + 1; if (sz == k) { remove(tp); return 1; } int r = sz \u0026lt; k; int\u0026amp; s = n.ch[r]; int ret = erasefind(s, k - sz * r); if (ret) { update(tp); return 1; } return 0; } void remove(int\u0026amp; tp) { if (tp == 0) return; if (!nodes[tp].ch[0] || !nodes[tp].ch[1]) { recycle.push_back(tp); tp = nodes[tp].ch[!nodes[tp].ch[0]]; } else { int r = nodes[nodes[tp].ch[0]].k \u0026lt; nodes[nodes[tp].ch[1]].k; rotate(tp, r ^ 1); remove(nodes[tp].ch[r]); update(tp); } } int kth(int tp, int k) // return id { if (tp == 0) return tp; node n = nodes[tp]; pushdown(tp); int sz = nodes[n.ch[0]].sz; if (sz \u0026gt;= k) return kth(n.ch[0], k); if (sz + 1 \u0026gt;= k) return tp; return kth(n.ch[1], k - sz - 1); } data getsum(int\u0026amp; tp, int l, int r) { if (tp == 0 || l \u0026gt;= r) return 0; node\u0026amp; n = nodes[tp]; int sz = nodes[n.ch[0]].sz + 1; if (l \u0026lt;= 1 \u0026amp;\u0026amp; r \u0026gt; n.sz) { return n.sum; } else { pushdown(tp); data sum = 0; if (l \u0026lt;= sz \u0026amp;\u0026amp; sz \u0026lt; r) { sum = nodes[tp].d; } sum = sum + getsum(n.ch[0], l, min(sz, r)); sum = sum + getsum(n.ch[1], max(1, l - sz), r - sz); return sum; } } void range_add(int\u0026amp; tp, int l, int r, const data\u0026amp; d) { if (tp == 0 || l \u0026gt;= r) return; node\u0026amp; n = nodes[tp]; int sz = nodes[n.ch[0]].sz + 1; if (l \u0026lt;= 1 \u0026amp;\u0026amp; r \u0026gt; n.sz) { _add(tp, d); } else { //pushdown(tp); if (l \u0026lt;= sz \u0026amp;\u0026amp; sz \u0026lt; r) { nodes[tp].d = nodes[tp].d + d; } nodes[tp].sum = nodes[tp].sum + d * (r - l); range_add(n.ch[0], l, min(sz, r), d); range_add(n.ch[1], max(1, l - sz), r - sz, d); } } // interface void init(int size) { nodes.clear(); recycle.clear(); nodes.reserve(size + 1); nodes.push_back(node(0)); root = 0; reserve_size = size; } T get(int id) { return nodes[id].d; } int size() { return nodes[root].sz; } int insert(int k, data v) { reserve(); return insert(root, k, v); } int erase(int k) { return erasefind(root, k); } int kth(int k) { return kth(root, k); } // return id T getsum(int l, int r) { return getsum(root, l, r + 1); } void range_add(int l, int r, data v) { range_add(root, l, r + 1, v); } };  Splay tree 使用以上这个Treap的自由度还是不够好，有些操作还是不容易做，例如区间翻转，或者区间删除。所以我们需要一个功能更为强大的树，因为那个随机数的限制，不能任意节点都能当树根，而没有那个随机数字段的树，就是伸展树Splay tree，区别主要是三个地方，一是需要父节点字段，维护关系时常数更大，二是旋转，使用双旋，三是splay操作，作用是把节点提升到树根。这个splay操作就是神器，能把很多区间操作写得非常简单，代码也确实是目前介绍的树里面代码最少的。不过伸展树的缺点是编码理解难度稍大。\n和其它树的不同点是，为了保证区间操作代码简短，初始化的时候直接插入两个元素作为序列的一头一尾，于是实际操作区间是2到n+1，这个细节要注意，有了这两个元素可以减少很多特判操作。例如说，要找区间[l,r]，那么只要让位置r+1的元素splay到根，然后再让位置l-1的元素splay到根的左边，那么l-1位的元素的右子树就是整个操作区间了，而为了让这个总是能做，所以才要预先加两个元素。这个技巧用在了几乎所有操作里面，包括插入，删除，所有的区间操作。splay操作的时间复杂度 $O(logn)$\n以下是序列维护用的基本splaytree模板，要改成支持区间求和什么的就自己改吧。\ntemplate\u0026lt;typename T\u0026gt; struct splaytree_seq { struct data { T v; data(int _v = 0) :v(_v) {} operator T() const { return v; } }; struct node { int ch[2], fa, sz; data d; node(int z = 1) :sz(z) { ch[0] = ch[1] = fa = 0; } }; vector\u0026lt;node\u0026gt; nodes; int root; int recyc; int reserve_size; void reserve() { if (size() \u0026gt;= reserve_size) nodes.reserve((reserve_size *= 2) + 1); } inline int\u0026amp; ch(int tp, int r) { return nodes[tp].ch[r]; } inline int\u0026amp; fa(int tp) { return nodes[tp].fa; } inline int rch(int tp) { return ch(fa(tp), 1) == tp; } int new_node() { int id = (int)nodes.size(); if (recyc) { id = recyc; if (ch(recyc, 0) \u0026amp;\u0026amp; ch(recyc, 1)) recyc = merge(ch(recyc, 0), ch(recyc, 1)); else recyc = ch(recyc, 0) ? ch(recyc, 0) : ch(recyc, 1); fa(recyc) = 0; nodes[id] = node(); } else nodes.push_back(node()); return id; } void update(int tp) { node\u0026amp; n = nodes[tp]; n.sz = 1 + nodes[n.ch[0]].sz + nodes[n.ch[1]].sz; } void add(int tp, const data\u0026amp; d) { node\u0026amp; n = nodes[tp]; n.d = n.d + d; } void rotate(int s) { int f1 = fa(s), f2 = fa(f1); int d1 = rch(s), d2 = rch(f1); ch(f2, d2) = s; fa(s) = f2; fa(ch(s, d1 ^ 1)) = f1; ch(f1, d1) = ch(s, d1 ^ 1); fa(f1) = s; ch(s, d1 ^ 1) = f1; update(f1); update(s); } void splay(int tp, int goal = 0) { for (int f; (f = fa(tp)) != goal; rotate(tp)) if (fa(f) != goal) rotate(rch(tp) == rch(f) ? f : tp); if (!goal) root = tp; } int find_m(int tp, int r) { int p = tp; while (ch(p, r)) p = ch(p, r); if (p != tp) splay(p, tp); return p; } int merge(int tl, int tr) { if (!tl) { fa(tr) = 0; return tr; } if (!tr) { fa(tl) = 0; return tl; } int p = find_m(tl, 1); ch(p, 1) = tr; fa(tr) = p; return tl; } void insert(int k, const data\u0026amp; d) { int tp = new_node(); splay(kth(root, k + 1)); splay(kth(root, k), root); int c = ch(root, 0); nodes[c].ch[1] = tp; nodes[tp].fa = c; nodes[tp].d = d; update(c); update(root); } void remove(int\u0026amp; tp) { fa(tp) = 0; if (recyc == 0) recyc = tp; else recyc = merge(recyc, tp); tp = 0; } int kth(int tp, int k) { if (tp == 0) return tp; node\u0026amp; n = nodes[tp]; //pushdown(tp); int sz = nodes[n.ch[0]].sz + 1; if (sz \u0026gt; k) return kth(n.ch[0], k); if (sz \u0026gt;= k) return tp; return kth(n.ch[1], k - sz); } // interface void init(int size) { nodes.clear(); nodes.reserve((size = max(size, 15)) + 1); nodes.push_back(node(0)); nodes.push_back(node()); nodes.push_back(node()); nodes[1].ch[0] = 2; nodes[1].sz = 2; nodes[2].fa = 1; root = 1; // be the bound recyc = 0; reserve_size = size + 1; } T get(int id) { return nodes[id].d; } int size() { return nodes[root].sz - 2; } int kth(int k) { int id = kth(root, k + 1); splay(id); return id; } void erase(int l, int r) { splay(kth(root, r + 2)); splay(kth(root, l), root); remove(ch(ch(root, 0), 1)); update(ch(root, 0)); update(root); } void range_add(int l, int r, data v) { splay(kth(root, r + 2)); splay(kth(root, l), root); add(ch(ch(root, 0), 1), v); update(ch(root, 0)); update(root); } };  以上已经直接写好了区间删除，对于区间反转等操作，可以模仿线段树加懒惰标记即可。\n","date":1576213800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576213800,"objectID":"31f3512e84b016b73e8fd4709aa87898","permalink":"/post/20191213-tree-sequence/","publishdate":"2019-12-13T13:10:00+08:00","relpermalink":"/post/20191213-tree-sequence/","section":"post","summary":"平衡树除了用来对存在偏序关系的数据进行维护，还能用于对序列维护，相当于一个数组。阅读本文你需要先看完上一篇关于treap的文章。\n序列维护 在之前的文章，我们介绍过使用树状数组，以及线段树来维护一个序列，可以做区间操作及区间求和，但它们都存在一个缺点，不能动态插入数据。那我们怎么样才能通过平衡树来维护序列呢，之前我们有一个size字段能快速找第k大（或树的中序遍历第k个元素），而旋转操作并不会改变元素之间的相对顺序，那么我们就通过它直接插入到第k个元素的前面，这样我们插入的时候就不再通过要插入的值本身的大小关系，而需要多加一个参数k决定插入的位置。当平衡树用于维护序列的时候，就不用考虑元素相等的问题了。这样我们把元素相等处理的代码删除并修改基本操作的代码就能得到第一个能维护序列的基本模板，以下模板使用Treap修改得来。\n","tags":["数据结构","Treap","SplayTree","模板","c++"],"title":"平衡树与序列维护","type":"post"},{"authors":null,"categories":["研究"],"content":"这里之所以把这两个放在一起讲，是因为它们实在是相似度很高（至少在竞赛领域），都需要求kth和指定元素的rank（Treap的话可有可无，但通常会需要）。不过如果你没有写过树，强烈建议你自己通过理解来写一遍。\nBST 首先，Treap和SBT都属于BST的一种，BST就是二叉搜索树，它满足的特点是：\n 二叉树 没有两个节点的值相等 任意子树的根节点的值都比左子树所有节点的值要大 任意子树的根节点的值都比右子树所有节点的值要小 任意子树均为二叉搜索树  如果我们实在需要支持多个相同值放在树里面，那么有两种情况，如果那些相同值是确实完全没有区别（例如int），那么只需要在每个节点多加一个字段记录这个值出现的次数就可以了，但如果这些值只有偏序关系，可能不是严格相等，存在其它非比较字段，那么我们就再在每个节点增加一个next域做成一个链表即可。\n基本操作\n 插入(insert)：对比子树的根节点的值r与插入的值v，如果v与r相等，根节点重复数量+1，如果v小于r，插入到左子树，v大于r则插入到右子树 查找(find)：和插入相似，值相等时返回其id 删除(erase)：先查找，找到的时候，再查找它的后继（右子树的最小），用后继元素替换后再删除原后继  支持简单重复元素的BST模板 这个模板还添加了size域，用于求第k小元素和元素排名\nstruct bst { struct data { int v; data(int _v = 0) :v(_v) {} bool operator==(const data\u0026amp; d) const { return v == d.v; } bool operator\u0026lt;(const data\u0026amp; d) const { return v \u0026lt; d.v; } }; struct node { int ch[2], sz, dup; data d; node(int z = 1) :sz(z), dup(z) { ch[0] = ch[1] = 0; } }; vector\u0026lt;node\u0026gt; nodes; vector\u0026lt;int\u0026gt; recycle; int root; int reserve_size; void reserve() { if (size() \u0026gt;= reserve_size) nodes.reserve((reserve_size *= 2) + 1); } int new_node() { int id = (int)nodes.size(); if (!recycle.empty()) { id = recycle.back(); recycle.pop_back(); nodes[id] = node(); } else nodes.push_back(node()); return id; } int insert(int\u0026amp; tp, const data\u0026amp; d) { if (tp == 0) { tp = new_node(); nodes[tp].d = d; return tp; } node\u0026amp; n = nodes[tp]; ++n.sz; if (d == n.d) { ++n.dup; return tp; } int r = d \u0026lt; n.d; int\u0026amp; s = n.ch[r ^ 1]; int ret = insert(s, d); return ret; } int find(int tp, const data\u0026amp; d) // return id { if (tp == 0) return 0; if (d == nodes[tp].d) return tp; return find(nodes[tp].ch[(d \u0026lt; nodes[tp].d) ^ 1], d); } int erasefind(int\u0026amp; tp, const data\u0026amp; d) // return deleted { if (tp == 0) return 0; if (d == nodes[tp].d) { --nodes[tp].sz; if (--nodes[tp].dup \u0026lt;= 0) remove(tp); return 1; } if (erasefind(nodes[tp].ch[(d \u0026lt; nodes[tp].d) ^ 1], d)) { --nodes[tp].sz; return 1; } return 0; } void remove(int\u0026amp; tp) { if (tp == 0) return; if (!nodes[tp].ch[0] || !nodes[tp].ch[1]) { recycle.push_back(tp); tp = nodes[tp].ch[!nodes[tp].ch[0]]; } else { int nxt = nodes[tp].ch[1]; while (nodes[nxt].ch[0]) nxt = nodes[nxt].ch[0]; int dup = nodes[nxt].dup; nodes[tp].d = nodes[nxt].d; nodes[tp].dup = nodes[nxt].dup; recycle.push_back(nxt); int* tmp = \u0026amp;nodes[tp].ch[1]; while (nodes[*tmp].ch[0]) { nodes[*tmp].sz -= dup; tmp = \u0026amp;nodes[*tmp].ch[0]; } *tmp = nodes[*tmp].ch[1]; } } int kth(int tp, int k) // return id { node\u0026amp; n = nodes[tp]; int sz = nodes[n.ch[0]].sz; if (sz \u0026gt;= k) return kth(n.ch[0], k); if (sz + n.dup \u0026gt;= k) return tp; return kth(n.ch[1], k - sz - n.dup); } int rank(int tp, const data\u0026amp; d, int dup) { if (tp == 0) return 1; node\u0026amp; n = nodes[tp]; if (d == n.d) return nodes[n.ch[0]].sz + 1 + dup * n.dup; else if (d \u0026lt; n.d) return rank(n.ch[0], d, dup); return rank(n.ch[1], d, dup) + nodes[n.ch[0]].sz + n.dup; } // interface void init(int size) { nodes.clear(); recycle.clear(); nodes.reserve(size + 1); nodes.push_back(node(0)); root = 0; reserve_size = size; } int get(int id) { return nodes[id].d.v; } int size() { return nodes[root].sz; } int insert(data v) { reserve(); return insert(root, v); } int erase(data v) { return erasefind(root, v); } int find(data v) { return find(root, v); } // return id int kth(int k) { return kth(root, k); } // return id // upperbound when upper = 1 int rank(data v, int upper = 0) { return rank(root, v, upper); } };  一些说明 子节点用的节段是ch数组(child的缩写)，不使用left和right的原因是为了节省代码，例如在insert函数里，通过计算d \u0026lt; n.d的值是0或1决定下一步是递归调用左还是右子节点的时候，就不需要分别针对left和right写代码，后面的find和erase同理。\nrank函数在upper为0的时候，找到的是相同元素里面最小的排名，如果v不存在树里面，那么就是v假如要插入到树里的排名。upper为1的时候，找到的是大于v的最小的元素的排名，即v的后继。\nkth函数的参数如果非法，会导致无限循环，如果你想避免那么你可以在函数里添加检查，例如加一句if (tp == 0) return 0;即可。\n优化BST 单纯的BST最大的问题是，它最坏的情况是可能成为一条链表，例如你按从小到大插入到树里面的时候，缺乏让它缩减树高的机制，所以接下来要讲两个非常重要的操作，就是树的旋转\n图A\ngraph TD; 4--\u0026gt;2 2--\u0026gt;1 2--\u0026gt;3 4--\u0026gt;6  图B\ngraph TD; 2--\u0026gt;4 4--\u0026gt;3 2--\u0026gt;1 4--\u0026gt;6  以上两图，从A到B叫做zig，把左儿子旋转到root的位置，也叫右旋，B到A叫做zag，把右儿子旋转到root的位置，也叫左旋，旋转代码也很简单\nvoid rotate(int\u0026amp; tp, int r) { node\u0026amp; n = nodes[tp]; int s = n.ch[r]; n.ch[r] = nodes[s].ch[r ^ 1]; nodes[s].ch[r ^ 1] = tp; tp = s; }  以上参数r如果是0，就是zig，r是1就是zag。有了旋转操作，我们就可以开始看自平衡树了。\nTreap Treap其实炒鸡简单，在BST的基础上多一个随机数生成的字段，这个字段用于决定树要怎么旋转。这个字段就是个优先级，父节点的优先级不大于两个子节点的优先级，这其实就是heap，所以，Treap就是树堆（Tree-heap）。维护Treap，我们只需要在insert的时候，检查是不是满足heap，如果不满足就旋转，相对BST只加了非常少的代码，也就加了rotate函数，rnd函数（直接用rand也行），insert加了维护，以及旋转时需要的update函数维护size字段，也就是说Treap是最经济实惠的平衡树。\n操作：\n 更新(update): 累加左右子树的size 删除(erase): 找到要删除的元素后，对比两子树的根的优先级，把较的小旋转到原来要删除的元素的位置，使要删除的元素的深度+1，直到删除的元素没有两个子树为止\nstruct treap { struct data { int v; data(int _v = 0) :v(_v) {} bool operator==(const data\u0026amp; d) const { return v == d.v; } bool operator\u0026lt;(const data\u0026amp; d) const { return v \u0026lt; d.v; } }; struct node { int ch[2], sz, dup; unsigned k; data d; node(int z = 1) :sz(z), dup(z), k(rnd()) { ch[0] = ch[1] = 0; } static unsigned rnd() { static unsigned r = 0x123; r = r * 69069 + 1; return r; } }; vector\u0026lt;node\u0026gt; nodes; vector\u0026lt;int\u0026gt; recycle; int root; int reserve_size; void reserve() { if (size() \u0026gt;= reserve_size) nodes.reserve((reserve_size *= 2) + 1); } int new_node() { int id = (int)nodes.size(); if (!recycle.empty()) { id = recycle.back(); recycle.pop_back(); nodes[id] = node(); } else nodes.push_back(node()); return id; } void update(int tp) { node\u0026amp; n = nodes[tp]; n.sz = n.dup + nodes[n.ch[0]].sz + nodes[n.ch[1]].sz; } int insert(int\u0026amp; tp, const data\u0026amp; d) { if (tp == 0) { tp = new_node(); nodes[tp].d = d; return tp; } node\u0026amp; n = nodes[tp]; ++n.sz; if (d == n.d) { ++n.dup; return tp; } int r = d \u0026lt; n.d; int\u0026amp; s = n.ch[r ^ 1]; int ret = insert(s, d); if (nodes[s].k \u0026lt; n.k) rotate(tp, r ^ 1), update(tp); return ret; } void rotate(int\u0026amp; tp, int r) { node\u0026amp; n = nodes[tp]; int s = n.ch[r]; n.ch[r] = nodes[s].ch[r ^ 1]; nodes[s].ch[r ^ 1] = tp; update(tp); tp = s; } int find(int tp, const data\u0026amp; d) // return id { if (tp == 0) return 0; if (d == nodes[tp].d) return tp; return find(nodes[tp].ch[(d \u0026lt; nodes[tp].d) ^ 1], d); } int erasefind(int\u0026amp; tp, const data\u0026amp; d) // return deleted { if (tp == 0) return 0; if (d == nodes[tp].d) { --nodes[tp].sz; if (--nodes[tp].dup \u0026lt;= 0) remove(tp); return 1; } if (erasefind(nodes[tp].ch[(d \u0026lt; nodes[tp].d) ^ 1], d)) { --nodes[tp].sz; return 1; } return 0; } void remove(int\u0026amp; tp) { if (tp == 0) return; if (!nodes[tp].ch[0] || !nodes[tp].ch[1]) { recycle.push_back(tp); tp = nodes[tp].ch[!nodes[tp].ch[0]]; } else { int r = nodes[nodes[tp].ch[0]].k \u0026lt; nodes[nodes[tp].ch[1]].k; rotate(tp, r ^ 1); remove(nodes[tp].ch[r]); update(tp); } } int kth(int tp, int k) // return id { node\u0026amp; n = nodes[tp]; int sz = nodes[n.ch[0]].sz; if (sz \u0026gt;= k) return kth(n.ch[0], k); if (sz + n.dup \u0026gt;= k) return tp; return kth(n.ch[1], k - sz - n.dup); } int rank(int tp, const data\u0026amp; d, int dup) { if (tp == 0) return 1; node\u0026amp; n = nodes[tp]; if (d == n.d) return nodes[n.ch[0]].sz + 1 + dup * n.dup; else if (d \u0026lt; n.d) return rank(n.ch[0], d, dup); return rank(n.ch[1], d, dup) + nodes[n.ch[0]].sz + n.dup; } // interface void init(int size) { nodes.clear(); recycle.clear(); nodes.reserve(size + 1); nodes.push_back(node(0)); root = 0; reserve_size = size; } int get(int id) { return nodes[id].d.v; } int size() { return nodes[root].sz; } int insert(data v) { reserve(); return insert(root, v); } int erase(data v) { return erasefind(root, v); } int find(data v) { return find(root, v); } // return id int kth(int k) { return kth(root, k); } // return id // upperbound when upper = 1 int rank(data v, int upper = 0) { return rank(root, v, upper); } };   SBT 这个名字和BST特别像，但它全名是Size Balanced Tree，作者是CQF，它通过size字段来进行树平衡。它的关键操作叫做maintain，这个操作的平摊复杂度是 $O(1)$ ，这货具体解释可以看CQF的论文，SBT的时间常数比Treap更小一些，内存也更小，不过代码也稍长一些（就是因为maintain）\nstruct sbt { struct data { int v; data(int _v = 0) :v(_v) {} bool operator==(const data\u0026amp; d) const { return v == d.v; } bool operator\u0026lt;(const data\u0026amp; d) const { return v \u0026lt; d.v; } }; struct node { int ch[2], sz, dup; data d; node(int z = 1) :sz(z), dup(z) { ch[0] = ch[1] = 0; } }; vector\u0026lt;node\u0026gt; nodes; vector\u0026lt;int\u0026gt; recycle; int root; int reserve_size; void reserve() { if (size() \u0026gt;= reserve_size) nodes.reserve((reserve_size *= 2) + 1); } int new_node() { int id = (int)nodes.size(); if (!recycle.empty()) { id = recycle.back(); recycle.pop_back(); nodes[id] = node(); } else nodes.push_back(node()); return id; } void update(int tp) { node\u0026amp; n = nodes[tp]; n.sz = n.dup + nodes[n.ch[0]].sz + nodes[n.ch[1]].sz; } int insert(int\u0026amp; tp, const data\u0026amp; d) { if (tp == 0) { tp = new_node(); nodes[tp].d = d; return tp; } node\u0026amp; n = nodes[tp]; ++n.sz; if (d == n.d) { ++n.dup; return tp; } int r = d \u0026lt; n.d; int\u0026amp; s = n.ch[r ^ 1]; int ret = insert(s, d); maintain(tp, r ^ 1); return ret; } void rotate(int\u0026amp; tp, int r) { node\u0026amp; n = nodes[tp]; int s = n.ch[r]; n.ch[r] = nodes[s].ch[r ^ 1]; nodes[s].ch[r ^ 1] = tp; update(tp); update(s); tp = s; } void maintain(int\u0026amp; tp, int s) { if (tp == 0) return; if (nodes[nodes[nodes[tp].ch[s]].ch[s]].sz \u0026gt; nodes[nodes[tp].ch[s ^ 1]].sz) rotate(tp, s); else if (nodes[nodes[nodes[tp].ch[s]].ch[s ^ 1]].sz \u0026gt; nodes[nodes[tp].ch[s ^ 1]].sz) { rotate(nodes[tp].ch[s], s ^ 1); rotate(tp, s); } else return; maintain(nodes[tp].ch[s], s); maintain(nodes[tp].ch[s ^ 1], s ^ 1); maintain(tp, s); maintain(tp, s ^ 1); } int find(int tp, const data\u0026amp; d) // return id { if (tp == 0) return 0; if (d == nodes[tp].d) return tp; return find(nodes[tp].ch[(d \u0026lt; nodes[tp].d) ^ 1], d); } int erasefind(int\u0026amp; tp, const data\u0026amp; d) // return deleted { if (tp == 0) return 0; if (d == nodes[tp].d) { --nodes[tp].sz; if (--nodes[tp].dup \u0026lt;= 0) remove(tp); return 1; } if (erasefind(nodes[tp].ch[(d \u0026lt; nodes[tp].d) ^ 1], d)) { --nodes[tp].sz; return 1; } return 0; } void remove(int\u0026amp; tp) { if (tp == 0) return; if (!nodes[tp].ch[0] || !nodes[tp].ch[1]) { recycle.push_back(tp); tp = nodes[tp].ch[!nodes[tp].ch[0]]; } else { int r = nodes[nodes[tp].ch[0]].sz \u0026gt;= nodes[nodes[tp].ch[1]].sz; rotate(tp, r ^ 1); remove(nodes[tp].ch[r]); update(tp); } } int kth(int tp, int k) // return id { node\u0026amp; n = nodes[tp]; int sz = nodes[n.ch[0]].sz; if (sz \u0026gt;= k) return kth(n.ch[0], k); if (sz + n.dup \u0026gt;= k) return tp; return kth(n.ch[1], k - sz - n.dup); } int rank(int tp, const data\u0026amp; d, int dup) { if (tp == 0) return 1; node\u0026amp; n = nodes[tp]; if (d == n.d) return nodes[n.ch[0]].sz + 1 + dup * n.dup; else if (d \u0026lt; n.d) return rank(n.ch[0], d, dup); return rank(n.ch[1], d, dup) + nodes[n.ch[0]].sz + n.dup; } // interface void init(int size) { nodes.clear(); recycle.clear(); nodes.reserve(size + 1); nodes.push_back(node(0)); root = 0; reserve_size = size; } int get(int id) { return nodes[id].d.v; } int size() { return nodes[root].sz; } int insert(data v) { reserve(); return insert(root, v); } int erase(data v) { return erasefind(root, v); } int find(data v) { return find(root, v); } // return id int kth(int k) { return kth(root, k); } // return id // upperbound when upper = 1 int rank(data v, int upper = 0) { return rank(root, v, upper); } };  温馨提示 别看代码长，如果你还没自己实现过，硬着头皮写一次，你就懂了，核心其实只有那么点。以上没有实现插入相等元素后用链表串起来，实在有需要时自己加一下就好了。又或者，如果你不需要处理相同元素，那么代码也有不少的简化，特别是删除元素的地方。\n","date":1576041000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576041000,"objectID":"77ff0ddaa1e03838893c9e88b92e4d60","permalink":"/post/20191211-treap-sbt/","publishdate":"2019-12-11T13:10:00+08:00","relpermalink":"/post/20191211-treap-sbt/","section":"post","summary":"这里之所以把这两个放在一起讲，是因为它们实在是相似度很高（至少在竞赛领域），都需要求kth和指定元素的rank（Treap的话可有可无，但通常会需要）。不过如果你没有写过树，强烈建议你自己通过理解来写一遍。\nBST 首先，Treap和SBT都属于BST的一种，BST就是二叉搜索树，它满足的特点是：\n 二叉树 没有两个节点的值相等 任意子树的根节点的值都比左子树所有节点的值要大 任意子树的根节点的值都比右子树所有节点的值要小 任意子树均为二叉搜索树  如果我们实在需要支持多个相同值放在树里面，那么有两种情况，如果那些相同值是确实完全没有区别（例如int），那么只需要在每个节点多加一个字段记录这个值出现的次数就可以了，但如果这些值只有偏序关系，可能不是严格相等，存在其它非比较字段，那么我们就再在每个节点增加一个next域做成一个链表即可。\n","tags":["数据结构","BST","Treap","SBT","模板","c++"],"title":"Treap与SBT","type":"post"},{"authors":null,"categories":["研究"],"content":"很多人在初始接触线段树的时候，一看到别人写一大堆代码就直接弃坑了，其实不要被它的外表所欺骗，线段树其实是相当好写的树结构了，而且理解起来其实很简单。要学会这个，你不能光会抄模板就会区间修改和求个区间和，因为实际应用经常会使用它的变形，还是在于理解（理解后背板）。\n数据结构 首先，回想一下heap的结构，它使用一个数组，同时使用下标本身来表达父子关系，这样的方式能节省大量指针所需要的内存空间，以下也使用这种表示方法来表示一棵线段树，也就是说，这里介绍的，属于狭义线段树。假设我们的数据是以下这样\n   下标 1 2 3 4 5 6 7 8     数据 1 0 5 2 3 4 0 1    构建线段树后结果如下\ngraph TD; 1,8:16--\u0026gt;1,4:8 1,8:16--\u0026gt;5,8:8 1,4:8--\u0026gt;1,2:1 1,4:8--\u0026gt;3,4:7 1,2:1--\u0026gt;1,1:1 1,2:1--\u0026gt;2,2:0 3,4:7--\u0026gt;3,3:5 3,4:7--\u0026gt;4,4:2 5,8:8--\u0026gt;5,6:7 5,8:8--\u0026gt;7,8:1 5,6:7--\u0026gt;5,5:3 5,6:7--\u0026gt;6,6:4 7,8:1--\u0026gt;7,7:0 7,8:1--\u0026gt;8,8:1  冒号前面的两个数表示一条线段，冒号后表示的是数据，这个数据表示的是这个区间的和。如此一来，我们查询一个区间的和，可以很快地计算出来，例如求[1,6]的和，那么需要拆分为[1,4]与[5,6]的和，分别是8和7，所以结果是8+7=15，原理就是这样而已。\n单点数据更新 单点更新时，可以参考树状数组，先更新子节点，然后向上找父节点更新即可，也可以递归实现，这不在本节讨论范围。不过如果你确实只需要单点修改，那么可以考虑ZKW线段树，ZKW线段树是先更新子节点，然后向上找父节点更新，由于少了很多递归，常数比递归的线段树要小。后文提供一个简易的模板作为参考。\n区间数据更新 例如，我们希望对区间[3,5]上的数都加上2，这时候需要引入懒惰标记，其实就是把操作记录在父节点上，有必要时再向下传递。像刚才的例子，都加上懒惰标记后\ngraph TD; 1,8:16,0--\u0026gt;1,4:8,0 1,8:16,0--\u0026gt;5,8:8,0 1,4:8,0--\u0026gt;1,2:1,0 1,4:8,0--\u0026gt;3,4:7,0 1,2:1,0--\u0026gt;1,1:1,0 1,2:1,0--\u0026gt;2,2:0,0 3,4:7,0--\u0026gt;3,3:5,0 3,4:7,0--\u0026gt;4,4:2,0 5,8:8,0--\u0026gt;5,6:7,0 5,8:8,0--\u0026gt;7,8:1,0 5,6:7,0--\u0026gt;5,5:3,0 5,6:7,0--\u0026gt;6,6:4,0 7,8:1,0--\u0026gt;7,7:0,0 7,8:1,0--\u0026gt;8,8:1,0  然后对区间[3,5]上的数都加上2，那么把这个区间拆分为[3,4]和[5,5]，更新标记\ngraph TD; 1,8:16,0--\u0026gt;1,4:8,0 1,8:16,0--\u0026gt;5,8:8,0 1,4:8,0--\u0026gt;1,2:1,0 1,4:8,0--\u0026gt;3,4:11,2 1,2:1,0--\u0026gt;1,1:1,0 1,2:1,0--\u0026gt;2,2:0,0 3,4:11,2--\u0026gt;3,3:5,0 3,4:11,2--\u0026gt;4,4:2,0 5,8:8,0--\u0026gt;5,6:7,0 5,8:8,0--\u0026gt;7,8:1,0 5,6:7,0--\u0026gt;5,5:5,2 5,6:7,0--\u0026gt;6,6:4,0 7,8:1,0--\u0026gt;7,7:0,0 7,8:1,0--\u0026gt;8,8:1,0  也就是说，[3,3]和[4,4]都没有更新，更新在[3,4]上了，那么接下来需要查询[3,3]的话，就把标记向下传递一层，变成\ngraph TD; 1,8:16,0--\u0026gt;1,4:8,0 1,8:16,0--\u0026gt;5,8:8,0 1,4:8,0--\u0026gt;1,2:1,0 1,4:8,0--\u0026gt;3,4:11,0 1,2:1,0--\u0026gt;1,1:1,0 1,2:1,0--\u0026gt;2,2:0,0 3,4:11,0--\u0026gt;3,3:7,2 3,4:11,0--\u0026gt;4,4:4,2 5,8:8,0--\u0026gt;5,6:7,0 5,8:8,0--\u0026gt;7,8:1,0 5,6:7,0--\u0026gt;5,5:5,2 5,6:7,0--\u0026gt;6,6:4,0 7,8:1,0--\u0026gt;7,7:0,0 7,8:1,0--\u0026gt;8,8:1,0  这样，再获取区间[3,3]的结果7，就是所需要的答案\n基础模板 以下基础模板只支持区间求和，以及区间整体加上一个数的操作，和树状数组后面提供的模板实现了相同的功能\nstruct seg_tree_add { struct node { int sum; int lz_add; }; int sz; vector\u0026lt;node\u0026gt; d; // 仿heap的形式保存线段树 inline int lson(int tp) { return tp * 2 + 1; } inline int rson(int tp) { return tp * 2 + 2; } // 当前tp节点对应的线段区间为[tl,tr]，更新区间是[l,r] void update_add(int l, int r, int v, int tl, int tr, int tp) { if (l \u0026lt;= tl \u0026amp;\u0026amp; tr \u0026lt;= r) { d[tp].sum += (tr - tl + 1) * v; d[tp].lz_add = v; return; } int tmid = (tl + tr) / 2; // 下发lazy标志一层 if (d[tp].lz_add != 0) { update_add(tl, tmid, d[tp].lz_add, tl, tmid, lson(tp)); update_add(tmid + 1, tr, d[tp].lz_add, tmid + 1, tr, rson(tp)); d[tp].lz_add = 0; } // 更新左右儿子 if (l \u0026lt;= tmid) update_add(l, r, v, tl, tmid, lson(tp)); if (r \u0026gt; tmid) update_add(l, r, v, tmid + 1, tr, rson(tp)); d[tp].sum = d[lson(tp)].sum + d[rson(tp)].sum; } int get_sum(int l, int r, int tl, int tr, int tp) { if (l \u0026lt;= tl \u0026amp;\u0026amp; tr \u0026lt;= r) { return d[tp].sum; } int tmid = (tl + tr) / 2; // 下发lazy标志一层 if (d[tp].lz_add != 0) { update_add(tl, tmid, d[tp].lz_add, tl, tmid, lson(tp)); update_add(tmid + 1, tr, d[tp].lz_add, tmid + 1, tr, rson(tp)); d[tp].lz_add = 0; } // 统计左右儿子 int sum = 0; if (l \u0026lt;= tmid) sum += get_sum(l, r, tl, tmid, lson(tp)); if (r \u0026gt; tmid) sum += get_sum(l, r, tmid + 1, tr, rson(tp)); return sum; } void init(int size) // 可操作下标范围为0~size-1，如需要从1开始那么要+1 { sz = size; while (sz \u0026amp; (sz - 1)) sz += sz\u0026amp;-sz; // 扩展为满二叉树 d.resize(sz * 2); } void update_add(int l, int r, int v) { update_add(l, r, v, 0, sz - 1, 0); } int get_sum(int l, int r) { return get_sum(l, r, 0, sz - 1, 0); } };  用法，调用init初始化范围（注意下标从0到size-1，下标要从1开始的话要size+1，否则如果size正好是2的k次方时操作下标为size时会出问题），然后通过update_add和get_sum更新数据即可。\n另外一点，这个模板实现没有使用左闭右开区间来写，如果改用左闭右开区间，并添加build实现，则得到如下实现（代码有少许简化且更对称更好读）\nstruct seg_tree_add { struct node { int sum; int lz_add; }; int sz; vector\u0026lt;node\u0026gt; d; inline int lson(int tp) { return tp * 2 + 1; } inline int rson(int tp) { return tp * 2 + 2; } void update_add(int l, int r, int v, int tl, int tr, int tp) { if (l \u0026lt;= tl \u0026amp;\u0026amp; tr \u0026lt;= r) { d[tp].sum += (tr - tl) * v; d[tp].lz_add = v; return; } int tmid = (tl + tr) / 2; // 下发lazy标志一层 if (d[tp].lz_add != 0) { update_add(tl, tmid, d[tp].lz_add, tl, tmid, lson(tp)); update_add(tmid, tr, d[tp].lz_add, tmid, tr, rson(tp)); d[tp].lz_add = 0; } // 更新左右儿子 if (l \u0026lt; tmid) update_add(l, r, v, tl, tmid, lson(tp)); if (r \u0026gt; tmid) update_add(l, r, v, tmid, tr, rson(tp)); d[tp].sum = d[lson(tp)].sum + d[rson(tp)].sum; } int get_sum(int l, int r, int tl, int tr, int tp) { if (l \u0026lt;= tl \u0026amp;\u0026amp; tr \u0026lt;= r) { return d[tp].sum; } int tmid = (tl + tr) / 2; // 下发lazy标志一层 if (d[tp].lz_add != 0) { update_add(tl, tmid, d[tp].lz_add, tl, tmid, lson(tp)); update_add(tmid, tr, d[tp].lz_add, tmid, tr, rson(tp)); d[tp].lz_add = 0; } // 统计左右儿子 int sum = 0; if (l \u0026lt; tmid) sum += get_sum(l, r, tl, tmid, lson(tp)); if (r \u0026gt; tmid) sum += get_sum(l, r, tmid, tr, rson(tp)); return sum; } void build(int a[], int alen, int tl, int tr, int tp) { if (tl + 1 == tr) { if (tl \u0026lt; alen) d[tp].sum = a[tl]; else d[tp].sum = 0; return; } int tmid = (tl + tr) / 2; build(a, alen, tl, tmid, lson(tp)); build(a, alen, tmid, tr, rson(tp)); d[tp].sum = d[lson(tp)].sum + d[rson(tp)].sum; d[tp].lz_add = 0; } void build(int a[], int alen) { build(a, alen, 0, sz, 0); } void init(int size) // 可操作下标范围为0~size-1 { sz = size; while (sz \u0026amp; (sz - 1)) sz += sz\u0026amp;-sz; d.resize(sz * 2); } void update_add(int l, int r, int v) { update_add(l, r + 1, v, 0, sz, 0); } int get_sum(int l, int r) { return get_sum(l, r + 1, 0, sz, 0); } };  进阶模板 如果你需要支持区间整体加上某个数，同时支持区间整体设置为指定数，那么就需要多重懒惰标记，模板可以改写如下（闭区间实现）\n   点击展开  \nstruct seg_tree { static const int lz_mark = 0x80000000; struct node { int sum; int lz_set; int lz_add; }; int sz; vector\u0026lt;node\u0026gt; d; inline int lson(int tp) { return tp * 2 + 1; } inline int rson(int tp) { return tp * 2 + 2; } void update_add(int l, int r, int v, int tl, int tr, int tp) { if (l \u0026lt;= tl \u0026amp;\u0026amp; tr \u0026lt;= r) { d[tp].sum += (tr - tl + 1) * v; if (d[tp].lz_set != lz_mark) d[tp].lz_set += v; else d[tp].lz_add = v; return; } int tmid = (tl + tr) / 2; // 下发lazy标志一层 if (d[tp].lz_set != lz_mark) { update_set(tl, tmid, d[tp].lz_set, tl, tmid, lson(tp)); update_set(tmid + 1, tr, d[tp].lz_set, tmid + 1, tr, rson(tp)); d[tp].lz_set = lz_mark; } else if (d[tp].lz_add != 0) { update_add(tl, tmid, d[tp].lz_add, tl, tmid, lson(tp)); update_add(tmid + 1, tr, d[tp].lz_add, tmid + 1, tr, rson(tp)); d[tp].lz_add = 0; } if (l \u0026lt;= tmid) update_add(l, r, v, tl, tmid, lson(tp)); if (r \u0026gt; tmid) update_add(l, r, v, tmid + 1, tr, rson(tp)); d[tp].sum = d[lson(tp)].sum + d[rson(tp)].sum; } void update_set(int l, int r, int v, int tl, int tr, int tp) { if (l \u0026lt;= tl \u0026amp;\u0026amp; tr \u0026lt;= r) { d[tp].sum = (tr - tl + 1) * v; //区间和 d[tp].lz_set = v; d[tp].lz_add = 0; return; } int tmid = (tl + tr) / 2; // 下发lazy标志一层 if (d[tp].lz_set != lz_mark) { update_set(tl, tmid, d[tp].lz_set, tl, tmid, lson(tp)); update_set(tmid + 1, tr, d[tp].lz_set, tmid + 1, tr, rson(tp)); d[tp].lz_set = lz_mark; } else if (d[tp].lz_add != 0) { update_add(tl, tmid, d[tp].lz_add, tl, tmid, lson(tp)); update_add(tmid + 1, tr, d[tp].lz_add, tmid + 1, tr, rson(tp)); d[tp].lz_add = 0; } if (l \u0026lt;= tmid) update_set(l, r, v, tl, tmid, lson(tp)); if (r \u0026gt; tmid) update_set(l, r, v, tmid + 1, tr, rson(tp)); d[tp].sum = d[lson(tp)].sum + d[rson(tp)].sum; } int get_sum(int l, int r, int tl, int tr, int tp) { if (l \u0026lt;= tl \u0026amp;\u0026amp; tr \u0026lt;= r) { return d[tp].sum; } int tmid = (tl + tr) / 2; // 下发lazy标志一层 if (d[tp].lz_set != lz_mark) { update_set(tl, tmid, d[tp].lz_set, tl, tmid, lson(tp)); update_set(tmid + 1, tr, d[tp].lz_set, tmid + 1, tr, rson(tp)); d[tp].lz_set = lz_mark; } else if (d[tp].lz_add != 0) { update_add(tl, tmid, d[tp].lz_add, tl, tmid, lson(tp)); update_add(tmid + 1, tr, d[tp].lz_add, tmid + 1, tr, rson(tp)); d[tp].lz_add = 0; } int sum = 0; if (l \u0026lt;= tmid) sum += get_sum(l, r, tl, tmid, lson(tp)); if (r \u0026gt; tmid) sum += get_sum(l, r, tmid + 1, tr, rson(tp)); return sum; } void init(int size) // 可操作下标范围为0~size-1 { sz = size; while (sz \u0026amp; (sz - 1)) sz += sz\u0026amp;-sz; d.resize(sz * 2); } void update_add(int l, int r, int v) { update_add(l, r, v, 0, sz - 1, 0); } void update_set(int l, int r, int v) { update_set(l, r, v, 0, sz - 1, 0); } int get_sum(int l, int r) { return get_sum(l, r, 0, sz - 1, 0); } };  \n左闭右开区间实现（接口为闭区间）\n   点击展开  \nstruct seg_tree { static const int lz_mark = 0x80000000; struct node { int sum; int lz_set; int lz_add; }; int sz; vector\u0026lt;node\u0026gt; d; inline int lson(int tp) { return tp * 2 + 1; } inline int rson(int tp) { return tp * 2 + 2; } void update_add(int l, int r, int v, int tl, int tr, int tp) { if (l \u0026lt;= tl \u0026amp;\u0026amp; tr \u0026lt;= r) { d[tp].sum += (tr - tl) * v; if (d[tp].lz_set != lz_mark) d[tp].lz_set += v; else d[tp].lz_add = v; return; } int tmid = (tl + tr) / 2; // 下发lazy标志一层 if (d[tp].lz_set != lz_mark) { update_set(tl, tmid, d[tp].lz_set, tl, tmid, lson(tp)); update_set(tmid, tr, d[tp].lz_set, tmid, tr, rson(tp)); d[tp].lz_set = lz_mark; } else if (d[tp].lz_add != 0) { update_add(tl, tmid, d[tp].lz_add, tl, tmid, lson(tp)); update_add(tmid, tr, d[tp].lz_add, tmid, tr, rson(tp)); d[tp].lz_add = 0; } if (l \u0026lt; tmid) update_add(l, r, v, tl, tmid, lson(tp)); if (r \u0026gt; tmid) update_add(l, r, v, tmid, tr, rson(tp)); d[tp].sum = d[lson(tp)].sum + d[rson(tp)].sum; } void update_set(int l, int r, int v, int tl, int tr, int tp) { if (l \u0026lt;= tl \u0026amp;\u0026amp; tr \u0026lt;= r) { d[tp].sum = (tr - tl) * v; //区间和 d[tp].lz_set = v; d[tp].lz_add = 0; return; } int tmid = (tl + tr) / 2; // 下发lazy标志一层 if (d[tp].lz_set != lz_mark) { update_set(tl, tmid, d[tp].lz_set, tl, tmid, lson(tp)); update_set(tmid, tr, d[tp].lz_set, tmid, tr, rson(tp)); d[tp].lz_set = lz_mark; } else if (d[tp].lz_add != 0) { update_add(tl, tmid, d[tp].lz_add, tl, tmid, lson(tp)); update_add(tmid, tr, d[tp].lz_add, tmid, tr, rson(tp)); d[tp].lz_add = 0; } if (l \u0026lt; tmid) update_set(l, r, v, tl, tmid, lson(tp)); if (r \u0026gt; tmid) update_set(l, r, v, tmid, tr, rson(tp)); d[tp].sum = d[lson(tp)].sum + d[rson(tp)].sum; } ll get_sum(int l, int r, int tl, int tr, int tp) { if (l \u0026lt;= tl \u0026amp;\u0026amp; tr \u0026lt;= r) { return d[tp].sum; } int tmid = (tl + tr) / 2; // 下发lazy标志一层 if (d[tp].lz_set != lz_mark) { update_set(tl, tmid, d[tp].lz_set, tl, tmid, lson(tp)); update_set(tmid, tr, d[tp].lz_set, tmid, tr, rson(tp)); d[tp].lz_set = lz_mark; } else if (d[tp].lz_add != 0) { update_add(tl, tmid, d[tp].lz_add, tl, tmid, lson(tp)); update_add(tmid, tr, d[tp].lz_add, tmid, tr, rson(tp)); d[tp].lz_add = 0; } int sum = 0; if (l \u0026lt; tmid) sum += get_sum(l, r, tl, tmid, lson(tp)); if (r \u0026gt; tmid) sum += get_sum(l, r, tmid, tr, rson(tp)); return sum; } void init(int size) // 可操作下标范围为0~size-1 { sz = size; while (sz \u0026amp; (sz - 1)) sz += sz\u0026amp;-sz; d.resize(sz * 2); } void update_add(int l, int r, int v) { update_add(l, r + 1, v, 0, sz, 0); } void update_set(int l, int r, int v) { update_set(l, r + 1, v, 0, sz, 0); } ll get_sum(int l, int r) { return get_sum(l, r + 1, 0, sz, 0); } };  \n简易区间最值模板（就是简易得只有查询，如果要支持更新就自己加上）\n   点击展开  \nstruct seg_tree { struct node { int max; int min; }; int sz; vector\u0026lt;node\u0026gt; d; inline int lson(int tp) { return tp * 2 + 1; } inline int rson(int tp) { return tp * 2 + 2; } int get_max(int l, int r, int tl, int tr, int tp) { if (l \u0026lt;= tl \u0026amp;\u0026amp; tr \u0026lt;= r) { return d[tp].max; } int tmid = (tl + tr) / 2; int ret = INT_MIN; if (l \u0026lt; tmid) ret = max(ret, get_max(l, r, tl, tmid, lson(tp))); if (r \u0026gt; tmid) ret = max(ret, get_max(l, r, tmid, tr, rson(tp))); return ret; } int get_min(int l, int r, int tl, int tr, int tp) { if (l \u0026lt;= tl \u0026amp;\u0026amp; tr \u0026lt;= r) { return d[tp].min; } int tmid = (tl + tr) / 2; int ret = INT_MAX; if (l \u0026lt; tmid) ret = min(ret, get_min(l, r, tl, tmid, lson(tp))); if (r \u0026gt; tmid) ret = min(ret, get_min(l, r, tmid, tr, rson(tp))); return ret; } void build(int a[], int alen, int tl, int tr, int tp) { if (tl + 1 == tr) { if (tl \u0026lt; alen) { d[tp].max = a[tl]; d[tp].min = a[tl]; } else { d[tp].max = 0; d[tp].min = 0; } return; } int tmid = (tl + tr) / 2; build(a, alen, tl, tmid, lson(tp)); build(a, alen, tmid, tr, rson(tp)); d[tp].max = max(d[lson(tp)].max, d[rson(tp)].max); d[tp].min = min(d[lson(tp)].min, d[rson(tp)].min); } void build(int a[], int alen) { build(a, alen, 0, sz, 0); } void init(int size) // 可操作下标范围为0~size-1 { sz = size; while (sz \u0026amp; (sz - 1)) sz += sz\u0026amp;-sz; d.resize(sz * 2); } int get_min(int l, int r) { return get_min(l, r + 1, 0, sz, 0); } int get_max(int l, int r) { return get_max(l, r + 1, 0, sz, 0); } };  \nZKW线段树模板 这是单点修改求区间和的模板，求区间最值稍微改改就好了，如果需要区间修改，那么可以模仿树状数组的办法做差分，或做永久化标记，适应性比递归实现的线段树差一些，优点是常数小，以下实现比前面的大约快30%左右，代码更简单，就不额外解释了。\nstruct zkwseg_tree { struct node { int sum; }; int sz; vector\u0026lt;node\u0026gt; d; void init(int size) // 可操作下标范围为0~size-1 { sz = size; while (sz \u0026amp; (sz - 1)) sz += sz\u0026amp;-sz; d.resize(sz * 2); } void update_add(int p, int v) { int i = sz + p; while (i) { d[i].sum += v; i \u0026gt;\u0026gt;= 1; } } int get_sum(int l, int r) { int sum = 0; l += sz; r += sz + 1; for (; l \u0026lt; r; l\u0026gt;\u0026gt;=1, r\u0026gt;\u0026gt;=1) { if (l \u0026amp; 1) { sum += d[l++].sum; } if (r \u0026amp; 1) { sum += d[--r].sum; } } return sum; } };  其它说明 以上模板为了解释简单，有的实现只有update和get_sum操作，并没有build的部分，只使用update即可完成build的操作，时间复杂度也是一样的。除了维护区间和，也可以维护区间最大最小值。\n","date":1575800760,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575800760,"objectID":"2d11ef2515a9a4a368ec843f3a022436","permalink":"/post/20191208-segtree/","publishdate":"2019-12-08T18:26:00+08:00","relpermalink":"/post/20191208-segtree/","section":"post","summary":"很多人在初始接触线段树的时候，一看到别人写一大堆代码就直接弃坑了，其实不要被它的外表所欺骗，线段树其实是相当好写的树结构了，而且理解起来其实很简单。要学会这个，你不能光会抄模板就会区间修改和求个区间和，因为实际应用经常会使用它的变形，还是在于理解（理解后背板）。\n数据结构 首先，回想一下heap的结构，它使用一个数组，同时使用下标本身来表达父子关系，这样的方式能节省大量指针所需要的内存空间，以下也使用这种表示方法来表示一棵线段树，也就是说，这里介绍的，属于狭义线段树。假设我们的数据是以下这样\n   下标 1 2 3 4 5 6 7 8     数据 1 0 5 2 3 4 0 1    构建线段树后结果如下\ngraph TD; 1,8:16--\u0026gt;1,4:8 1,8:16--\u0026gt;5,8:8 1,4:8--\u0026gt;1,2:1 1,4:8--\u0026gt;3,4:7 1,2:1--\u0026gt;1,1:1 1,2:1--\u0026gt;2,2:0 3,4:7--\u0026gt;3,3:5 3,4:7--\u0026gt;4,4:2 5,8:8--\u0026gt;5,6:7 5,8:8--\u0026gt;7,8:1 5,6:7--\u0026gt;5,5:3 5,6:7--\u0026gt;6,6:4 7,8:1--\u0026gt;7,7:0 7,8:1--\u0026gt;8,8:1 ","tags":["数据结构","线段树","模板","c++"],"title":"线段树","type":"post"},{"authors":null,"categories":["研究"],"content":"后缀数组其实概念很好理解，就是给出一个字符串，长度是n，对它所有的n个后缀编号从1到n进行排序，排序后，最小的那个后缀的编号假设是m1，那么sa[1] = m1，类似地，第二小的是m2的话，sa[2] = m2，sa这个数组就是我们所需要的后缀数组。根据这个，我们可以直接用sort算出sa，以下为最简单的实现\nstruct SA_simple { vector\u0026lt;int\u0026gt; sa; int s_size; const char* p_s; int size() const { return s_size; } static bool cmp(const char* x, const char* y) { return strcmp(x, y) \u0026lt; 0; } void init(char * str) { int n = strlen(str); s_size = n; p_s = str - 1; sa.resize(n + 1); vector\u0026lt; const char* \u0026gt; rp; rp.resize(n + 1); for (int i = 1; i \u0026lt;= n; ++i) { rp[i] = p_s + i; } sort(rp.begin() + 1, rp.end(), cmp); for (int i = 1; i \u0026lt;= n; ++i) { sa[i] = rp[i] - p_s; } } };  这个实现的时间复杂度 $O(n^2logn)$\n要注意的一点是下标从1开始。有了这个，可以做点什么呢？例如给你一个串p，求出p在主串s中出现了多少次。那么在有了sa的情况下，因为sa是有序的，问题就变成了二分搜索，分别用lower_bound和upper_bound通过sa搜索p，两个相减便得出现次数。\nrank 数组 光有sa其实还不够用，我们还需要rank数组，rank[m]的值是p的话，那么表示字符串中编号m的后缀，它的排名是p，即与sa数组是互逆，所以我们可以得到 sa[rank[i]] == rank[sa[i]] == i ，也就是说通过rank，可以快速判断某两个后缀的大小关系。\nheight 数组 height[i]的值表示的是，sa[i-1]与sa[i]这两个后缀的相同前缀长度，特别地，height[1] == 0，求解height需要用到rank数组和sa数组，以及如下引理\n$$height[rank[i]]\\ge height[rank[i-1]]-1$$\n通过以上引理直接暴力实现即可，复杂度 $O(n)$ ，这里不做证明。\n三个数组的完整实现如下\nstruct SA_simple { vector\u0026lt;int\u0026gt; sa, rk, ht; protected: int s_size; const char* p_s; public: int size() const { return s_size; } static bool cmp(const char* x, const char* y) { return strcmp(x, y) \u0026lt; 0; } void init(char * str, bool h = true) { int n = strlen(str); s_size = n; p_s = str - 1; sa.resize(n + 1); rk.resize(n + 1); vector\u0026lt;const char*\u0026gt; rp; rp.resize(n + 1); for (int i = 1; i \u0026lt;= n; ++i) { rp[i] = p_s + i; } sort(rp.begin() + 1, rp.end(), cmp); for (int i = 1; i \u0026lt;= n; ++i) { sa[i] = rp[i] - p_s; rk[sa[i]] = i; } if (h) create_height(); } void create_height() { ht.resize(s_size + 1); for (int i = 1, k = 0; i \u0026lt;= s_size; ++i) { if (k) --k; while (p_s[i + k] == p_s[sa[rk[i] - 1] + k]) ++k; ht[rk[i]] = k; } } };  应用1 可重叠最长重复子串 这个题目在本博客讲kmp部分已经有介绍，例如eabcaefabcabc，最长重复子串是abca，长度是4，这里介绍用后缀数组的解法。其实所谓的最长重复子串，就是找到两个后缀，让它们的公共前缀最长，那这就简单了，我们只要在height数组里找最大值就可以了，查找时间 $O(n)$ 。\n应用2 不同子串的个数 来看这道题 SPOJ-DISUBSTR ，说的是统计一个字符串里有多少不同的子串。\n这里我们就需要用到height数组，由于它表示的正是和前一个后缀的相同前缀长度，那么我们对任意的后缀sa[i]，取这个后缀的长度，即len(s)-sa[i]，减去height[i]再加上1，即表示sa[i]这个后缀有多少个前缀与sa[i-1]不相同，所以我们累加即可。核心代码也就这么几行\nint sum_h = 0; for (int i = 1; i \u0026lt;= sa.size(); ++i) { sum_h += sa.size() - sa.sa[i] - sa.ht[i] + 1; } printf(\u0026quot;%d\\n\u0026quot;, sum_h);  也许有人会发现问题了，这个题直接用hash实现，才 $O(n^2)$ 的复杂度，这个后缀数组的实现，光是生成就 $O(n^2logn)$ ，不是还更慢吗？单看时间复杂度的确是这样，但事实上后缀数组可以0ms通过，hash实现约400ms左右。\n优化 直接排序的后缀数组确实过于暴力了，虽然不少题目已经足够AC，但我们还有更好的，这里简要介绍倍增法。假设对字符串\u0026rdquo;ababaabb\u0026rdquo;求后缀数组，那么先对每一个字符做排序，计算出它们的rank，注意相同串的rank结果要相同，结果在下表的\u0026rdquo;排序1\u0026rdquo;，然后我们对每个i和i+1在\u0026rdquo;排序1\u0026rdquo;上的rank组合起来，这个组合的key再做排序，如下表\n   下标 1 2 3 4 5 6 7 8     原 a b a b a a b b   排序1 1 2 1 2 1 1 2 2   组合1 1 2 2 1 1 2 2 1 1 1 1 2 2 2 2 0   排序2 2 4 2 4 1 2 5 3    事实上这样得到了所有后缀中，前缀长度为2的排名，接下来，我们步长翻倍，对每个i和i+2在\u0026rdquo;排序2\u0026rdquo;上的rank组合起来再排序\n   下标 1 2 3 4 5 6 7 8     排序2 2 4 2 4 1 2 5 3   组合2 2 2 4 4 2 1 4 2 1 5 2 3 5 0 3 0   排序3 3 7 2 6 1 4 8 5    事实上这样得到了所有后缀中，前缀长度为4的排名，接下来，我们步长翻倍，对每个i和i+4在\u0026rdquo;排序3\u0026rdquo;上的rank组合起来再排序\n   下标 1 2 3 4 5 6 7 8     排序3 3 7 2 6 1 4 8 5   组合3 3 1 7 4 2 8 6 5 1 0 4 0 8 0 5 0   排序4 3 7 2 6 1 4 8 5    至此，再下一轮的步长是8，已经大于等于字符串长度的时候，rank数组便计算完成了。以下是使用此思路的实现代码\nstruct SA_2_sort { vector\u0026lt;int\u0026gt; sa, ht; int *rk; protected: vector\u0026lt;int\u0026gt; rk1, rk2; int s_size; int *p_rk, *o_rk; const char* p_s; struct SA_2_sort_cmp { int *rk, w; SA_2_sort_cmp(int *_rk, int _w) :rk(_rk), w(_w) {} bool operator()(int x, int y) const { return rk[x] == rk[y] ? rk[x + w] \u0026lt; rk[y + w] : rk[x] \u0026lt; rk[y]; } }; public: bool cmp(int x, int y, int w) { return o_rk[x] == o_rk[y] \u0026amp;\u0026amp; o_rk[x + w] == o_rk[y + w]; } int size() const { return s_size; } void init(char * str, bool h = true) { int n = strlen(str); s_size = n; p_s = str - 1; sa.resize(n + 1); rk1.clear(); rk1.resize(n * 2 + 2); rk2.clear(); rk2.resize(n * 2 + 2); p_rk = \u0026amp;*rk1.begin(); o_rk = \u0026amp;*rk2.begin(); for (int i = 1; i \u0026lt;= n; ++i) p_rk[i] = p_s[i]; for (int w = 1, i, p; w \u0026lt; n; w \u0026lt;\u0026lt;= 1) { // init sa for (int i = 1; i \u0026lt;= n; ++i) sa[i] = i; sort(sa.begin() + 1, sa.end(), SA_2_sort_cmp(p_rk, w)); // write new rank for (std::swap(p_rk, o_rk), p = 0, i = 1; i \u0026lt;= n; ++i) p_rk[sa[i]] = cmp(sa[i], sa[i - 1], w) ? p : ++p; } rk = p_rk; if (n == 1) sa[1] = rk[1] = 1; if (h) create_height(); } void create_height() { int n = s_size; ht.resize(n + 1); for (int i = 1, k = 0; i \u0026lt;= n; ++i) { if (k) --k; while (p_s[i + k] == p_s[sa[p_rk[i] - 1] + k]) ++k; ht[p_rk[i]] = k; } } };  以上实现的时间复杂度是 $O(nlog^2n)$ ，如果你想要更快，那就用 $O(n)$ 的计数排序吧，便可把整体时间复杂度下降到 $O(nlogn)$\n再优化 绝大多数情况下，使用以上方法 $O(nlogn)$ 复杂度已经够用了，但如果你是一个更有追求的人，可以继续学习 $O(n)$ 复杂度建立后缀数组的办法，名字叫做SA-IS和DC3，你可以通过搜索以上两个名字得到更具体的介绍，本文就只介绍到这里。\n$O(nlogn)$ 模板 struct SA_2 { vector\u0026lt;int\u0026gt; sa, ht; int *rk; protected: vector\u0026lt;int\u0026gt; rk1, rk2; int s_size; int *p_rk, *o_rk; const char* p_s; public: bool cmp(int x, int y, int w) { return o_rk[x] == o_rk[y] \u0026amp;\u0026amp; o_rk[x + w] == o_rk[y + w]; } int size() const { return s_size; } void init(char * str, bool h = true) { int n = strlen(str); s_size = n; p_s = str - 1; int cnt_size = max(256, n) + 1; vector\u0026lt;int\u0026gt; vid, vpx, vcnt; sa.resize(n + 1); rk1.clear(); rk1.resize(n * 2 + 2); rk2.clear(); rk2.resize(n * 2 + 2); vid.resize(n + 1); vpx.resize(n + 1); vcnt.resize(cnt_size); int* id = \u0026amp;*vid.begin(); int* px = \u0026amp;*vpx.begin(); int* cnt = \u0026amp;*vcnt.begin(); p_rk = \u0026amp;*rk1.begin(); o_rk = \u0026amp;*rk2.begin(); int m = 128, p = 0; for (int i = 1; i \u0026lt;= n; ++i) ++cnt[p_rk[i] = p_s[i]]; for (int i = 1; i \u0026lt;= m; ++i) cnt[i] += cnt[i - 1]; for (int i = n; i \u0026gt;= 1; --i) sa[cnt[p_rk[i]]--] = i; for (int w = 1, i; w \u0026lt; n; w \u0026lt;\u0026lt;= 1, m = p) { // init id for (p = 0, i = n; i \u0026gt; n - w; --i) id[++p] = i; for (int i = 1; i \u0026lt;= n; ++i) if (sa[i] \u0026gt; w) id[++p] = sa[i] - w; sort(cnt, id, px, n, m); // write new rank for (std::swap(p_rk, o_rk), p = 0, i = 1; i \u0026lt;= n; ++i) p_rk[sa[i]] = cmp(sa[i], sa[i - 1], w) ? p : ++p; } rk = p_rk; if (n == 1) sa[1] = rk[1] = 1; if (h) create_height(); } void sort(int* cnt, int* id, int* px, int n, int m) { memset(cnt, 0, sizeof(int) * (m + 1)); for (int i = 1; i \u0026lt;= n; ++i) ++cnt[px[i] = p_rk[id[i]]]; for (int i = 1; i \u0026lt;= m; ++i) cnt[i] += cnt[i - 1]; for (int i = n; i \u0026gt;= 1; --i) sa[cnt[px[i]]--] = id[i]; } void create_height() { int n = s_size; ht.resize(n + 1); for (int i = 1, k = 0; i \u0026lt;= n; ++i) { if (k) --k; while (p_s[i + k] == p_s[sa[p_rk[i] - 1] + k]) ++k; ht[p_rk[i]] = k; } } }; ","date":1573640760,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573640760,"objectID":"4df6c8d08499b9417007ad54c050e642","permalink":"/post/20191113-suffixarray/","publishdate":"2019-11-13T18:26:00+08:00","relpermalink":"/post/20191113-suffixarray/","section":"post","summary":"后缀数组其实概念很好理解，就是给出一个字符串，长度是n，对它所有的n个后缀编号从1到n进行排序，排序后，最小的那个后缀的编号假设是m1，那么sa[1] = m1，类似地，第二小的是m2的话，sa[2] = m2，sa这个数组就是我们所需要的后缀数组。根据这个，我们可以直接用sort算出sa，以下为最简单的实现\nstruct SA_simple { vector\u0026lt;int\u0026gt; sa; int s_size; const char* p_s; int size() const { return s_size; } static bool cmp(const char* x, const char* y) { return strcmp(x, y) \u0026lt; 0; } void init(char * str) { int n = strlen(str); s_size = n; p_s = str - 1; sa.resize(n + 1); vector\u0026lt; const char* \u0026gt; rp; rp.resize(n + 1); for (int i = 1; i \u0026lt;= n; ++i) { rp[i] = p_s + i; } sort(rp.begin() + 1, rp.end(), cmp); for (int i = 1; i \u0026lt;= n; ++i) { sa[i] = rp[i] - p_s; } } };  这个实现的时间复杂度 $O(n^2logn)$\n要注意的一点是下标从1开始。有了这个，可以做点什么呢？例如给你一个串p，求出p在主串s中出现了多少次。那么在有了sa的情况下，因为sa是有序的，问题就变成了二分搜索，分别用lower_bound和upper_bound通过sa搜索p，两个相减便得出现次数。\n","tags":["数据结构","后缀数组","suffix array","模板","c++"],"title":"后缀数组","type":"post"},{"authors":null,"categories":["研究"],"content":"树状数组，是一个用于在近似 $O(logn)$ 时间内动态修改以及查询前缀和的数据结构，以下我们先来看以下树关系表格\n   层 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16     1                16   2        8    12  14 15    3    4  6 7   10 11  13      4  2 3  5    9          5 1                   这里表达的是，16的子节点有8, 12, 14, 15\n8的子节点有4, 6, 7\n12的子节点有10, 11，即夹在12与它的同级节点8之间\n我们把数值与它的二进制一起形象化画出下图\ngraph TD; 2,0010--\u0026gt;1,0001 4,0100--\u0026gt;3,0011 4,0100--\u0026gt;2,0010 6,0110--\u0026gt;5,0101 8,1000--\u0026gt;7,0111 8,1000--\u0026gt;6,0110 8,1000--\u0026gt;4,0100 10,1010--\u0026gt;9,1001 12,1100--\u0026gt;11,1011 12,1100--\u0026gt;10,1010 14,1110--\u0026gt;13,1101 16,10000--\u0026gt;8,1000 16,10000--\u0026gt;12,1100 16,10000--\u0026gt;14,1110 16,10000--\u0026gt;15,1111  这样构造的原理是运用到一个二进制运算技巧，假设一个节点x，那么它的父节点就是x + (x \u0026amp; -x)，其中，x \u0026amp; -x是去掉右起第一个1的左边的1，例如x如果是6，二进制是110，只保留最右边的1结果就是10了，所以6的父节点就是6+2=8，更多的可以参考这篇二进制技巧。\n前缀和 给一个数组a，如果我们需要计算前n个元素的和 $\\sum_{i=1}^n{a[i]}$ ，直接累加是很慢的，这里我们用树状数组，我们规定，每个节点保存的值，是它和它的子节点的和，我们用数组 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, 6, 5, 4, 3, 2, 1 画个表格，注意数组下标从1开始。\n   层 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16     原 9 8 7 6 5 4 3 2 1 0 6 5 4 3 2 1   1                66   2        44    12  7 2    3    30  9 3   1 6  4      4  17 7  5    1          5 9                   那有了这个表，我们要是求出前4个数的和，直接看第4列是30，答案就出来了，因为它上面的数就是它和它所有子结点的和。但如果是别的数呢，例如要求前7个数的和，就不能光看第7列了，需要把第4列、第6列和第7列的3个数相加，即30+9+3=42就是前7个数的和。注意到这三列其实就是三个同级节点，而且我们通过7这个数本身可以轻松计算前两列的数，计算的方法是x - (x \u0026amp; -x)，把x=7代入，得到6，再把6代入，得到4，再把4代入，得到0，0就结束了，而在这个迭代的过程里，就知道我们应该把4,6,7三列的数相加。\n再换一个数，例如11呢，把x=11代入，得到10，再把10代入，得到8，再把8代入，得到0，所以我们应该把8,10,11三列的数加起来，即44+1+6=51就是前11个数的和。\n把以上过程写成函数，就是\nint sum(int fwtree[], int x) { int r = 0; while (x \u0026gt; 0) { r += fwtree[x]; x -= x\u0026amp;-x; } return r; }  可以看出，这段代码的时间复杂度近似是 $O(logx)$\n动态维护 还是前面的数组 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, 6, 5, 4, 3, 2, 1 ，现在假如已经计算好了树状数组，但我们需要对第6个元素，让它减少6，怎么操作呢，其实很简单，根据定义，在子节点修改的时候，让它的所有父节点都做相同的修改，那么6的父节点分别有8,16，所以我们对第6,8,16列都一起减少6，得到以下新表格\n   层 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16     原 9 8 7 6 5 -2 3 2 1 0 6 5 4 3 2 1   1                60   2        38    12  7 2    3    30  3 3   1 6  4      4  17 7  5    1          5 9                   这样就维护完成了，所以咱们的实现代码也非常的简单\nvoid add(int fwtree[], int treesize, int x, int add) { while (x \u0026lt;= treesize) { fwtree[x] += add; x += x\u0026amp;-x; } }  区间和 我们之所以需要前缀和，就是为了能快速求区间和。例如我们需要求出数组第i个到第j个元素的和，那么我们用sum(x)表示前x个元素的和，那么可以转化为求sum(j) - sum(i-1)\n区间操作+单点查询 因为树状数组的修改是单点修改，即每次只能修改一个数，那么现在我们提出一个新问题，如果我们需要多次做区间操作（整个区间的数同时加上y），然后查询数组里面指定第k个元素是什么，例如这个题loj131\n由于树状数组不能快速做区间操作，我们用到另一个技巧叫做差分法，我们对数组 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, 6, 5, 4, 3, 2, 1求相邻元素的差，得到新的数组\n9, -1, -1, -1, -1, -1, -1, -1, -1, -1, 6, -1, -1, -1, -1, -1\n这样做了后，如果我们要求出原来第k个元素，那么就是求前k个元素之和，所以如果第i个元素加上a，那么相当于i后面所有元素都加上a。\n所以，这时候的区间操作，就会变成单点操作，例如我们要对区间[i,j]所有的元素加上a，那么在差分了以后，其实就是对第i个元素加上a，再对第j+1个元素减去a。\n区间操作+区间和 如果我们既要做区间操作，同时还要求区间和怎么办，为了支持区间操作，我们仍然先做差分，然后接下来就是让人头痛的数学推导，假设数组a是原数组，b是a的差分数组，由前缀和的定义，我们求前n个元素的和，即\n$$ \\sum_{i=1}^{n} a_i $$\n展开为b数组表达\n$$ = \\sum_{i=1}^n{} \\sum_{j=1}^i b_j $$\n展开，合并同类项\n$$ = \\sum_{i=1}^n b_i\\times(n-i+1) $$\n$$ = (n+1)\\times\\sum_{i=1}^n b_i - \\sum_{i=1}^n b_i\\times i $$\n那么，我们再定义一个c数组，满足c[i] == b[i] * i，然后我们再分别对b和c维护一个树状数组，定义sum(b,x)表示数组b前x个元素的和，sum(c,x)表示数组c前x个元素的和，那么我们便可以通过计算(x + 1) * sum(b, x) - sum(c, x)求出数组a的前缀和。\n习题：loj132\n拓展 树状数组还有一些别的技巧，一是 $O(n)$ 建立，通过已知数组a在 $O(n)$ 时间生成对应的树状数组（直接add来操作是nlogn），这个在这里不做介绍。\n还有权值树状数组求第k小元素。所谓权值树状数组，就是用a[i] = v来表示数值i重复出现了v次，所以v是非负数，那么这个数组的前缀和就是递增的，即存在二分。然后对数组a维护的树状数组直接二分的话是 $O(lognlogn)$ ，但我们可以运用树状数组的特性优化到 $O(logn)$ ，以下是实现代码\nint kth(int fwtree[], int size, int k) { int cnt = 0, ret = 0; for (int i = (int)(log(size + 0.1) / log(2)); ~i; --i) { ret += 1 \u0026lt;\u0026lt; i; if (ret \u0026gt;= size || cnt + fwtree[ret] \u0026gt;= k) ret -= 1 \u0026lt;\u0026lt; i; else cnt += fwtree[ret]; } return ret + 1; }  权值树状数组还有一个应用，就是用来求逆序数，先对原数组排序求出每个元素的rank，转化为长度n，元素为1~n的一个排列，之后使用权值树状数组，就可以轻松求出在a[1]到a[i-1]有多少个元素比a[i]要大，计算sum(n) - sum(a[i])便知，把结果累加就是逆序数。\n模板 区间修改+区间求和模板\n#include \u0026lt;vector\u0026gt; typedef long long ll; struct fwtree_range { std::vector\u0026lt;int\u0026gt; ta; std::vector\u0026lt;ll\u0026gt; tb; int sz; void init(int size) { ta.clear(); ta.resize(size + 1); tb.clear(); tb.resize(size + 1); sz = size; } void add(int x, int a) { ll v = a * (ll)x; for (; x \u0026lt;= sz; x += x\u0026amp;-x) { ta[x] += a; tb[x] += v; } } template \u0026lt;class T\u0026gt; ll sum_t(T\u0026amp; t, int x) { ll r = 0; for (; x \u0026gt; 0; x -= x\u0026amp;-x) r += t[x]; return r; } ll sum(int x) { return (x + 1) * sum_t(ta, x) - sum_t(tb, x); } void range_add(int l, int r, int a) { add(l, a); add(r + 1, -a); } ll range_sum(int l, int r) { return sum(r) - sum(l - 1); } };  用法，调用init初始化大小后，使用range_add及range_sum做区间修改及区间和查询就行了，当然它也支持单点修改和单点查询，你令区间l == r就行了。\n","date":1573450320,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573450320,"objectID":"4f092d15912cc710e0cc14d72e1f6b7a","permalink":"/post/20191111-fenwicktree/","publishdate":"2019-11-11T13:32:00+08:00","relpermalink":"/post/20191111-fenwicktree/","section":"post","summary":"树状数组，是一个用于在近似 $O(logn)$ 时间内动态修改以及查询前缀和的数据结构，以下我们先来看以下树关系表格\n   层 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16     1                16   2        8    12  14 15    3    4  6 7   10 11  13      4  2 3  5    9          5 1                   这里表达的是，16的子节点有8, 12, 14, 15\n8的子节点有4, 6, 7\n12的子节点有10, 11，即夹在12与它的同级节点8之间\n我们把数值与它的二进制一起形象化画出下图\ngraph TD; 2,0010--\u0026gt;1,0001 4,0100--\u0026gt;3,0011 4,0100--\u0026gt;2,0010 6,0110--\u0026gt;5,0101 8,1000--\u0026gt;7,0111 8,1000--\u0026gt;6,0110 8,1000--\u0026gt;4,0100 10,1010--\u0026gt;9,1001 12,1100--\u0026gt;11,1011 12,1100--\u0026gt;10,1010 14,1110--\u0026gt;13,1101 16,10000--\u0026gt;8,1000 16,10000--\u0026gt;12,1100 16,10000--\u0026gt;14,1110 16,10000--\u0026gt;15,1111  这样构造的原理是运用到一个二进制运算技巧，假设一个节点x，那么它的父节点就是x + (x \u0026amp; -x)，其中，x \u0026amp; -x是去掉右起第一个1的左边的1，例如x如果是6，二进制是110，只保留最右边的1结果就是10了，所以6的父节点就是6+2=8，更多的可以参考这篇二进制技巧。\n","tags":["数据结构","树状数组","Fenwick Tree","模板","c++"],"title":"树状数组","type":"post"},{"authors":null,"categories":["研究"],"content":"KMP之所以在竞赛中常见，并不是因为它用来匹配字符串，而是用它的next数组，为了介绍它，我们先讲讲最长公共前缀\n最长公共前缀 我们拿字符串ababcab作为例子\n   string a b a b c a b     len 0 0 1 2 0 1 2    这里所表达的是，例如取第3、4个字符\u0026rdquo;ab\u0026rdquo;，这个子串与前缀完全匹配，且它的长度是2，所以就记录2，而第3、4、5个字符\u0026rdquo;abc\u0026rdquo;与前缀不能完全匹配，就记作0，含义就这么简单，而且你会发现，计算b的时候，可以根据它所匹配的字符的偏移来，b如果是匹配的，就找到匹配的那个字符是数组中的第几个，它是第二个，所以填2进去。我们再来看更复杂的例子\n   string a b a c a b a b     len 0 0 1 0 1 2 3 2    最后那个字符不匹配的时候，1是怎么计算出来的呢，直接重新计算当然也可以，但就出现重复计算了。我们考虑一下匹配过程，在前面的字符a的时候，前后各一个指针，像这样\n   string a b a c a b a b     len 0 0 1 0 1 2 3 ?   pointer   ^    ^     然后两个a匹配，arr[6] = pointer1 - arr 得到3，然后两指针一起移动\n   string a b a c a b a b     len 0 0 1 0 1 2 3 ?   pointer   * ^    ^    这时候，不匹配，那么前一个指针上一次指向的是arr[2]的位置，即图上*的地方，值是1，这个值如果是p，那就移动到arr[p]的地方，所以就移动到arr[1]的地方，本质上就是找到前一个匹配此后缀的位置，即\n   string a b a c a b a b     len 0 0 1 0 1 2 3 2   pointer  ^      ^    然后再尝试匹配，这次匹配上了，然后前一指针指向第二个元素，所以赋值2\nnext数组 以上过程你需要细细理解，在理解以上过程后，再去理解next数组就非常简单了，next数组只是把以上数组加了一偏移，如下\n   string a b a c a b a b \\0     next -1 0 0 1 0 1 2 3 2    这么做是为了简化代码的书写，当然你直接用公共前缀的那个数组来做也是可以的\n不过本文不介绍怎么做字符串匹配，这种文章到处都是，我们要讲的是竞赛中的典型应用\n生成next数组的算法的时间复杂度为 $O(n)$ ，n是数组长度\n应用1 poj2406 题目大意是给你一个字符串s，找出一个串a，使得a自己重复n次，便得到字符串s，要找到最大的n值。例如ababab，可以找到ab重复3次得到，所以输出3。像这种就是next数组表演的时候，它在计算自匹配方面非常合适，我们先再来理解一下next数组，它的值表示与前缀的重复长度，那么看下表，使用长度为102的abab....abab\n   string a b a b \u0026hellip; b a b \\0     next -1 0 0 1 \u0026hellip; 97 98 99 100    我们发现，使用串长102减去next数组最后一个值，自然就得到了重复前缀的最短长度，既然它是最短的，那么我们用总长102除以2，就得到了重复的次数，就是我们想要的答案。当然前提是能整除，如果不能整除那么这样的前缀便不存在，输出1就行了。\n应用2 poj2752 题目大意是给你一个字符串s，找出所有前缀等于后缀的串长。我们先来试试算一个短点的ababcababcabab\n   string a b a b c a b a b c a b a b \\0     next -1 0 0 1 2 0 1 2 3 4 5 6 7 8 9    可以轻松看出next的最后一个值9肯定就是其中一个长度，那接着呢？我们需要回想一下，构造这个数组的时候，如果匹配失败，是怎么找到前一个匹配当前后缀的前缀的，这个值如果是p，那就移动到arr[p]的地方，如果你还记得这个，那就好办了，我们取arr[9]，结果是4，再取arr[4]结果是2，再取arr[2]，结果是0，循环结束，所以加上整个串长14就是我们所要的答案了，完整结果是2 4 9 14。\n应用3 子串出现次数 给你主串s和子串t，求t在s中出现了多少次，例如s=\u0026quot;abababa\u0026quot;，t=\u0026quot;aba\u0026quot;，那么t在s中出现了3次。\n这里运用到一个技巧，我们把s和t连接成这个串u=\u0026quot;aba#abababa\u0026quot;，即把t放在s的前面并中间使用#分隔，这个符号在两个串中都没有出现。然后我们对u计算next数组，那么next数组中值等于t的长度的元素个数就是答案。\n应用4 可重叠最长重复子串 大意是给你一个字符串s，任意选取两个不同的起始位置i和j，这两个位置的后缀串有相同的前缀，这个前缀可以重叠，问这个相同的前缀的最大长度\n例如eabcaefabcabc，最长重复子串是abca，长度是4。\nKMP在生成的时候，总是以串的前缀作为匹配对象，我们要做的，就是遍历那个字符串的每一个后缀，都生成一次next数组，而在生成过程中出现的最大值就是答案，所以时间复杂度 $O(n^2)$ 。当然我们还有更好的算法，这个之后再讲。\nZ Algorithm Z函数的定义是对于字符串s，生成数组z，定义z[i]是s.substr(i)与s的最长相同前缀长度\n样例如下\n   string a b a c a b a c \\0     Z 8 0 1 0 4 0 1 0 0    扩展KMP需要依赖这个z数组，但是在介绍这个之前，我们先介绍下面的扩展KMP\n扩展KMP 所谓扩展KMP，即给定两个字符串s和p，需要求出数组ext，其中ext[i]的值表示s.substr(i)与p的最长相同前缀长度\n这个算法依赖 Z Algorithm 中生成的z数组。\n为了比较容易理解，我省略一堆说明，我们直接来模拟匹配过程，一边模拟一边解说，一开始数据如下，i是匹配位置指针\n   string b a a b a c a c \\0     i ^           p a b a c a b      Z 6 0 1 0 2 0      ext 0 0 0 0 0 0 0 0 -    上表，一开始，不匹配，不操作，移动p\n   string b a a b a c a c \\0     e   ^         i  ^          p  a b a c a b     Z  6 0 1 0 2 0     ext 0 1 0 0 0 0 0 0 -    这时，p与s[i]是匹配的，我们用e指针记录未能匹配的位置，并写入ext[i]=e-i得1\n继续移动p，并更新e，得到下表\n   string b a a b a c a c \\0     e        ^    i   ^         p   a b a c a b    Z   6 0 1 0 2 0    ext 0 1 5 0 0 0 0 0 -    得到上表这个后，令ext[i]=e-i得5，这个时候，移动到下一个元素，但同时p暂时不动。这个情况出现于p\u0026lt;e的时候，严格来说，应该是z[i-p]+i \u0026lt; e的时候，具体原因后面解释。\n   string b a a b a c a c \\0     e        ^    i    ^        p   a b a c a b    Z   6 0 1 0 2 0    ext 0 1 5 0 0 0 0 0 -    上表这个时候，不看字符匹配的情况，只看i指针位置上那一列对应的Z数组的值，即z[i-p]为0，如果这个数加上i小于e的话，直接令ext[i]=z[i-p]得到0\n   string b a a b a c a c \\0     e        ^    i     ^       p   a b a c a b    Z   6 0 1 0 2 0    ext 0 1 5 0 1 0 0 0 -    继续以上操作，ext[i]=z[i-p]得到1。之所以能这么操作，是因为p是自匹配的，在这个位置上的z值，就同时表达了i开始，字符串s与p连续多少个字符能匹配p的前缀，前提是这个串的范围必须在e的前面。\n   string b a a b a c a c \\0     e        ^    i      ^      p   a b a c a b    Z   6 0 1 0 2 0    ext 0 1 5 0 1 0 0 0 -    继续以上操作，ext[i]=z[i-p]得到0，注意到，下一步i将指向a，导致z[i-p]+i \u0026gt;= e，这个会导致z数组的内容不能直接复制到ext数组内，所以我们要恢复之前的字符串匹配过程，令p等于i，得如下状态\n   string b a a b a c a c \\0     e        ^    i       ^     p       a b a   Z       6 0 1   ext 0 1 5 0 1 0 1 0 -    这个时候，写入ext[i]=e-i得1\n   string b a a b a c a c \\0     e        ^    i        ^    p        a b   Z        6 0   ext 0 1 5 0 1 0 1 0 -    最后一步，第一个也不匹配，写入ext[i]=e-i得0，下一步i到达字符串末尾，结束。\n扩展kmp与经典kmp的算法的时间复杂度均为 $O(len(s)+len(p))$\n那么讲完了扩展KMP我们回来讲Z Algorithm，其实它们的区别，仅仅是计算对象的差异，即扩展KMP是通过字符串p求出s的ext数组，而Z Algorithm是通过自身来求，我们只需要把原来扩展KMP的代码复制一份改改名字，且起点改为1行了，详见下面模板实现代码。\n应用实例有：hdu4333\nKMP模板 以下是我写的模板代码\nvoid kmp_next(const char* pattern, int next[]) { int len = strlen(pattern); next[0] = -1; for (int i = 0, j = -1; i \u0026lt; len;) { if (j == -1 || pattern[i] == pattern[j]) next[++i] = ++j; else j = next[j]; } } const char* kmp_match(const char* str, const char* pattern, int next[]) { int len = strlen(pattern); int i = 0; kmp_next(pattern, next); while (*str \u0026amp;\u0026amp; i \u0026lt; len) { if (pattern[i] == *str) { ++i, ++str; } else { i = next[i]; if (i == -1) { ++i, ++str; } } } return i == len ? str - i : str; } void extkmp_z(const char* str, int z[]) { int s_len = strlen(str); z[0] = s_len; for (int i = 1, p = 1, e = 1; i \u0026lt; s_len; ++i) { if (i + z[i - p] \u0026gt;= e) { e = std::max(i, e); p = i; while (e \u0026lt; s_len \u0026amp;\u0026amp; str[e] == str[e - i]) ++e; z[i] = e - i; } else z[i] = z[i - p]; } } void extkmp_ext(const char* str, int ext[], const char* pattern, int z[]) { int s_len = strlen(str); extkmp_z(pattern, z); for (int i = 0, p = 0, e = 0; i \u0026lt; s_len; ++i) { if (i + z[i - p] \u0026gt;= e) { e = std::max(i, e); p = i; while (e \u0026lt; s_len \u0026amp;\u0026amp; str[e] == pattern[e - i]) ++e; ext[i] = e - i; } else ext[i] = z[i - p]; } }  最后总结 字符串就是一个深坑，不过KMP也许是打开你理解后缀树或后缀数组的好工具，为后者的学习做铺垫。\n","date":1572240720,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572240720,"objectID":"2a6a3ab68e6c4190930e5710ae988b68","permalink":"/post/20191028-kmp/","publishdate":"2019-10-28T13:32:00+08:00","relpermalink":"/post/20191028-kmp/","section":"post","summary":"KMP之所以在竞赛中常见，并不是因为它用来匹配字符串，而是用它的next数组，为了介绍它，我们先讲讲最长公共前缀\n最长公共前缀 我们拿字符串ababcab作为例子\n   string a b a b c a b     len 0 0 1 2 0 1 2    这里所表达的是，例如取第3、4个字符\u0026rdquo;ab\u0026rdquo;，这个子串与前缀完全匹配，且它的长度是2，所以就记录2，而第3、4、5个字符\u0026rdquo;abc\u0026rdquo;与前缀不能完全匹配，就记作0，含义就这么简单，而且你会发现，计算b的时候，可以根据它所匹配的字符的偏移来，b如果是匹配的，就找到匹配的那个字符是数组中的第几个，它是第二个，所以填2进去。我们再来看更复杂的例子\n   string a b a c a b a b     len 0 0 1 0 1 2 3 2    最后那个字符不匹配的时候，1是怎么计算出来的呢，直接重新计算当然也可以，但就出现重复计算了。我们考虑一下匹配过程，在前面的字符a的时候，前后各一个指针，像这样\n   string a b a c a b a b     len 0 0 1 0 1 2 3 ?   pointer   ^    ^     然后两个a匹配，arr[6] = pointer1 - arr 得到3，然后两指针一起移动\n   string a b a c a b a b     len 0 0 1 0 1 2 3 ?   pointer   * ^    ^    这时候，不匹配，那么前一个指针上一次指向的是arr[2]的位置，即图上*的地方，值是1，这个值如果是p，那就移动到arr[p]的地方，所以就移动到arr[1]的地方，本质上就是找到前一个匹配此后缀的位置，即\n   string a b a c a b a b     len 0 0 1 0 1 2 3 2   pointer  ^      ^    然后再尝试匹配，这次匹配上了，然后前一指针指向第二个元素，所以赋值2\n","tags":["算法","模式匹配","KMP","状态机","模板","c"],"title":"KMP及扩展KMP","type":"post"},{"authors":null,"categories":["研究"],"content":"在上一篇我们介绍了快排的各种优化，最后得到了一个超越VS的STL std::sort实现的版本，这回我们来讲讲怎么折磨gcc的std::sort。\nGCC的实现 这个我直接给个github来源，链接里是gcc8分支的实现源码，我已经通过链接标记出第1896行，那里就是__unguarded_partition函数的实现，就是快排的划分函数，而在后面几个函数就是快排的本体了。为了避免它代码更新导致位置变化，我把相关代码复制过来。\n/// Swaps the median value of *__a, *__b and *__c under __comp to *__result template\u0026lt;typename _Iterator, typename _Compare\u0026gt; void __move_median_to_first(_Iterator __result,_Iterator __a, _Iterator __b, _Iterator __c, _Compare __comp) { if (__comp(__a, __b)) { if (__comp(__b, __c)) std::iter_swap(__result, __b); else if (__comp(__a, __c)) std::iter_swap(__result, __c); else std::iter_swap(__result, __a); } else if (__comp(__a, __c)) std::iter_swap(__result, __a); else if (__comp(__b, __c)) std::iter_swap(__result, __c); else std::iter_swap(__result, __b); } /// This is a helper function... template\u0026lt;typename _RandomAccessIterator, typename _Compare\u0026gt; _RandomAccessIterator __unguarded_partition(_RandomAccessIterator __first, _RandomAccessIterator __last, _RandomAccessIterator __pivot, _Compare __comp) { while (true) { while (__comp(__first, __pivot)) ++__first; --__last; while (__comp(__pivot, __last)) --__last; if (!(__first \u0026lt; __last)) return __first; std::iter_swap(__first, __last); ++__first; } } /// This is a helper function... template\u0026lt;typename _RandomAccessIterator, typename _Compare\u0026gt; inline _RandomAccessIterator __unguarded_partition_pivot(_RandomAccessIterator __first, _RandomAccessIterator __last, _Compare __comp) { _RandomAccessIterator __mid = __first + (__last - __first) / 2; std::__move_median_to_first(__first, __first + 1, __mid, __last - 1, __comp); return std::__unguarded_partition(__first + 1, __last, __first, __comp); } template\u0026lt;typename _RandomAccessIterator, typename _Compare\u0026gt; inline void __partial_sort(_RandomAccessIterator __first, _RandomAccessIterator __middle, _RandomAccessIterator __last, _Compare __comp) { std::__heap_select(__first, __middle, __last, __comp); std::__sort_heap(__first, __middle, __comp); } /// This is a helper function for the sort routine. template\u0026lt;typename _RandomAccessIterator, typename _Size, typename _Compare\u0026gt; void __introsort_loop(_RandomAccessIterator __first, _RandomAccessIterator __last, _Size __depth_limit, _Compare __comp) { while (__last - __first \u0026gt; int(_S_threshold)) { if (__depth_limit == 0) { std::__partial_sort(__first, __last, __last, __comp); return; } --__depth_limit; _RandomAccessIterator __cut = std::__unguarded_partition_pivot(__first, __last, __comp); std::__introsort_loop(__cut, __last, __depth_limit, __comp); __last = __cut; } } // sort template\u0026lt;typename _RandomAccessIterator, typename _Compare\u0026gt; inline void __sort(_RandomAccessIterator __first, _RandomAccessIterator __last, _Compare __comp) { if (__first != __last) { std::__introsort_loop(__first, __last, std::__lg(__last - __first) * 2, __comp); std::__final_insertion_sort(__first, __last, __comp); } }  吐槽一句，连gcc源代码也把tab和空格混合使用我也是醉了，源代码的tab在这里已替换为空格以保证版面一致\n这里我们并不需要关注太多东西，在上一篇我们讲到过，快排最大的弱点正在于它的划分元素选择上，所以我们只需要看这个函数\ntemplate\u0026lt;typename _RandomAccessIterator, typename _Compare\u0026gt; inline _RandomAccessIterator __unguarded_partition_pivot(_RandomAccessIterator __first, _RandomAccessIterator __last, _Compare __comp) { _RandomAccessIterator __mid = __first + (__last - __first) / 2; std::__move_median_to_first(__first, __first + 1, __mid, __last - 1, __comp); return std::__unguarded_partition(__first + 1, __last, __first, __comp); }  这个函数从__first + 1, __mid, __last - 1三个数里面，取一个中位数交换到__first的位置，知道这个就能想办法生成对抗数据了。为了让它运行缓慢，那么只要让它这个函数每次都选到第二小的元素放最左边，这样每次调用__unguarded_partition的结果，就是把划分点划分到了__first + 2的位置上，即每次只划分两个元素，这就是它的最坏情况。\n构造这个东西需要一些技巧，我们要模拟std::sort的过程，但为了复杂性降低，我们令最右边元素值最大，那么中位数必定在__first + 1与__mid中选出，这样在partition过程中就能保证不会动到最后的元素，只会在这两个之间换来换去。然后我们只模拟出交换的结果，而不必去遍历，否则你生成的复杂度就$O(n^2)$了。\n另外，还要注意的一点是，它使用的是intro sort来实现，也就是说深度到一定程度后，会转化为堆排序，而堆排序的最坏情况是乱序数组，我们不必一直这么做，否则堆排序时间并不是最长的，我们只要弄深度150的就够用了。我们来看看生成的数据在8000000长度下，使用mingw64-gcc8编译参数-O3的实测结果\n   int 1 2 3 4 5 evil Avg     intro_sort 6 76 82 509 510 510 282   std::sort 86 92 94 473 487 1650 480   std::heap 584 369 421 1436 1467 1499 962    第4、5列是随机打乱的数据，作为对比组，而evil列就是生成的对抗数据，我把heap sort及前一篇的intro_sort实现放上来做比较，可以看出在这组数据下，std::sort必然地比堆排序还要慢，是乱序数据的3.5倍左右，当然这个时间完全取决于堆排序的时间。\n附上生成代码\nstruct save_index { int val; int index; save_index(int i = 0, int v = -1) : val(v) , index(i) {} void swap(save_pos\u0026amp; p) { int t = p.val; p.val = val; val = t; } bool operator \u0026lt; (const save_index\u0026amp; p) const { return index \u0026lt; p.index; } }; void qsort_sim_gcc(save_index * beg, save_index * end, int max_round) { int cur_num = 0; if ((end-1)-\u0026gt;val == -1) { (end - 1)-\u0026gt;val = (end - beg) * 2; } while (beg + 1 \u0026lt; end \u0026amp;\u0026amp; --max_round \u0026gt; 0) { save_index *l = beg + 1, *r = end - 1, *m = beg + (end - beg) / 2; if (l-\u0026gt;val == -1) l-\u0026gt;val = ++cur_num; if (r-\u0026gt;val == -1) r-\u0026gt;val = ++cur_num; if (m-\u0026gt;val == -1) m-\u0026gt;val = ++cur_num; if (l-\u0026gt;val \u0026gt; m-\u0026gt;val) { if (m-\u0026gt;val \u0026gt; r-\u0026gt;val) std::swap(*beg, *m); else if (l-\u0026gt;val \u0026gt; r-\u0026gt;val) std::swap(*beg, *r); else std::swap(*beg, *l); } else { if (m-\u0026gt;val \u0026lt; r-\u0026gt;val) std::swap(*beg, *m); else if (l-\u0026gt;val \u0026gt; r-\u0026gt;val) std::swap(*beg, *l); else std::swap(*beg, *r); } if (l-\u0026gt;val \u0026lt; beg-\u0026gt;val \u0026amp;\u0026amp; l-\u0026gt;val != -1) ; else if (m-\u0026gt;val \u0026lt; beg-\u0026gt;val \u0026amp;\u0026amp; m-\u0026gt;val != -1) std::swap(*l, *m); beg += 2; } } void anti_qsort_gen_gcc(std::vector\u0026lt;save_index\u0026gt;\u0026amp; vec, size_t len, int max_round) { for (size_t i = 0; i \u0026lt; len; ++i) { vec.push_back(save_index((int)i)); } qsort_sim_gcc(\u0026amp;*vec.begin(), \u0026amp;*vec.begin() + len, max_round); int cnt = 0; for (size_t i = 0; i \u0026lt; len; ++i) { if (vec[i].val == -1) ++cnt; } std::vector\u0026lt;int\u0026gt; val_list(cnt); for (int i = 0; i \u0026lt; cnt; ++i) { val_list[i] = i + len - cnt; } // 以下 random_shuffle 实现需要自己实现，如果你用的是mingw // 不能使用std::random_shuffle，注意 random_shuffle(val_list.begin(), val_list.end()); for (int i = 0, j = 0; i \u0026lt; len; ++i) { if (vec[i].val == -1) { vec[i].val = val_list[j++]; } } std::sort(vec.begin(), vec.end()); } void anti_qsort_gen_gcc(sort_element_t arr[], size_t len) { std::vector\u0026lt;save_index\u0026gt; vec; anti_qsort_gen_gcc(vec, len, 150); for (size_t i = 0; i \u0026lt; len; ++i) { arr[i] = vec[i].val; } }  代码中注释的random_shuffle问题参见这篇文章\n最后总结，老实加个rand比啥都强，至少大大增加构造evil数据的难度，也大大降低遇到最坏情况的可能。\n","date":1571650320,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571650320,"objectID":"02b136457d3bf2565b7b5e0b513b74fc","permalink":"/post/20191019-qsort-talk-3/","publishdate":"2019-10-21T17:32:00+08:00","relpermalink":"/post/20191019-qsort-talk-3/","section":"post","summary":"在上一篇我们介绍了快排的各种优化，最后得到了一个超越VS的STL std::sort实现的版本，这回我们来讲讲怎么折磨gcc的std::sort。\nGCC的实现 这个我直接给个github来源，链接里是gcc8分支的实现源码，我已经通过链接标记出第1896行，那里就是__unguarded_partition函数的实现，就是快排的划分函数，而在后面几个函数就是快排的本体了。为了避免它代码更新导致位置变化，我把相关代码复制过来。\n","tags":["算法","排序","快速排序","对抗数据生成","c++","stl"],"title":"Quick sort(快速排序)杂谈 3","type":"post"},{"authors":null,"categories":["研究"],"content":"在上一篇我们介绍了四种不同的划分算法，现在我们来针对Hoare partition scheme来讲解一些优化和注意的问题。\n最坏时间复杂度的优化 在前一篇的示例代码里面，只是最简单地选择的最开头或最后面的元素作为划分，这对于乱序的数据还好，对于有序的数据这么做，时间复杂度就直接变成$O(n^2)$了，那么怎么解决？第一个要解决的反而不是划分元素的选择上，而是改成intro sort，记录递归深度或类似的办法，到达限制条件的时候改而使用堆排序，这属于混合排序，先让排序的最坏时间复杂度降下来是第一要务。所以可以改写出以下代码：\nsort_element_t* intro_sort_partition(sort_element_t * beg, sort_element_t * end) { sort_element_t *l = beg, *r = end - 1; sort_element_t pivot = *r; while (1) { while (l \u0026lt; r \u0026amp;\u0026amp; *l \u0026lt; pivot) ++l; while (l \u0026lt; r \u0026amp;\u0026amp; !(*r \u0026lt; pivot)) --r; if (l \u0026gt;= r) break; sort_element_swap(l++, r); } sort_element_swap(l, end - 1); return l; } void intro_sort_recursive(sort_element_t * beg, sort_element_t * end, int depth) { if (end - beg \u0026lt;= 1) return; if (depth \u0026lt;= 0) { heap_sort(beg, end); return; } sort_element_t *p = intro_sort_partition(beg, end); intro_sort_recursive(beg, p, depth - 1); intro_sort_recursive(p + 1, end, depth - 1); } void intro_sort(sort_element_t * beg, sort_element_t * end) { int depth = (int)(log(end - beg) * 2.5); intro_sort_recursive(beg, end, depth); }  同时，这份代码使用的分割结果是\n   左 中 右     \u0026lt; = \u0026gt;=    至于为什么选择这种划分结果，与后面的优化有关系。\n划分元素的选择 好，我们从这个代码开始重新谈一下分割元素的选取，网上常见有以下方案：\n 固定选择最开头或最后一个 固定选择中间的元素 随机选择元素 在开头、中间、末尾固定三个数里选择一个中位数 在更多的数里面找中位数，同样是固定选择  首先，我们能显然地排除第一个，它对已排序或接近排序完成的数据效率特别低，所以，接下来我们的思路就是分别针对这些选择方案看看有哪些情况让它们特别低效。\n那么按这个思路，我样再来考虑一下，如果要排序的数据重复元素特别的多，甚至于所有元素都相等呢？这时候你会发现不管哪种选取方案都没有用，都会陷入最坏情况，所以我们接下来在继续研究分割元素的选取之前，先考虑重复元素的问题。\n重复元素的过滤 之所以分割方式使用上文那种，为的就是能更方便地过滤重复元素，大于等于分割元素的，都一定在分割位置的右边，所以intro_sort_recursive函数可以这样改\nvoid intro_sort_recursive(sort_element_t * beg, sort_element_t * end, int depth) { if (end - beg \u0026lt;= 1) return; if (depth \u0026lt;= 0) { heap_sort(beg, end); return; } sort_element_t *p = intro_sort_partition(beg, end); intro_sort_recursive(beg, p, depth - 1); for (++p; p \u0026lt; end \u0026amp;\u0026amp; !(p[-1] \u0026lt; *p || *p \u0026lt; p[-1]); ) ++p; intro_sort_recursive(p, end, depth - 1); }  其中!(p[-1] \u0026lt; *p || *p \u0026lt; p[-1])就是判断p[-1] == *p\n这样修改后，在所有元素相等的情况下，时间复杂度能达到$O(n)$\n再次考虑划分元素的选择 这次我们把方案一个个来列举优缺点\n 固定选择中间的元素，速度快，对有序或逆序的数据分割效率最高，但在中间附近元素都是数据里最大的数据的时候，即遇到最坏情况，会快速退化成堆排序 在开头、中间、末尾固定三个数里选择一个中位数，这个是也gcc的STL实现，但能构造出让它遇到最坏情况的数据，比乱序数据慢4倍甚至更多 在更多的数里面找中位数，同样是固定选择，VS的STL实现就是在9个数里面取，但同样能构造出让它遇到最坏情况的数据，比乱序数据慢4倍甚至更多 随机选择元素，遇到最坏情况机率极低，但对于有序或逆序的数据时间比前三种都会慢一些  事实上，任何的固定选取方案理论上都能构造出固定的使其遇到最坏的情况，而我们的目标当然是让它减少遇到的机率，所以我推荐增加随机选择在里面，但单纯的随机选择虽然并不太优秀，但已足够实用，而且我们并不需要真的搞什么复杂的随机数，所以我们先来实现这个：\nsort_element_t* intro_sort_partition(sort_element_t * beg, sort_element_t * end) { static int s_rnd = 0x123456; sort_element_t *l = beg, *r = end - 1; sort_element_swap(r, l + (++s_rnd % (end - beg))); sort_element_t pivot = *r; while (1) { while (l \u0026lt; r \u0026amp;\u0026amp; *l \u0026lt; pivot) ++l; while (l \u0026lt; r \u0026amp;\u0026amp; !(*r \u0026lt; pivot)) --r; if (l \u0026gt;= r) break; sort_element_swap(l++, r); } sort_element_swap(l, end - 1); return l; }  只要一个静态的计数器作为随机数其实就足够了，把选中的元素交换到最右边即可。\n那我们还是要考虑优化的话怎么弄呢？那我们结合着来，在三个数里取中位数，不过还要带上随机，代码如下\ninline void make_mid_pivot(sort_element_t* l, sort_element_t* mid, sort_element_t* r) { if (*r \u0026lt; *mid) { if (*mid \u0026lt; *l) return; sort_element_swap(mid, r); } if (*mid \u0026lt; *l) { sort_element_swap(mid, l); if (*r \u0026lt; *mid) sort_element_swap(mid, r); } } sort_element_t* intro_sort_partition(sort_element_t * beg, sort_element_t * end) { static int s_rnd = 0x123456; sort_element_t *l = beg, *r = end - 1; int half = (end - beg) / 2; make_mid_pivot(l + s_rnd % half, l + half, r - s_rnd % half); ++s_rnd; sort_element_swap(r, l + half); sort_element_t pivot = *r; while (1) { while (l \u0026lt; r \u0026amp;\u0026amp; *l \u0026lt; pivot) ++l; while (l \u0026lt; r \u0026amp;\u0026amp; !(*r \u0026lt; pivot)) --r; if (l \u0026gt;= r) break; sort_element_swap(l++, r); } sort_element_swap(l, end - 1); return l; }  到这个阶段，这个实现已经能和VS版本的std::sort平起平坐了，接下我们就要超越它\n小数据优化 当需要排序的数据长度较小的时候，快速排序其实并不快，我们改用插入排序，在16个元素或以下的时候使用。修改的那部分代码如下\nvoid intro_sort_recursive(sort_element_t * beg, sort_element_t * end, int depth) { if (end - beg \u0026lt;= 16) { insert_sort(beg, end); return; } if (depth \u0026lt;= 0) { heap_sort(beg, end); return; } sort_element_t *p = intro_sort_partition(beg, end); intro_sort_recursive(beg, p, depth - 1); for (++p; p \u0026lt; end \u0026amp;\u0026amp; !(p[-1] \u0026lt; *p || *p \u0026lt; p[-1]); ) ++p; intro_sort_recursive(p, end, depth - 1); }  至此，已经能比VS的std::sort快了\n运行测试 我们来看在VS2005下对4500000个int排序的测试结果\n   int 1 2 3 4 5 6 7 8 9 10 Avg     intro_sort 3 38 43 282 281 71 18 60 103 269 116   std::sort 2 53 57 327 331 72 40 85 114 317 139    再看mingw64-gcc9下使用-O3参数编译，对4500000个int排序的测试结果\n   int 1 2 3 4 5 6 7 8 9 10 Avg     intro_sort 4 41 46 274 281 67 18 80 105 266 118   std::sort 45 52 55 254 255 98 82 64 106 248 125    可以看到几乎在所有的测试数据里都比VS的实现快。不过尽管这个比VS的实现快，但比起gcc的实现还是稍差一点点，但已经足够好。\n本篇就介绍到这里了，最后把优化后的完整代码给出，更多优化请看下一篇文章\n   点击展开  \ninline void make_mid_pivot(sort_element_t* l, sort_element_t* mid, sort_element_t* r) { if (*r \u0026lt; *mid) { if (*mid \u0026lt; *l) { return; } sort_element_swap(mid, r); } if (*mid \u0026lt; *l) { sort_element_swap(mid, l); if (*r \u0026lt; *mid) sort_element_swap(mid, r); } } sort_element_t* intro_sort_partition(sort_element_t * beg, sort_element_t * end) { static int s_rnd = 0x123456; sort_element_t *l = beg, *r = end - 1; int half = (end - beg) / 2; make_mid_pivot(l + s_rnd % half, l + half, r - s_rnd % half); ++s_rnd; sort_element_swap(r, l + half); sort_element_t pivot = *r; while (1) { while (l \u0026lt; r \u0026amp;\u0026amp; *l \u0026lt; pivot) ++l; while (l \u0026lt; r \u0026amp;\u0026amp; !(*r \u0026lt; pivot)) --r; if (l \u0026gt;= r) break; sort_element_swap(l++, r); } sort_element_swap(l, end - 1); return l; } void intro_sort_recursive(sort_element_t * beg, sort_element_t * end, int depth) { if (end - beg \u0026lt;= 16) { insert_sort(beg, end); return; } if (depth \u0026lt;= 0) { heap_sort(beg, end); return; } sort_element_t *p = intro_sort_partition(beg, end); intro_sort_recursive(beg, p, depth - 1); for (++p; p \u0026lt; end \u0026amp;\u0026amp; !(p[-1] \u0026lt; *p || *p \u0026lt; p[-1]); ) ++p; intro_sort_recursive(p, end, depth - 1); } void intro_sort(sort_element_t * beg, sort_element_t * end) { int depth = (int)(log(end - beg) * 2.5); intro_sort_recursive(beg, end, depth); }  \n","date":1571417820,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571417820,"objectID":"a0b751a4ee6303e6beef85cebea4884b","permalink":"/post/20191019-qsort-talk-2/","publishdate":"2019-10-19T00:57:00+08:00","relpermalink":"/post/20191019-qsort-talk-2/","section":"post","summary":"在上一篇我们介绍了四种不同的划分算法，现在我们来针对Hoare partition scheme来讲解一些优化和注意的问题。\n最坏时间复杂度的优化 在前一篇的示例代码里面，只是最简单地选择的最开头或最后面的元素作为划分，这对于乱序的数据还好，对于有序的数据这么做，时间复杂度就直接变成$O(n^2)$了，那么怎么解决？第一个要解决的反而不是划分元素的选择上，而是改成intro sort，记录递归深度或类似的办法，到达限制条件的时候改而使用堆排序，这属于混合排序，先让排序的最坏时间复杂度降下来是第一要务。所以可以改写出以下代码：\n","tags":["算法","排序","快速排序","c","c++","stl"],"title":"Quick sort(快速排序)杂谈 2","type":"post"},{"authors":null,"categories":["研究"],"content":"所谓毕氏（毕达哥拉斯）三元数（Pythagorean triple），又叫做勾股数，商高数，是由毕氏定理衍生出来的，即直角三角形两直角边的平方和等于第三边的平方。毕氏三元数就是满足方程 $a^2+b^2=c^2$ 的正整数解，例如3,4,5这组解，以下我们用 $(3,4,5)$ 来表示一组毕氏三元数。这里存在一个问题，有没有可能表示出所有的正整数解呢？\n假设我们随意取直角边的长度，例如1和2，那么斜边长为 $\\sqrt{5}$ ，斜边长度不是整数，那怎么把它变成整数呢，很简单，直接平方一下，可是两直角边就不对了，那怎么解决呢？标题上已经剧透了我们要使用复数，那么，我们可以把斜边看成是一个复数，而两直角边分别是复数的实部和虚部，那么我们就可以把刚刚例子中的直角三角形用 $2+i$ 来表示，那我们对这个复数计算平方，$(2+i)(2+i)=4+4i-1=3+4i$，这个复数的模就是5。哎？我们看到了这是啥？是不是正好表示 $(3,4,5)$ ，这是巧合吗？\n我们再来换一组，就 $3+2i$ 吧，平方一下，得到 $(3+2i)(3+2i)=9+12i-4=5+12i$ ，模是13，表示的是 $(5,12,13)$ 。刚刚的都是实部比虚部要大的，再试试虚部大的 $(2+3i)(2+3i)=4+12-9=-5+12i$ ，得到的是方程的负数解。你继续试验其它的值的话将得到更多的毕氏三元数。\n首先我们要知道一个结论，实部虚部都是整数的复数，它平方后实部虚部仍然是整数，同时它的模也会得到整数，那么它的实部虚部的平方和，就等于模的平方。例如 $(a+bi)(a+bi)=a^2+2abi-b^2=a^2-b^2+2abi$ ，而这个复数的模是 $a^2+b^2$，于是我们得到毕氏三元数的整数解公式\n$$(u^2-v^2,2uv,u^2+v^2)$$\n接下来我们用另一种方法证明\n根据原式公式 $a^2+b^2=c^2$ ，我们假定a与b互质，那么可推论a,b,c两两互质，又称为素三元数。原式子可以改写为 $a^2=c^2-b^2=(c+b)(c-b)$ 那么 $\\frac{a}{c-b}=\\frac{c+b}{a}$ ，令 $\\frac{c-b}{a}=\\frac{c}{a}-\\frac{b}{a}=\\frac{n}{m}$ ，其中$m,n$都是正整数且互质，得$\\frac{c+b}{a}=\\frac{c}{a}+\\frac{b}{a}=\\frac{m}{n}$ 两式相加得\n$$\\frac{c}{a}=\\frac{1}{2}(\\frac{n}{m}+\\frac{m}{n})=\\frac{m^2+n^2}{2mn}$$\n两式相减得\n$$\\frac{b}{a}=\\frac{1}{2}(\\frac{m}{n}-\\frac{n}{m})=\\frac{m^2-n^2}{2mn}$$\n因为我们需要$a,b,c$都是正整数，所以$\\frac{c}{a}$与$\\frac{b}{a}$是有理数且不可约简（它们之间互质），而且两数分母一样，而这两个等式右边分母都是$2mn$，即式子左右两边分母相等，所以$a=2mn$且$\\frac{m^2+n^2}{2mn}$与$\\frac{m^2-n^2}{2mn}$不可约简（互质）。另外因为分母一定是偶数，所以$m,n$当中必须一个奇数一个偶数。由此解得三元数公式与前面完全一致。\n那有没有这个公式无法表示的毕氏三元数呢，我们假设这个无法表示的三元数是$(a\u0026rsquo;,b\u0026rsquo;,c\u0026rsquo;)$，那么c-b是个正整数，所以$\\frac{c-b}{a}$一定是有理数，满足 $\\frac{c-b}{a}=\\frac{n}{m}$ 的唯一的一对素质m与n必定存在，而通过这个m与n必定能通过上面的公式表示出$(a\u0026rsquo;,b\u0026rsquo;,c\u0026rsquo;)$，但前提是a,b,c之间两两互质，在这个前提下，与前面假设矛盾，所以这个公式能表示所有的素毕氏三元数，但不能表示所有的毕氏三元数。\n那咱们回到复数表示法上，对于任意的 $(a,b,c)$ ，相应的复数定义为 $a+bi$ ，再通过前面的公式替换为 $m^2-n^2+2mni$ ，然后我们来求解 $\\sqrt{m^2-n^2+2mni}=m+ni$，即任意整系数复数的平方，均能表示一组毕氏三元数。\n","date":1571379420,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571379420,"objectID":"a264e11f57c330fe22542f28321d1aff","permalink":"/post/20191018-pythagorean-triple/","publishdate":"2019-10-18T14:17:00+08:00","relpermalink":"/post/20191018-pythagorean-triple/","section":"post","summary":"所谓毕氏（毕达哥拉斯）三元数（Pythagorean triple），又叫做勾股数，商高数，是由毕氏定理衍生出来的，即直角三角形两直角边的平方和等于第三边的平方。毕氏三元数就是满足方程 $a^2+b^2=c^2$ 的正整数解，例如3,4,5这组解，以下我们用 $(3,4,5)$ 来表示一组毕氏三元数。这里存在一个问题，有没有可能表示出所有的正整数解呢？\n假设我们随意取直角边的长度，例如1和2，那么斜边长为 $\\sqrt{5}$ ，斜边长度不是整数，那怎么把它变成整数呢，很简单，直接平方一下，可是两直角边就不对了，那怎么解决呢？标题上已经剧透了我们要使用复数，那么，我们可以把斜边看成是一个复数，而两直角边分别是复数的实部和虚部，那么我们就可以把刚刚例子中的直角三角形用 $2+i$ 来表示，那我们对这个复数计算平方，$(2+i)(2+i)=4+4i-1=3+4i$，这个复数的模就是5。哎？我们看到了这是啥？是不是正好表示 $(3,4,5)$ ，这是巧合吗？\n","tags":["数学","复数","数论"],"title":"毕氏三元数与复数","type":"post"},{"authors":null,"categories":["笔记"],"content":"本篇补充smooth sort和weakheap sort，不打算做太多介绍，因为自己太菜不会讲，只作为笔记来记录一下实现代码。smooth sort在接近排序完成的情况下的动态图\n\nsmooth sort // http://www.keithschwarz.com/smoothsort/ static const unsigned int leonardo[] = { 1, 1, 3, 5, 9, 15, 25, 41, 67, 109, 177, 287, 465, 753, 1219, 1973, 3193, 5167, 8361, 13529, 21891, 35421, 57313, 92735, 150049, 242785, 392835, 635621, 1028457, 1664079, 2692537, 4356617, 7049155, 11405773, 18454929, 29860703, 48315633, 78176337, 126491971, 204668309, 331160281, 535828591, 866988873, 1402817465, 2269806339u, 3672623805u, }; template\u0026lt;typename RandomAccessIterator, class Comp\u0026gt; void smooth_sort_fix(RandomAccessIterator arr, size_t current_heap, int level_index, int levels[], Comp compare) { while (level_index \u0026gt; 0) { size_t prev_heap = current_heap - leonardo[levels[level_index]]; if (compare(arr[current_heap], arr[prev_heap])) { if (levels[level_index] \u0026gt; 1) { size_t child_heap2 = current_heap - 1; size_t child_heap1 = child_heap2 - leonardo[levels[level_index] - 2]; if (compare(arr[prev_heap], arr[child_heap1]) || compare(arr[prev_heap], arr[child_heap2])) break; } std::swap(arr[current_heap], arr[prev_heap]); current_heap = prev_heap; level_index -= 1; } else break; } int current_level = levels[level_index]; while (current_level \u0026gt; 1) { size_t max_child = current_heap; size_t child_heap2 = current_heap - 1; size_t child_heap1 = child_heap2 - leonardo[current_level - 2]; if (compare(arr[max_child], arr[child_heap1])) max_child = child_heap1; if (compare(arr[max_child], arr[child_heap2])) max_child = child_heap2; if (max_child == child_heap1) { std::swap(arr[current_heap], arr[child_heap1]); current_heap = child_heap1; current_level -= 1; } else if (max_child == child_heap2) { std::swap(arr[current_heap], arr[child_heap2]); current_heap = child_heap2; current_level -= 2; } else break; } } template\u0026lt;typename RandomAccessIterator, class Comp\u0026gt; void smooth_sort(RandomAccessIterator arr, size_t size, Comp compare) { int levels[64] = { 1 }; int toplevel = 0; for (size_t i = 1; i \u0026lt; size; ++i) { if (toplevel \u0026gt; 0 \u0026amp;\u0026amp; levels[toplevel - 1] - levels[toplevel] == 1) { toplevel -= 1; levels[toplevel] += 1; } else if (levels[toplevel] != 1) { toplevel += 1; levels[toplevel] = 1; } else { toplevel += 1; levels[toplevel] = 0; } smooth_sort_fix(arr, i, toplevel, levels, compare); } for (size_t i = size - 2; i \u0026gt; 0; --i) { if (levels[toplevel] \u0026lt;= 1) { toplevel -= 1; } else { levels[toplevel] -= 1; levels[toplevel + 1] = levels[toplevel] - 1; toplevel += 1; smooth_sort_fix(arr, i - leonardo[levels[toplevel]], toplevel - 1, levels, compare); smooth_sort_fix(arr, i, toplevel, levels, compare); } } } template\u0026lt;typename RandomAccessIterator, class Comp\u0026gt; void smooth_sort(RandomAccessIterator beg, RandomAccessIterator end, Comp compare) { if (end - beg \u0026gt; 1) { smooth_sort(\u0026amp;*beg, (size_t)(end - beg), compare); } } template\u0026lt;typename RandomAccessIterator\u0026gt; void smooth_sort(RandomAccessIterator beg, RandomAccessIterator end) { smooth_sort(beg, end, std::less\u0026lt;typename std::iterator_traits\u0026lt;RandomAccessIterator\u0026gt;::value_type\u0026gt;()); }  weakheap sort unsigned char weakheap_getflag(unsigned char *r, size_t index) { return (r[index \u0026gt;\u0026gt; 3] \u0026gt;\u0026gt; (index \u0026amp; 7)) \u0026amp; 1; } template\u0026lt;typename RandomAccessIterator, class Comp\u0026gt; void weakheap_merge(unsigned char flags[], RandomAccessIterator beg, RandomAccessIterator i, RandomAccessIterator j, Comp compare) { if (compare(*i, *j)) { flags[(j - beg) \u0026gt;\u0026gt; 3] ^= 1 \u0026lt;\u0026lt; ((j - beg) \u0026amp; 7); std::swap(*i, *j); } } template\u0026lt;typename RandomAccessIterator, class Comp\u0026gt; void weakheap_sort(RandomAccessIterator beg, RandomAccessIterator end, Comp compare) { if (end - beg \u0026gt; 1) { size_t n = (size_t)(end - beg); unsigned char * flags = new unsigned char[(n + 7) / 8]; for (size_t i = 0; i \u0026lt; n / 8; ++i) flags[i] = 0; for (size_t i = n - 1; i \u0026gt; 0; --i) { size_t j = i; while ((j \u0026amp; 1) == weakheap_getflag(flags, j \u0026gt;\u0026gt; 1)) j \u0026gt;\u0026gt;= 1; weakheap_merge(flags, beg, beg + (j \u0026gt;\u0026gt; 1), beg + i, compare); } for (size_t i = n - 1; i \u0026gt; 1; --i) { std::swap(*beg, *(beg + i)); size_t j = 1, k; while ((k = 2 * j + weakheap_getflag(flags, j)) \u0026lt; i) j = k; while (j \u0026gt; 0) { weakheap_merge(flags, beg, beg, beg + j, compare); j \u0026gt;\u0026gt;= 1; } } std::swap(*beg, *(beg + 1)); delete[] flags; } } template\u0026lt;typename RandomAccessIterator\u0026gt; void weakheap_sort(RandomAccessIterator beg, RandomAccessIterator end) { weakheap_sort(beg, end, std::less\u0026lt;typename std::iterator_traits\u0026lt;RandomAccessIterator\u0026gt;::value_type\u0026gt;()); } ","date":1571303640,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571303640,"objectID":"caf90dddb7361fbc70da6665a292ef3d","permalink":"/post/20191017-weakheapsort/","publishdate":"2019-10-17T17:14:00+08:00","relpermalink":"/post/20191017-weakheapsort/","section":"post","summary":"本篇补充smooth sort和weakheap sort，不打算做太多介绍，因为自己太菜不会讲，只作为笔记来记录一下实现代码。smooth sort在接近排序完成的情况下的动态图\n\n","tags":["算法","排序","weakheap sort","smooth sort","c++"],"title":"smooth sort与weakheap sort实现","type":"post"},{"authors":null,"categories":["研究"],"content":"堆排序其实是最不好优化的一个，在数据结构都确定的情况下，优化空间太小，除非优化数据结构本身，但那样就不叫做堆排序了。类似堆排序的还有smooth sort和weakheap sort，有兴趣可以自己查找相关资料。\n堆排序原理 堆排序其实是选择排序的优化变种，选择排序是把最大或最小的元素放到最边上，然后不断重复以上过程，堆排序也是如此，只不过堆排序通过构建数据结构，让查找最大或最小元素并放到最边上的速度比选择排序快得多。\n首先我们先来介绍什么是堆。堆只是个缩写，全名是二叉堆，是一种完全二叉树，它的特点是二叉堆的父节点元素不小于子节点的元素，以下为二叉堆例图\ngraph TD; 30--\u0026gt;29 30--\u0026gt;28 29--\u0026gt;24 29--\u0026gt;25 28--\u0026gt;26 28--\u0026gt;22 24--\u0026gt;21  根节点是最大值的时候，就叫做最大堆，反之叫做最小堆。之所以使用完全二叉堆，是为了它能直接放到数组里，例如上图放数组里的结果是：\n   下标 0 1 2 3 4 5 6 7     值 30 29 28 24 25 26 22 21    可以看出，就是按层序遍历的结果。这样表示的好处是，可以通过下标的简单运算得到子节点的下标，我们通过简单找规律就能发现，下标k的子节点是2k+1和2k+2，所以我们能直接在数组里组织一个二叉堆。而且堆的根节点就是最值，找最值的时间复杂度是O(1)\n那么假如堆结构已经组织好了，我们接下来看怎么排序，还是以刚刚的数组作为例子，下标0就是最大值，那么我们就把它拿出来，与最右边元素交换，得到\n   下标 0 1 2 3 4 5 6 7     值 21 29 28 24 25 26 22 30   指针 r a b         下标7的是已经排好的，后面不管它。这时候堆的性质破坏了，我们要去修正，指针r的子结点分别是a和b，在r,a,b中找出最大的元素a与r交换，得到\n   下标 0 1 2 3 4 5 6     值 29 21 28 24 25 26 22   指针  r  a b      再继续操作\n   下标 0 1 2 3 4 5 6     值 29 25 28 24 21 26 22   指针     r      这时候，指针r已经没有子结点，这时候堆就修正好了。这个过程由于是从根向叶子的操作，叫做shiftdown，还有一种相反的过程叫做shiftup，就是从叶子向根的方向操作。以上就是一轮完整的操作，包括交换最值，修正堆两步。不断循环以上操作直到所有元素有序即可。\n排序方法说完了，我们回头来说怎么构建堆。用shiftup法描述起来比较简单，一开始，只看下标0，那一个元素就肯定是堆。然后添加一个元素在最末，然后shiftup，修改新添加的元素，如此循环。伪代码如下\nmakeheap(arr, len) for i in (1, len) shiftup(arr, i)  而使用shiftdown的话，原理一样，只是换一个方向\nmakeheap(arr, len) for i in (len / 2, 1) shiftdown(arr, i)  以下为完整动态图演示\n\n堆排序基本实现 以下shiftdown实现的函数名是max_heapify\nvoid max_heapify(sort_element_t arr[], size_t index, size_t length) { size_t child; sort_element_t temp = arr[index]; for (; (child = 2 * index + 1) \u0026lt; length; index = child) { if (child + 1 \u0026lt; length \u0026amp;\u0026amp; arr[child] \u0026lt; arr[child + 1]) ++child; if (temp \u0026lt; arr[child]) arr[index] = arr[child]; else break; } arr[index] = temp; } void heap_sort(sort_element_t arr[], size_t length) { if (length \u0026gt; 1) { for (size_t i = length / 2; i-- \u0026gt; 0; ) max_heapify(arr, i, length); for (size_t i = length - 1; i \u0026gt; 0; --i) { sort_element_swap(\u0026amp;arr[0], \u0026amp;arr[i]); max_heapify(arr, 0, i); } } } void heap_sort(sort_element_t* beg, sort_element_t* end) { heap_sort(beg, end - beg); }  堆排序\u0026rdquo;优化\u0026rdquo; 我们来重新看原来的表\n   下标 0 1 2 3 4 5 6 7     值 30 29 28 24 25 26 22 21    这里下标k的子节点是2k+1和2k+2，运算起来麻烦，那我们如果把所有的下标加1，得到\n   下标 1 2 3 4 5 6 7 8     值 30 29 28 24 25 26 22 21    这时候，下标k的子节点是2k和2k+1，能减少一步加法运算\n所以可以得到以下模板代码\ntemplate \u0026lt;class RandomAccessIterator, class Comp\u0026gt; void max_heapify(RandomAccessIterator arr, size_t index, size_t last, Comp compare) { typename std::iterator_traits\u0026lt;RandomAccessIterator\u0026gt;::value_type temp = arr[index]; size_t child; for (; (child = index \u0026lt;\u0026lt; 1) \u0026lt;= last; index = child) { if (child \u0026lt; last \u0026amp;\u0026amp; compare(*(arr + child), *(arr + child + 1))) ++child; if (compare(temp, *(arr + child))) *(arr + index) = *(arr + child); else break; } *(arr + index) = temp; } template \u0026lt;class RandomAccessIterator, class Comp\u0026gt; void heap_sort(RandomAccessIterator beg, RandomAccessIterator end, Comp compare) { if (end - beg \u0026gt; 1) { size_t length = (size_t)(end - beg); RandomAccessIterator parr = beg - 1; for (size_t i = length / 2; i \u0026gt; 0; --i) max_heapify_1(parr, i, length, compare); for (size_t i = length - 1; i \u0026gt; 0; --i) { std::swap(*beg, *(beg + i)); max_heapify_1(parr, 1, i, compare); } } } template \u0026lt;class RandomAccessIterator, class Comp\u0026gt; void heap_sort(RandomAccessIterator beg, RandomAccessIterator end, Comp compare) { heap_sort(beg, end, compare); }  但是，还是那句但是，这些所谓的优化到了不同编译器的手上结果可能会和你想象的不一样。这个在VS上是有效果的，但不幸的是这份代码在GCC下跑得并没有比原来的快，不过在GCC上办法还是有的，就是把下标操作全部换成指针，见代码\ntemplate \u0026lt;class RandomAccessIterator, class Comp\u0026gt; void max_heapify_p(RandomAccessIterator first, RandomAccessIterator target, RandomAccessIterator last, Comp compare) { typename std::iterator_traits\u0026lt;RandomAccessIterator\u0026gt;::value_type temp = *target; --first; RandomAccessIterator son; for (; (son = target + (target - first)) \u0026lt;= last; target = son) { if (son \u0026lt; last \u0026amp;\u0026amp; compare(*son, *(son + 1))) ++son; if (compare(temp, *son)) *target = *son; else break; } *target = temp; } template \u0026lt;class RandomAccessIterator, class Comp\u0026gt; void heap_sort_p(RandomAccessIterator beg, RandomAccessIterator end, Comp compare) { if (end - beg \u0026gt; 1) { for (RandomAccessIterator i = beg + (end - beg) / 2; i \u0026gt;= beg; --i) max_heapify_p(beg, i, end - 1, compare); for (; --end \u0026gt; beg; ) { std::swap(*beg, *end); max_heapify_p(beg, beg, end - 1, compare); } } }  这份代码比GCC STL中的make_heap/sort_heap实现来得快一些。完整实现可以参见我的sort项目\n堆排序其它注意问题 堆排序在特殊情况下是能以O(n)复杂度完成的，就是当几乎所有元素或所有元素都相等的时候，是可以很快完成的。但是VS和GCC的STL中的堆排序实现面对这种情形时却花费较多的时间，原因是对相等元素的处理上，我们拿最前面的代码作为例子，我们如果改成这样子：\nvoid max_heapify(sort_element_t arr[], size_t index, size_t length) { size_t child; sort_element_t temp = arr[index]; for (; (child = 2 * index + 1) \u0026lt; length; index = child) { if (child + 1 \u0026lt; length \u0026amp;\u0026amp; arr[child] \u0026lt; arr[child + 1]) ++child; if (temp \u0026lt;= arr[child]) // 小于改小于等于 arr[index] = arr[child]; else break; } arr[index] = temp; }  或者是\nvoid max_heapify(sort_element_t arr[], size_t index, size_t length) { size_t child; sort_element_t temp = arr[index]; for (; (child = 2 * index + 1) \u0026lt; length; index = child) { if (child + 1 \u0026lt; length \u0026amp;\u0026amp; arr[child] \u0026lt; arr[child + 1]) ++child; if (arr[child] \u0026lt; temp) // 小于才跳出，与前一个等价 break; arr[index] = arr[child]; } arr[index] = temp; }  这样导致的后果是不存在最优情况下O(n)的时间复杂度。最后再来回应开头的问题，什么很少听说smooth sort和weakheap sort呢？单从时间复杂度其实看不出来不用它们的理由，但真正的问题是时间常数的问题，对普通的乱序数组，smooth sort和weakheap sort比heap sort慢，而且实现更复杂。\n","date":1571143972,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571143972,"objectID":"370a84fccaf1feceb53ee4089dd112e3","permalink":"/post/20191015-sorting-3/","publishdate":"2019-10-15T20:52:52+08:00","relpermalink":"/post/20191015-sorting-3/","section":"post","summary":"堆排序其实是最不好优化的一个，在数据结构都确定的情况下，优化空间太小，除非优化数据结构本身，但那样就不叫做堆排序了。类似堆排序的还有smooth sort和weakheap sort，有兴趣可以自己查找相关资料。\n堆排序原理 堆排序其实是选择排序的优化变种，选择排序是把最大或最小的元素放到最边上，然后不断重复以上过程，堆排序也是如此，只不过堆排序通过构建数据结构，让查找最大或最小元素并放到最边上的速度比选择排序快得多。\n首先我们先来介绍什么是堆。堆只是个缩写，全名是二叉堆，是一种完全二叉树，它的特点是二叉堆的父节点元素不小于子节点的元素，以下为二叉堆例图\ngraph TD; 30--\u0026gt;29 30--\u0026gt;28 29--\u0026gt;24 29--\u0026gt;25 28--\u0026gt;26 28--\u0026gt;22 24--\u0026gt;21 ","tags":["算法","排序","堆排序","c","c++"],"title":"堆排序优化思路","type":"post"},{"authors":null,"categories":["笔记"],"content":"这里记录的是素数判断 Miller Rabbin 的快速判定算法，而分解使用的算法是 Pollard Rho 的玄学分解算法，这个算法的理论依据是生日悖论，这里不具体讨论这个数学问题，具体讨论看前面链接就可以了。\n以下我们分别简要介绍这两个算法的原理\n首先这是Miller Rabbin的维基百科介绍页，由于页面是中文，这里不做重复介绍。\n下面简要解释一下Pollard\u0026rsquo;s Rho算法的原理，这是它的维基百科页面\n首先我们来定义这样一个函数\n$$f(x)=(x*x+c)%n$$\n其中n是需要被分解的数，c是一个任意小于n的正整数常数。那么我们给一个初始值x1，通过计算 $f(x1)$ 得到x2，然后去求 $|x1-x2|$ 与 n 的最大公约数，只要结果大于1就找到了分解结果。那如果最大公约数仍然是1，那么就通过刚才的x2求出 $x3=f(x2)$ 并计算 $|x1-x3|$ 与 n 的最大公约数。也就是说，我们可以通过这个公式得到一个数列\n$$ x1,x2,x3,\u0026hellip;,xn,\u0026hellip; $$\n但这个数列总是不会无限的，总是会循环的，那怎么去判断它有没有陷入循环呢，这用到的办法是Floyd判环算法，两个数在数列里以不同速度前进，如果环存在，那它们总会有相遇的时刻。在代码里，我们令变量x是正常速度，变量y是在x每迭代两次后y再迭代一次，所以如果环的长度是k，那么迭代k次就能发现环的存在。\n而在具体实现中，如果发现环的存在，我们需要变换常数c，再次进行尝试。那么我们下面不废话直接上代码，作为笔记。为了避免部分环境的输入输出问题，main函数使用了C++的输入输出，其它部分可以作为C函数使用。\n#include\u0026lt;iostream\u0026gt; #include\u0026lt;cstdint\u0026gt; int64_t gcd(int64_t a, int64_t b) { return b == 0 ? a : gcd(b, a%b); } int64_t mul(int64_t a, int64_t b, int64_t mod) { a %= mod; int64_t res = 0; while (b) { if (b \u0026amp; 1) res = (res + a) % mod; b \u0026gt;\u0026gt;= 1; a = (a \u0026lt;\u0026lt; 1) % mod; } return res; } int64_t quick_pow(int64_t a, int64_t n, int64_t mod) { int64_t res = 1; while (n) { if (n \u0026amp; 1) res = mul(res, a, mod); a = mul(a, a, mod); n \u0026gt;\u0026gt;= 1; } return res; } int miller_rabbin(int64_t n, int a) { int r = 0; int64_t s = n - 1; if (!(n % a)) return 0; while (!(s \u0026amp; 1)) { s \u0026gt;\u0026gt;= 1; r++; } int64_t k = quick_pow(a, s, n); if (k == 1) return 1; for (int j = 0; j \u0026lt; r; j++, k = mul(k, k, n)) if (k == n - 1) return 1; return 0; } int is_prime(int64_t n) { int test_large[] = { 2, 3, 5, 7, 11, 13, 17, 19, 23 }; int test_small[] = { 2, 7, 61 }; int test_size = 9, *test = test_large; if (n \u0026lt; 2) return 0; if (n \u0026lt; 4759123141) { test = test_small; test_size = 3; } for (int i = 0; i \u0026lt; test_size; ++i) { if (n == test[i]) return 1; if (miller_rabbin(n, test[i]) == 0) return 0; } return 1; } int64_t pollard_rho(int64_t n, int c) { int64_t x = rand() % (n - 1) + 1, y; y = x = (mul(x, x, n) + c) % n; for (int n_try = 3, i = 0; n_try; ) { x = (mul(x, x, n) + c) % n; if (y == x) { --n_try; c = rand() % (n - 1) + 1; continue; } int64_t d = gcd((y - x + n) % n, n); if (d != 1 \u0026amp;\u0026amp; d != n) return d; if (++i == 2) { y = (mul(y, y, n) + c) % n; i = 0; } } return n; } int main(void) { int64_t n; std::cout \u0026lt;\u0026lt; \u0026quot;质数计算器，请输入任意小于1e18的正整数\u0026quot; \u0026lt;\u0026lt; std::endl; while (std::cin \u0026gt;\u0026gt; n) { if (is_prime(n)) { std::cout \u0026lt;\u0026lt; n \u0026lt;\u0026lt; \u0026quot;是质数\u0026quot; \u0026lt;\u0026lt; std::endl; } else if (n \u0026gt; 2) { int64_t p = pollard_rho(n, rand() % (n - 1) + 1); std::cout \u0026lt;\u0026lt; n \u0026lt;\u0026lt; \u0026quot;不是质数，能被\u0026quot; \u0026lt;\u0026lt; p \u0026lt;\u0026lt; \u0026quot;整除\u0026quot; \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026quot;请输入大于1小于1e18的整数\u0026quot; \u0026lt;\u0026lt; std::endl; } } return 0; }  以下为python版本实现\nimport random def _try_composite(a, d, n, s): if pow(a, d, n) == 1: return False for i in range(s): if pow(a, 2**i * d, n) == n-1: return False return True def _is_prime(n): if n in _known_primes: return True if n \u0026lt; 2 or any((n % p) == 0 for p in _known_primes): return False return True def is_prime(n, _precision_for_huge_n = 32): if n in _known_primes: return True d, s = n - 1, 0 while not d % 2: d, s = d \u0026gt;\u0026gt; 1, s + 1 if n \u0026lt; 4759123141: return not any(_try_composite(a, d, n, s) for a in (2, 7, 61)) if n \u0026lt; 1122004669633: return not any(_try_composite(a, d, n, s) for a in (2, 13, 23, 1662803)) if n \u0026lt; 3317044064679887385961981: return not any(_try_composite(a, d, n, s) for a in (2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41)) return not any(_try_composite(a, d, n, s) for a in _test_primes[:_precision_for_huge_n]) _known_primes = [2, 3] _known_primes += [x for x in range(5, 1000, 2) if _is_prime(x)] _test_primes = [2,3,307] + _known_primes[2:] def gcd(a, b): if b == 0: return a return gcd(b, a%b) def pollard_rho(n): x, c, 0 = random.randint(1, n - 1), random.randint(1, n - 1), 0 y = x = (pow(x, 2, n) + c) % n for n_try in range(3): while True: x = (pow(x, 2, n) + c) % n if x == y: c = random.randint(1, n - 1) break d = gcd(y - x + n, n) if d \u0026gt; 1 and d \u0026lt; n: return d a += 1 if a == 2: y = (pow(y, 2, n) + c) % n a = 0 return n number = 3451973391686190983 for i in range(number, number + 100, 2): if is_prime(i): print(i) break if is_prime(number): print(number, \u0026quot;prime number\u0026quot;) else: a = pollard_rho(number) print(number, \u0026quot;=\u0026quot;, a, \u0026quot;*\u0026quot;, number // a) ","date":1570952220,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570952220,"objectID":"88315dfb1104fd2991fcf635163c0b6a","permalink":"/post/20191013-prime-number/","publishdate":"2019-10-13T15:37:00+08:00","relpermalink":"/post/20191013-prime-number/","section":"post","summary":"这里记录的是素数判断 Miller Rabbin 的快速判定算法，而分解使用的算法是 Pollard Rho 的玄学分解算法，这个算法的理论依据是生日悖论，这里不具体讨论这个数学问题，具体讨论看前面链接就可以了。\n以下我们分别简要介绍这两个算法的原理\n首先这是Miller Rabbin的维基百科介绍页，由于页面是中文，这里不做重复介绍。\n下面简要解释一下Pollard\u0026rsquo;s Rho算法的原理，这是它的维基百科页面\n首先我们来定义这样一个函数\n$$f(x)=(x*x+c)%n$$\n其中n是需要被分解的数，c是一个任意小于n的正整数常数。那么我们给一个初始值x1，通过计算 $f(x1)$ 得到x2，然后去求 $|x1-x2|$ 与 n 的最大公约数，只要结果大于1就找到了分解结果。那如果最大公约数仍然是1，那么就通过刚才的x2求出 $x3=f(x2)$ 并计算 $|x1-x3|$ 与 n 的最大公约数。也就是说，我们可以通过这个公式得到一个数列\n","tags":["算法","素数","c++","python","Miller Rabbin","Pollard's Rho"],"title":"素数判断和因子分解","type":"post"},{"authors":null,"categories":["笔记"],"content":"二进制位运算的技巧特别多，这里就做一份cheat sheet，希望能帮助到大家。不过过于简单的就不列举了\n单行表达式    作用 表达式     把右边连续的1变成0 n \u0026amp; ( n + 1 )   把右边第一个1变成0 n \u0026amp; ( n - 1 )   把右起第一个0变成1 n | ( n + 1 )   把右起连续的0变成1 n | ( n - 1 )   取右边连续的1 n ^ ( n + 1 )   去掉右起第一个1的左边 n \u0026amp; -n 或 n \u0026amp; ( n ^ ( n - 1 ) )   高低位交换，前x位 ( n \u0026lt;\u0026lt; x ) | ( x \u0026gt;\u0026gt; ( 32 - x ) )   有符号整数计算绝对值 ( n ^ (n \u0026gt;\u0026gt; 31) ) - (n \u0026gt;\u0026gt; 31)    多行的技巧 1. 两数交换不使用第三个变量 void swap(int* a, int* b) { *a ^= *b; *b ^= *a; *a ^= *b; }  2. 奇偶校验码 int check_bit(int n) { n ^= n \u0026gt;\u0026gt; 1; n ^= n \u0026gt;\u0026gt; 2; n ^= n \u0026gt;\u0026gt; 4; n ^= n \u0026gt;\u0026gt; 8; n ^= n \u0026gt;\u0026gt; 16; return n \u0026amp; 1; }  3. 计算二进制中的1的个数 uint32_t method_1_uint32_count1(uint32_t n) { n = (n \u0026amp; 0x55555555) + ((n \u0026gt;\u0026gt; 1) \u0026amp; 0x55555555); n = (n \u0026amp; 0x33333333) + ((n \u0026gt;\u0026gt; 2) \u0026amp; 0x33333333); n = (n \u0026amp; 0x0f0f0f0f) + ((n \u0026gt;\u0026gt; 4) \u0026amp; 0x0f0f0f0f); n = (n \u0026amp; 0x00ff00ff) + ((n \u0026gt;\u0026gt; 8) \u0026amp; 0x00ff00ff); n = (n \u0026amp; 0x0000ffff) + ((n \u0026gt;\u0026gt; 16) \u0026amp; 0x0000ffff); return n; } uint32_t method_2_uint32_count1(uint32_t n) { n = n - ((n \u0026gt;\u0026gt; 1) \u0026amp; 0x55555555); n = (n \u0026amp; 0x33333333) + ((n \u0026gt;\u0026gt; 2) \u0026amp; 0x33333333); n = (n + (n \u0026gt;\u0026gt; 4)) \u0026amp; 0x0f0f0f0f; n = n + (n \u0026gt;\u0026gt; 8); n = n + (n \u0026gt;\u0026gt; 16); return n \u0026amp; 0x3f; }  4. 计算下一组合 前提：我们使用一个整数的二进制位来代表对应集合上的元素有没有选中，从而来表达一个组合。当我们要遍历所有组合的时候，就可以用这个办法了\nint next_combination(int k) { int b = k \u0026amp; -k, t = (k + b); return (((t ^ k) \u0026gt;\u0026gt; 2) / b) | t; }  5. n皇后问题位运算实现 uint64_t queen(uint32_t row, uint32_t lb, uint32_t rb) { if (row == 0) return 1; uint64_t sum = 0; for (uint32_t r = row; r; r \u0026amp;= r - 1) { uint32_t p = r ^ (r \u0026amp; (r - 1)); if ((p \u0026amp; lb) == 0 \u0026amp;\u0026amp; (p \u0026amp; rb) == 0) sum += queen(row ^ p, (lb | p) \u0026lt;\u0026lt; 1, (rb | p) \u0026gt;\u0026gt; 1); } return sum; } uint64_t nqueen(int n) // 返回值为棋盘大小n时解的个数 { return queen(((uint32_t)1 \u0026lt;\u0026lt; n) - 1, 0, 0); }  6. 古老的快速平方根倒数 求 1/sqrt(n)，这段代码出自Quake-III Arena (雷神之锤3)源代码 /game/code/q_math.c，针对 IEEE 754 标准的单精度浮点格式\nfloat Q_rsqrt( float number ) { long i; float x2, y; const float threehalfs = 1.5F; x2 = number * 0.5F; y = number; i = * ( long * ) \u0026amp;y; // evil floating point bit level hacking i = 0x5f3759df - ( i \u0026gt;\u0026gt; 1 ); // what the fuck? y = * ( float * ) \u0026amp;i; y = y * ( threehalfs - ( x2 * y * y ) ); // 1st iteration // y = y * ( threehalfs - ( x2 * y * y ) ); // 2nd iteration, this can be removed #ifndef Q3_VM #ifdef __linux__ assert( !isnan(y) ); // bk010122 - FPE? #endif #endif return y; }  注：使用常数 0x5f375a86 可以使得结果误差更小，详见维基百科\n7. 绘画Sierpinski三角 #include \u0026lt;stdio.h\u0026gt; int main(void) { const int n = (1 \u0026lt;\u0026lt; 5); for (int i = 0; i \u0026lt; n; ++i) { for (int j = 0; j \u0026lt;= i; ++j) putchar( ( i \u0026amp; j ) == j ? '#' : ' '); printf(\u0026quot;\\n\u0026quot;); } return 0; }  输出结果\n# ## # # #### # # ## ## # # # # ######## # # ## ## # # # # #### #### # # # # ## ## ## ## # # # # # # # # ################ # # ## ## # # # # #### #### # # # # ## ## ## ## # # # # # # # # ######## ######## # # # # ## ## ## ## # # # # # # # # #### #### #### #### # # # # # # # # ## ## ## ## ## ## ## ## # # # # # # # # # # # # # # # # ################################ ","date":1570864680,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570864680,"objectID":"d7f604b5e2a0d4ff98302e3384050d66","permalink":"/post/20191012-binary-skill/","publishdate":"2019-10-12T15:18:00+08:00","relpermalink":"/post/20191012-binary-skill/","section":"post","summary":"二进制位运算的技巧特别多，这里就做一份cheat sheet，希望能帮助到大家。不过过于简单的就不列举了\n单行表达式    作用 表达式     把右边连续的1变成0 n \u0026amp; ( n + 1 )   把右边第一个1变成0 n \u0026amp; ( n - 1 )   把右起第一个0变成1 n | ( n + 1 )   把右起连续的0变成1 n | ( n - 1 )   取右边连续的1 n ^ ( n + 1 )   去掉右起第一个1的左边 n \u0026amp; -n 或 n \u0026amp; ( n ^ ( n - 1 ) )   高低位交换，前x位 ( n \u0026lt;\u0026lt; x ) | ( x \u0026gt;\u0026gt; ( 32 - x ) )   有符号整数计算绝对值 ( n ^ (n \u0026gt;\u0026gt; 31) ) - (n \u0026gt;\u0026gt; 31)   ","tags":["算法","二进制","c","c++","cheat sheet"],"title":"二进制技巧","type":"post"},{"authors":null,"categories":null,"content":" vrmei的博客 废江\u0026rsquo;s博客 备战acm小菜鸟的个人日常 burningdzb的博客 白月光__编程小萌新 徐南木blog 南木心屋  ","date":1570809600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570809600,"objectID":"76742f83502b2cf566f8baa2d043b7db","permalink":"/blogroll/","publishdate":"2019-10-12T00:00:00+08:00","relpermalink":"/blogroll/","section":"","summary":" vrmei的博客 废江\u0026rsquo;s博客 备战acm小菜鸟的个人日常 burningdzb的博客 白月光__编程小萌新 徐南木blog 南木心屋  ","tags":null,"title":"Blogroll","type":"page"},{"authors":null,"categories":["研究"],"content":"本篇针对插入排序和希尔排序来讲优化思路，有部分内容因为前一篇文章已经有交代，这里不重复，如果你还没有看，请先看前一篇。我们来看插入排序的动图演示\n\n插入排序保证前面一块是有序的情况下，新增的一个元素通过向前交换到合适的位置，所以叫做插入排序。\n插入排序基本实现 我们先来看插入排序的基本实现\nvoid insert_sort(sort_element_t * beg, sort_element_t * end) { for (sort_element_t* i = beg + 1; i \u0026lt; end; ++i) { sort_element_t val = *i; sort_element_t* j = i; for (; j \u0026gt; beg \u0026amp;\u0026amp; val \u0026lt; j[-1]; --j) { *j = j[-1]; } *j = val; } }  插入排序即使不做任何优化，效率也明显高于上篇所说的冒泡排序和选择排序。那么按照惯例，先上双向看看效果\n插入排序优化，双向插入 不过双向版本的插入排序可能并不是你想象中那么好写，甚至于有点不太好懂\n   点击展开  \nvoid double_insert_sort(sort_element_t * beg, sort_element_t * end) { if (end - beg \u0026gt; 1) { for (sort_element_t* i = beg + 1, *j = end - 1; ; ) { sort_element_t val = *i; sort_element_t* t = i; for (; t \u0026gt; beg \u0026amp;\u0026amp; val \u0026lt; t[-1]; --t) { *t = t[-1]; } *t = val; if (++i \u0026gt; j) { if (*i \u0026lt; *j) ++j; else break; } val = j[-1]; t = j; for (; t \u0026lt; end \u0026amp;\u0026amp; *t \u0026lt; val; ++t) { t[-1] = *t; } t[-1] = val; if (i \u0026gt; --j) { if (*j \u0026lt; j[-1]) --i; else break; } } } }  \n我们来看看测试结果，在 VS2015 下对 45000 个int排序\n   int 1 2 3 4 5 6 7 8 9 10 Avg     insert2 0 0 376 165 174 176 177 0 0 80 114   insert 0 0 359 165 174 177 192 0 0 86 115   odd_even 0 0 575 1259 1242 1224 532 0 2 855 568   cocktail 0 0 1252 1474 1537 1611 642 1 2 813 733   select2 0 1068 809 1076 1082 1073 1072 1074 1073 1065 939   bubble 0 0 1192 2190 2220 2193 832 1 4 1376 1000   select 2159 2174 2157 2137 2166 2160 2155 2149 2146 2138 2154    这个优化效果非常不明显，有种吃力不讨好的感觉。那么，我们换个方法，来试试加大步长吧，这个变动让算法有了另一个名字\n希尔排序 希尔排序的坑特别深，你需要有心理准备。希尔排序和梳排序类似，都是通过使用较大的步长让元素更快速地到达正确位置附近\n\n不过在步长的选择上，希尔排序与梳排序差别巨大。首先梳排序的步长选择较为简单，每次乘以0.8即可，这个数字就不要管怎么来的了，我也不知道。梳排序的研究资料较少，但希尔排序则不一样，步长选择的研究非常多，也就是说光是步长的选择就是一门学问，这就是一个大坑，而且这个步长选择对性能的影响十分明显。我们先来看最早的希尔排序版本，最早的版本使用步长每次乘以0.5。\nvoid shell_sort_0_5(sort_element_t * beg, sort_element_t * end) { if (end - beg \u0026gt; 1) { size_t incre = (size_t)(end - beg) / 2; for (; incre \u0026gt;= 1; incre /= 2) { sort_element_t * bound = beg + incre; for (sort_element_t * i = bound; i \u0026lt; end; ++i) { sort_element_t * p = i; sort_element_t val = *i; for (; p \u0026gt;= bound \u0026amp;\u0026amp; val \u0026lt; *(p - incre); p -= incre) *p = *(p - incre); *p = val; } } } }  后来，Pratt 与 Knuth 改进了新的步长序列\n1, 4, 13, 40, 121, ...\n得到以下代码\nvoid shell_sort(sort_element_t * beg, sort_element_t * end) { if (end - beg \u0026gt; 1) { size_t incre = 1; while (incre \u0026lt; (size_t)(end - beg - 1) / 3) incre = incre * 3 + 1; // A003462, Pratt, 1971, Knuth, 1973 for (; incre \u0026gt;= 1; incre /= 3) { sort_element_t * bound = beg + incre; for (sort_element_t * i = bound; i \u0026lt; end; ++i) { sort_element_t * p = i; sort_element_t val = *i; for (; p \u0026gt;= bound \u0026amp;\u0026amp; val \u0026lt; *(p - incre); p -= incre) *p = *(p - incre); *p = val; } } } }  更多关于步长的研究可以参考维基百科，本篇不对步长做讲解。后文的优化将使用这个版本的代码\n希尔排序优化，运用带哨兵的插入排序 带哨兵的插入排序是什么东西？其实就是指以下这样的插入排序\nvoid unguarded_insert_sort(sort_element_t * beg, sort_element_t * end) { for (sort_element_t* i = beg + 1; i \u0026lt; end; ++i) { sort_element_t val = *i; sort_element_t* j = i; for (; val \u0026lt; j[-1]; --j) { *j = j[-1]; } *j = val; } }  和前面的插入排序的区别在哪？就是少了j \u0026gt; beg \u0026amp;\u0026amp;，不做边界判断。不做边界判断确实能运行得更快，但不会越界吗？我们来考虑以下这种情况\nint arr[8] = {-1, 8, 9, 4, 5, 6, 1, 6};\n然后我们排序的时候写unguarded_insert_sort(arr + 1, arr + 8);它就能正确排序而且不会发生越界，因为最前面存在比需要排序的元素都要小的数，而那个数就是哨兵，它充当着让内循环退出的作用，也就是说，在调用这个函数的时候，只要保证beg的左边存在比右边都要小的元素就行了。\n有了这个能怎么优化呢？我们把步长1的部分单独拆出来，写成下面这样\nvoid shell_sort_o1(sort_element_t * beg, sort_element_t * end) { if (end - beg \u0026gt; 1) { size_t incre = 1; while (incre \u0026lt; (size_t)(end - beg - 1) / 3) incre = incre * 3 + 1; // A003462, Pratt, 1971, Knuth, 1973 for (; incre \u0026gt; 1; incre /= 3) { sort_element_t * bound = beg + incre; for (sort_element_t * i = bound; i \u0026lt; end; ++i) { sort_element_t * p = i; sort_element_t val = *i; for (; p \u0026gt;= bound \u0026amp;\u0026amp; val \u0026lt; *(p - incre); p -= incre) *p = *(p - incre); *p = val; } } insert_sort(beg, end); } }  这个能理解吧，步长1的时候完全就是插入排序，但真正厉害的在下面这步，要注意到这种写法在变为步长1之前，它的步长是4，我们可以证明整个数组的最小值一定在前4个数中，即前一个步长的范围内。这里不给出具体证明，有兴趣你可以自己试试证明。有了这个结论，前4个元素用插入排序排好了后，后面的就可以使用unguarded_insert_sort了\nvoid shell_sort_o2(sort_element_t * beg, sort_element_t * end) { if (end - beg \u0026gt; 10) { size_t incre = 1; while (incre \u0026lt; (size_t)(end - beg - 1) / 3) incre = incre * 3 + 1; // A003462, Pratt, 1971, Knuth, 1973 for (; incre \u0026gt; 1; incre /= 3) { sort_element_t * bound = beg + incre; for (sort_element_t * i = bound; i \u0026lt; end; ++i) { sort_element_t * p = i; sort_element_t val = *i; for (; p \u0026gt;= bound \u0026amp;\u0026amp; val \u0026lt; *(p - incre); p -= incre) *p = *(p - incre); *p = val; } } insert_sort(beg, beg + 4); unguarded_insert_sort(beg + 4, end); } else { insert_sort(beg, end); } }  这个哨兵技巧在其它的排序里面甚至别的问题里同样也会存在。除了这个还有没有别的优化空间呢？例如，shellsort的最优情况下的时间复杂度还是O(nlogn)，那有没有办法使得最优情况时间复杂度下降到O(n)呢？确实有办法，如果在某一轮发现没有数进行交换，那么就立即转成带次数限制的插入排序进行尝试，具体请参阅我的sort项目。\n测试结果 以下是在 VS2015 上对 4,500,000 个int排序的测试\n   int 1 2 3 4 5 6 7 8 9 10 Avg     bao_shell 5 6 57 373 368 148 52 35 77 350 147   shell_o2 47 49 68 553 540 187 59 53 106 500 216   shell_sort 47 54 77 563 547 190 67 59 111 509 222   shell_0_5 80 89 114 606 601 236 82 89 143 572 261   comb_sort 166 161 180 492 477 214 171 169 223 478 273    其中bao_shell是我在sort项目中写的希尔排序，使用了更优的步长序列，里面包含更多的优化技巧，本篇就不一一介绍了。\n","date":1570711972,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570711972,"objectID":"ca48df74bf8be0f26c54d2e6620948f6","permalink":"/post/20191009-sorting-2/","publishdate":"2019-10-10T20:52:52+08:00","relpermalink":"/post/20191009-sorting-2/","section":"post","summary":"本篇针对插入排序和希尔排序来讲优化思路，有部分内容因为前一篇文章已经有交代，这里不重复，如果你还没有看，请先看前一篇。我们来看插入排序的动图演示\n\n插入排序保证前面一块是有序的情况下，新增的一个元素通过向前交换到合适的位置，所以叫做插入排序。\n插入排序基本实现 我们先来看插入排序的基本实现\nvoid insert_sort(sort_element_t * beg, sort_element_t * end) { for (sort_element_t* i = beg + 1; i \u0026lt; end; ++i) { sort_element_t val = *i; sort_element_t* j = i; for (; j \u0026gt; beg \u0026amp;\u0026amp; val \u0026lt; j[-1]; --j) { *j = j[-1]; } *j = val; } }  插入排序即使不做任何优化，效率也明显高于上篇所说的冒泡排序和选择排序。那么按照惯例，先上双向看看效果\n","tags":["算法","排序","插入排序","希尔排序","c","c++"],"title":"插入排序与希尔排序优化思路","type":"post"},{"authors":null,"categories":["研究"],"content":"本篇针对两种最基本的排序（冒泡、选择）来讲优化思路。越是简单的东西反而可能存在你越想不到的优化点。但是在开始之前，先给不了解的人讲一个设计原则的问题，我们在设计排序接口的时候，最为常见的有\nvoid sort(type arr[], int len)\n也许你也见过\nvoid sort(iter beg, iter end)\n这时候问题就来了，很多人会错误地把end认为是最后一个元素，其实不然，这两接口可以相互转换，例如我们可以写 sort(arr, arr + len) ，这样写很自然对不对，但如果你认为end是最后一个元素，那你就不得不改成 sort(arr, arr + len - 1) 。事实上，这类的接口我们需要一个统一的原则，就是左闭右开区间原则，即beg就是首个元素，而end是最后一个元素+1，即end是作为结束标志，不应该把end算在范围内。接下来下面所有的接口写法，都是以\nvoid sort(iter beg, iter end)\n这种方式写的，至于这样写有什么好处，接下来我们就看示例。\n选择排序 基本实现 我们先来看选择排序，因为它编写简单，而且最不容易出错，我们来看以下两种不同的接口写法，我们定义要排序的数据类型名字是sort_element_t，定义交换函数\nvoid sort_element_swap(sort_element_t *x, sort_element_t *y) { sort_element_t t = *x; *x = *y; *y = t; }  具体实现\nvoid select_sort(sort_element_t arr[], size_t len) //方式1 { for (size_t i = 0; i \u0026lt; len; ++i) { size_t head = i; for (size_t j = i + 1; j \u0026lt; len; ++j) { if (arr[j] \u0026lt; arr[head]) head = j; } sort_element_swap(arr + i, arr + head); } } void select_sort(sort_element_t * beg, sort_element_t * end) //方式2 { for (; beg \u0026lt; end; ++beg) { sort_element_t* head = beg; for (sort_element_t* i = beg + 1; i \u0026lt; end; ++i) { if (*i \u0026lt; *head) head = i; } sort_element_swap(beg, head); } }  就这么一眼看过去，看起来还真差不多，这样，我们再细分一下，选择排序的中间那步，其实就是找一个最小的元素，我们单独提取成一个独立函数再来看看\n//方式1 size_t find_min(sort_element_t arr[], size_t beg, size_t len) { size_t head = beg; for (size_t j = beg + 1; j \u0026lt; len; ++j) { if (arr[j] \u0026lt; arr[head]) head = j; } return head; } void select_sort(sort_element_t arr[], size_t len) { for (size_t i = 0; i \u0026lt; len; ++i) { sort_element_swap(arr + i, arr + find_min(arr, i, len)); } }  //方式2 sort_element_t* find_min(sort_element_t * beg, sort_element_t * end) { sort_element_t* head = beg; for (sort_element_t* i = beg + 1; i \u0026lt; end; ++i) { if (*i \u0026lt; *head) head = i; } return head; } void select_sort(sort_element_t * beg, sort_element_t * end) { for (; beg \u0026lt; end; ++beg) { sort_element_swap(beg, find_min(beg, end)); } }  仔细观察一下，是不是第二种写法函数参数统一，而且参数数量少，而且也少了很多不必要的加法运算（像方法一需要写arr + i这类）。如果你说方法一的find_min参数也可以只写两个，写成find_min(sort_element_t arr[], size_t len)，那么你在调用的地方将不得不写成find_min(arr + i, len - i)，这种又加又减在遇到更复杂的情况的时候，更容易把你弄晕出Bug。总之结论是最好把参数写成两个指针（或两个迭代器）的形式，不建议使用数组加长度的形式，STL的接口也全使用迭代器的形式。\n对于这个排序要注意的一点是，有人会写成类似下面的形式：\nvoid select_sort(sort_element_t arr[], size_t len) { for (size_t j = 0; j \u0026lt; len; ++j) { for (size_t i = j + 1; i \u0026lt; len; ++i) { if (arr[j] \u0026gt; arr[i]) { sort_element_t t = arr[j]; arr[j] = arr[i]; arr[i] = t; } } } }  以上这种叫做劣化版的选择排序，在大多数的情况下会比前一个方法慢，极端条件下甚至会慢1倍甚至更多\n那说完劣化再讲优化，选择排序的时间复杂度是$O(n^2)$，而且运行时间与原来的排列完全无关。以上的选择排序总是选择小的，那大小一起选呢？能不能起到优化的作用？如果你单纯的多写一个find_max变成双向选择来做，在VS2005下是没有优化效果的，我测试过了。那应该怎么样呢？确实还是双向选择，不过具体实现稍有点不同。\n优化1，双向选择 这里的实现是一个函数里同时把最大最小一起找，这样减少了一次遍历的过程，时间能减半之余，还有一个非常有用的优化，就是当你发现最大值等于最小值的时候能提前跳出\nsort_element_t* find_min_max( sort_element_t * beg, sort_element_t * end, sort_element_t** head_max) { sort_element_t* head = beg; *head_max = beg; for (sort_element_t* i = beg + 1; i \u0026lt; end; ++i) { if (*i \u0026lt; *head) head = i; else if (**head_max \u0026lt; *i) *head_max = i; } return head; } void double_select_sort(sort_element_t * beg, sort_element_t * end) { while (end - beg \u0026gt; 1) { sort_element_t * head_max, * head = find_min_max(beg, end, \u0026amp;head_max); if (head_max != head) { if (head_max == beg) head_max = head; sort_element_swap(beg++, head); sort_element_swap(--end, head_max); } else { break; } } }  与选择排序的运行时间比较如下，排序45000个int，编译环境是VS2015，用10组不同分布的数据，表格中的数字单位是毫秒，即排序用时\n   int 1 2 3 4 5 6 7 8 9 10 Avg     select2 0 1114 834 1113 1124 1124 1119 1124 1124 1141 981   select 2213 2238 2227 2229 2256 2242 2238 2241 2245 2260 2238    合理运用双向，效果也往往不错，但是千万要注意，环境不同会导致测试结果不相同，例如你换到mingw上使用-O3编译那么将会是select比select2快，所以上面数据只供参考，具体结果请自己做测试。\n优化2，数据结构 选择排序的优化主要是在find_min上面，find_min的时间复杂度是$O(n)$，那如果我们通过一些数据结构的组织，例如二叉堆，那么找最大或最小值时间将变成$O(1)$，而维护这个数据结构的代价是$O(logn)$的话，总体时间复杂度将变为$O(nlogn)$，这比起选择排序的$O(n^2)$就是一个巨大的变化，具体内容在之后的 堆排序 篇具体讲解。\n冒泡排序 基本实现 冒泡排序是我们课本必然介绍的一个排序，相对于选择排序，这种在编写的时候更容易出现逻辑错误，我们先来看典型的实现（双迭代器实现）\nvoid bubble_sort(sort_element_t * beg, sort_element_t * end) { for (; beg \u0026lt; end; --end) { for (sort_element_t * i = beg + 1; i \u0026lt; end; ++i) { if (*i \u0026lt; i[-1]) sort_element_swap(i - 1, i); } } }  冒泡排序这种写法，铁定的$O(n^2)$时间没跑，不过好在冒泡排序的优化方法也不少。\n优化1，提前跳出 void bubble_sort(sort_element_t * beg, sort_element_t * end) { for (; beg \u0026lt; end; --end) { int sorted = 1; for (sort_element_t * i = beg + 1; i \u0026lt; end; ++i) { if (*i \u0026lt; i[-1]) { sort_element_swap(i - 1, i); sorted = 0; } } if (sorted) break; } }  通过sorted变量记录某一轮是不是存在交换，如果没有交换则表明数据已经是有序的，可以提前退出循环。有这个优化对于已经有序的数据，冒泡排序将运行得特别快，即最优情况时间复杂度只有$O(n)$\n优化2，鸡尾酒排序 前面的冒泡写法是单向冒泡，把最大值向最右边移，这回我们做成双向，一边把最大值右移，一边把最小值左移，不过这种方法有另一个命名，叫做鸡尾酒排序\n\nvoid cocktail_sort(sort_element_t * beg, sort_element_t * end) { while (beg \u0026lt; end) { int sorted = 1; for (sort_element_t * i = beg + 1; i \u0026lt; end; ++i) { if (*i \u0026lt; i[-1]) { sort_element_swap(i - 1, i); sorted = 0; } } if (sorted) break; --end; sorted = 1; for (sort_element_t * i = end - 1; i \u0026gt; beg; --i) { if (*i \u0026lt; i[-1]) { sort_element_swap(i - 1, i); sorted = 0; } } if (sorted) break; ++beg; } }  那改成双向就真的有提升了吗？我们看实测，排序45000个int，用10组不同分布的数据，表格中的数字单位是毫秒，即排序用时\n   int 1 2 3 4 5 6 7 8 9 10 Avg     cocktail 0 0 1313 1502 1614 1674 671 1 2 836 761   bubble 0 0 1245 2286 2329 2332 871 1 4 1459 1052    其中第4组是乱序无重复数值的数据，最有代表性的一列。从中可以看到，cocktail比起bubble能节省30%的时间\n让我们再脑洞大开，除了可以双向，还有一种对CPU执行有利的优化方式\n优化3，奇偶排序 这种排序的排序方式见下表，假设有8个数，奇数轮比较(1,2), (3,4), (5,6), (7,8)，偶数轮比较(2,3), (4,5), (6,7)，如此循环，直到没有交换为止\n   轮次 1 2 3 4 5 6 7 8     0 8 7 6 5 4 3 2 1   1 7 8 5 6 3 4 1 2   2 7 5 8 3 6 1 4 2   3 5 7 3 8 1 6 2 4   4 5 3 7 1 8 2 6 4    具体实现代码如下\nvoid odd_even_sort(sort_element_t * beg, sort_element_t * end) { int sorted = 0, last_sorted = 0; while (sorted == 0) { last_sorted = sorted; sorted = 1; for (sort_element_t * i = beg + 1; i \u0026lt; end; i += 2) { if (*i \u0026lt; i[-1]) { sort_element_swap(i - 1, i); sorted = 0; } } if (last_sorted \u0026amp;\u0026amp; sorted) break; last_sorted = sorted; sorted = 1; for (sort_element_t * i = beg + 2; i \u0026lt; end; i += 2) { if (*i \u0026lt; i[-1]) { sort_element_swap(i - 1, i); sorted = 0; } } if (last_sorted \u0026amp;\u0026amp; sorted) break; } }  让我们再脑洞大开，除了比较方向，好像我们有一个条件没有考虑上，就是冒泡排序总是相邻元素的比较，那么如果不相邻地比较呢？\n优化4，梳排序 通过一开始设置较大的步长，让元素能较快移动，然后逐步减少步长，直到1变成普通的冒泡排序为止。这个方法的优点，就是快，相对前面的方法来说飞快。当然，最后一步你也可以选择不调用冒泡排序，而改调用cocktail_sort或odd_even_sort都可以，差别不明显。\n\nvoid comb_sort(sort_element_t * beg, sort_element_t * end) { const double shrink_factor = 0.8; ptrdiff_t gap = end - beg; while (gap \u0026gt; 1) { if (gap \u0026gt; 1) { gap = (ptrdiff_t)(gap * shrink_factor); if (gap == 10 || gap == 9) gap = 11; } for (sort_element_t * i = beg + gap; i \u0026lt; end; ++i) { if (*i \u0026lt; i[-gap]) sort_element_swap(i, i - gap); } } bubble_sort(beg, end); }  完整测试 在完整测试里你会发现一些和你想象中完全不一样的情况，可不要以为你的“优化”一定就是优化\nVS2005下的运行时间比较（按Avg平均值排序）    int 1 2 3 4 5 6 7 8 9 10 Avg     combsort 0 0 1 3 3 1 1 0 1 2 1   odd_even 0 0 574 1315 1315 1222 557 0 3 878 586   cocktail 0 0 1313 1502 1614 1674 671 1 2 836 761   select2 0 1114 834 1113 1124 1124 1119 1124 1124 1141 981   bubble 0 0 1245 2286 2329 2332 871 1 4 1459 1052   select 2213 2238 2227 2229 2256 2242 2238 2241 2245 2260 2238    如果你只测试随机数据，那么排序应该是\ncombsort \u0026lt;\u0026lt; select2 \u0026lt; odd_even \u0026lt; cocktail \u0026lt; select \u0026lt; bubble\n在mingw64(gcc8)下使用-O3编译（最大优化）的运行时间比较    int 1 2 3 4 5 6 7 8 9 10 Avg     combsort 0 1 1 2 3 2 2 1 2 3 1   select 497 497 434 501 501 500 501 503 500 502 493   odd_even 0 0 564 1311 1264 1217 562 0 2 882 580   cocktail 0 0 1242 1515 1610 1677 669 0 3 837 755   select2 1 1114 837 1114 1114 1112 1114 1113 1112 1114 974   bubble 0 0 1247 2312 2332 2338 951 0 3 1455 1063    你可以发现，找最小值过程在mingw64下被特别照顾了一下，结果它比其它的明显要快，你可以从中得知，如果你想在mingw下写出运行得快的双向选择排序，如果你的想法是再写一个find_max函数，那对不起，这样是没有优化效果的。但这不是全部，还有让你更大跌眼镜的情况。\n在mingw64(gcc8)下使用-O1编译（基本优化）的运行时间比较    int 1 2 3 4 5 6 7 8 9 10 Avg     combsort 0 0 0 3 3 1 1 0 2 2 1   select2 0 263 375 256 260 258 255 254 531 255 270   odd_even 0 0 597 1287 1256 1204 1368 1 3 780 649   cocktail 0 0 1244 1504 1594 1656 1081 1 3 815 789   bubble 0 0 1241 2091 2117 2115 685 0 3 1247 949   select 2233 2233 2232 2231 2232 2224 2229 2229 2225 2232 2230    现在双向选择不但最快，而且还比-O3下的快得多。老实说，会造成这种奇怪的结果，-O1比-O3还快的原因还真不要问我，找开发gcc/mingw的开发者。\n最后还是忠告一句，千万不要在一个编译器某个编译参数上看到有优化效果，就以为是事实，优化的坑远比你想象的要来得深，并不是你以为优化了它就一定变快了，编译器和编译参数以及运行环境才是你的老大。\n","date":1570511736,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570511736,"objectID":"d460bcc6e133fb754a6ffc672bf1f9c5","permalink":"/post/20191008-sorting-1/","publishdate":"2019-10-08T13:15:36+08:00","relpermalink":"/post/20191008-sorting-1/","section":"post","summary":"本篇针对两种最基本的排序（冒泡、选择）来讲优化思路。越是简单的东西反而可能存在你越想不到的优化点。但是在开始之前，先给不了解的人讲一个设计原则的问题，我们在设计排序接口的时候，最为常见的有\nvoid sort(type arr[], int len)\n也许你也见过\nvoid sort(iter beg, iter end)\n这时候问题就来了，很多人会错误地把end认为是最后一个元素，其实不然，这两接口可以相互转换，例如我们可以写 sort(arr, arr + len) ，这样写很自然对不对，但如果你认为end是最后一个元素，那你就不得不改成 sort(arr, arr + len - 1) 。事实上，这类的接口我们需要一个统一的原则，就是左闭右开区间原则，即beg就是首个元素，而end是最后一个元素+1，即end是作为结束标志，不应该把end算在范围内。接下来下面所有的接口写法，都是以\nvoid sort(iter beg, iter end)\n这种方式写的，至于这样写有什么好处，接下来我们就看示例。\n选择排序 ","tags":["算法","排序","冒泡排序","选择排序","鸡尾酒排序","奇偶排序","梳排序","c","c++"],"title":"选择和冒泡排序优化思路","type":"post"},{"authors":null,"categories":["研究"],"content":"我们现在使用的排序，很大比例在使用quick sort，因为它是平均速度最快的排序，但与此同时它可能也是坑最深的排序，现在我们就来讨论讨论它，因为内容较多，我计划写多篇，本篇是第一篇。\n快排的思路 我们先来介绍一下快排的思路。快排的思路其实很简单，在数组中选一个元素，我们就称呼这个元素为pivot，通过与这个元素的比较，把数组划分成不比pivot大的在一边，不比pivot小的在另一边，于是就分成了两个更小的数据，对它们分别再排序就行了。但是，这个描述特别的含糊，首先是怎么选中间元素，这里面有很多不同的做法。然后就是划分了，这个划分方法非常的多，水也特别深，这里主要介绍最为常见的划分方法。\n划分结果分类 首先，就是划分的结果，划分的结果有什么好讲的呢？其实算法的描述只说了划分成不比pivot大的在一边，不比pivot小的在另一边，并没有说等于的数怎么办。事实上，关键就在等于的数怎么处理，你既可以划在其中一边，也可以两边都有，也可以划成3分，中间那块就是等于pivot的，左边是小于等于，右边是大于等于，三种划分结果都是可以的。但是，不能容许的一种情况是划分后只有一块，例如你选的pivot正好是最小的数，于是划分后，整个数组就一块，全是大于等于pivot的，这样很可能导致无限递归，这次划分也白干了。\n所以很多人单凭算法思路来实现的时候，往往陷入栈溢出异常，其实就是划分结果上出了问题，并没有保证每次划分后，至少划分成两块。\n划分手段分类 划分手段的典型方法至少有5种，本篇介绍其中的4种\n1. Lomuto partition scheme 首先我们来看以下代码：\nsort_element_t * partition( sort_element_t * beg, sort_element_t * end) { sort_element_t pivot = *beg; sort_element_t * p = beg; for (sort_element_t * i = beg + 1; i \u0026lt; end; i++) { if (*i \u0026lt; pivot) { sort_element_swap(++p, i); } } sort_element_swap(p, beg); return p; } void quick_sort_recursive( sort_element_t * beg, sort_element_t * end) { if (end - beg \u0026gt; 1) { sort_element_t * p = partition(beg, end); quick_sort_recursive(beg, p); quick_sort_recursive(p + 1, end); } }  这种划分方法wiki上有描述，叫做 Lomuto partition scheme 它的思路挺好理解，首先p就是划分边界，一开始p = left，遍历数组，发现比pivot小的，就交换到p的位置，并且p++，那么p左边的就全是比p要小的。而在最后面，把pivot交换到p的位置，所以这个方法期望把数组划分成三块，小于pivot的，等于pivot的，大于等于pivot的，而且能保证至少划分出两块（中间那块等于pivot的一定存在，不过只有一个元素）。这个方法的优点是可以通过简单的修改就变成3路划分（小于、等于、大于三块），缺点是它这种划分方法速度最慢，交换次数较多。\n2. 不知名字的方法 这种方法来源不明，如果你知道请告诉我，在我看来有点像 Hoare partition scheme 的变种，来看代码\nsort_element_t* partition( sort_element_t * first, sort_element_t * last) { sort_element_t pivot = *first; while (first \u0026lt; last) { while (first \u0026lt; last \u0026amp;\u0026amp; pivot \u0026lt; *last) last--; *first = *last; while (first \u0026lt; last \u0026amp;\u0026amp; pivot \u0026gt;= *first) first++; *last = *first; } *first = pivot; return first; } void quick_sort_recursive( sort_element_t * beg, sort_element_t * end) { if (end - beg \u0026gt; 1) { sort_element_t* p = partition(beg, end - 1); quick_sort_recursive(beg, p); quick_sort_recursive(p + 1, end); } }  这个方法通过在右边寻找应该放在左边的元素，与pivot交换，然后在左边寻找应该放在右边的元素，再次与pivot交换，这样pivot通过多数交换换到划分位置上。不过上面代码做了一个简单优化，通过赋值而不是直接交换以减少赋值的次数，这种方法在网上非常常见。\n3. Hoare partition scheme 后来有个叫做 C.A.R. Hoare 的人发明了这种划分方法，见代码\nsort_element_t* partition( sort_element_t * first, sort_element_t * last) { sort_element_t * begin = first; sort_element_t pivot = *first; while (first \u0026lt; last) { while (first \u0026lt; last \u0026amp;\u0026amp; *last \u0026gt;= pivot) --last; while (first \u0026lt; last \u0026amp;\u0026amp; pivot \u0026gt;= *first) ++first; if (first \u0026lt; last) sort_element_swap(first, last); } sort_element_swap(first, begin); return first; } void quick_sort_recursive( sort_element_t * beg, sort_element_t * end) { if (end - beg \u0026gt; 1) { sort_element_t* p = partition(beg, end - 1); quick_sort_recursive(beg, p); quick_sort_recursive(p + 1, end); } }  注意的是，这个写法和 wiki 上的略有差别。这个方法与前一个的不同点是，通过在左边寻找应该放在右边的元素，而在右边寻找应该放在左边的元素，然后交换。这个方法是以上三种里面速度最快的，但与此同时是坑最多的。例如，原描述是左边找小于，右边找大于的交换，而上面代码的实现是左边找小于等于，右边找大于等于；原描述是先找左边再找右边，上面实现是先找右边再找左边。也就是说，取不取等于号有4种组合，再乘以先左或先右两种，共8种组合，这8种有一些要求pivot取最左边，有一些要求pivot取最右边，有些左右都行，有些pivot任意位置都行。所以当你写这种划分方法的时候，看起来没什么区别的代码，偏偏出现栈溢出各种问题，其实就隐藏在这些细节上。如果你想练习调试的本领，就把这8种组合的划分全写出来，你肯定收获不少。至于哪种组合最佳，我不知道，但我知道最差的组合，就是两边都取等于号的那两种。\n这个写法还有一个四路划分的变种，即先划分成以下这样\n  =   =   划分好后再把两端的相等元素交换到中间得到\n   =    这里不具体展开，有兴趣可以自行实现\n4. VS partition scheme 之所以这么叫是因为我目前只看到在Visual Studio系列STL的std::sort是这么写的，这个写成代码有点长，但思路和上面说的四路划分有点类似，这里简单讲讲它的思路。首先pivot选择在中间，形成这样的状态\n   ? = ?    找到等于的元素就交换到等于那块的旁边扩大它就行了，核心思想就这样，还有很多其它的细节，这里不展开。这种方法网上几乎没有人这么写，因为写起来确实挺麻烦的。\n总结 本篇先介绍到这里，大家写快排练习建议使用 Hoare partition scheme ，如果你觉得你的能力更好，那你可以写 VS partition scheme 自己琢磨一下细节问题，相信你是能写出来的。那么下一篇会介绍优化的部分。\n","date":1570429102,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570429102,"objectID":"e4a727e5a6348a68314ff2501d974f7a","permalink":"/post/20191007-qsort-talk-1/","publishdate":"2019-10-07T14:18:22+08:00","relpermalink":"/post/20191007-qsort-talk-1/","section":"post","summary":"我们现在使用的排序，很大比例在使用quick sort，因为它是平均速度最快的排序，但与此同时它可能也是坑最深的排序，现在我们就来讨论讨论它，因为内容较多，我计划写多篇，本篇是第一篇。\n快排的思路 我们先来介绍一下快排的思路。快排的思路其实很简单，在数组中选一个元素，我们就称呼这个元素为pivot，通过与这个元素的比较，把数组划分成不比pivot大的在一边，不比pivot小的在另一边，于是就分成了两个更小的数据，对它们分别再排序就行了。但是，这个描述特别的含糊，首先是怎么选中间元素，这里面有很多不同的做法。然后就是划分了，这个划分方法非常的多，水也特别深，这里主要介绍最为常见的划分方法。\n","tags":["算法","排序","快速排序","c","c++","partition"],"title":"Quick sort(快速排序)杂谈 1","type":"post"},{"authors":null,"categories":["杂谈"],"content":"这个问题最早的时候是今年8月，我在测试排序算法的速度，发现mingw上总有点不一样，而linux下的gcc是正常的，也在群里问过人，没人明白到底怎么回事，先描述一下当时遇到的情况。\n一开始我使用std::random_shuffle打乱数组并用std::sort排序，在VS上并没有发现什么问题，gcc也正常。但在mingw上，这样打乱的数组排序所花的时间，比起其它打乱方式的，例如直接赋值一个随机数的方式，要明显慢了近1倍，这个诡异的问题一直没想通是为啥。当时觉得可能是std::sort对这种方式打乱的数据排序有点问题导致变慢。\n后来，为了和std函数脱钩，我自己重新写了随机数函数和random_shuffle函数，结果发现我的random_shuffle函数打乱的结果，std::sort的时间是完全正常的，非得std::random_shuffle才会出现两倍的情况，一时间我还以为是我写的有问题，还更换了不同随机函数，怎么也发现不了原因，终于把怀疑转向std::random_shuffle，我就对这个函数的执行结果输出到文件，这一输出立即把我搞懵了，输出的结果分布特别有规律，初值我用的是arr[i] = i，打乱后结果前32768个数都是数组里最大的数值，一时没明白怎么回事，难道它的实现很不寻常吗？我就去翻了一下源代码，在cppreference下源代码长下面这样：\ntemplate\u0026lt; class RandomIt \u0026gt; void random_shuffle( RandomIt first, RandomIt last ) { typename std::iterator_traits\u0026lt;RandomIt\u0026gt;::difference_type i, n; n = last - first; for (i = n-1; i \u0026gt; 0; --i) { using std::swap; swap(first[i], first[std::rand() % (i+1)]); } }  这个代码我看着就不对，这个是生成不了我的执行结果的，于是又找到了下面这个：\ntemplate \u0026lt;class RandomAccessIterator\u0026gt; inline void random_shuffle(RandomAccessIterator first, RandomAccessIterator last) { __random_shuffle(first, last, distance_type(first)); } template \u0026lt;class RandomAccessIterator, class RandomNumberGenerator\u0026gt; void random_shuffle(RandomAccessIterator first, RandomAccessIterator last, RandomNumberGenerator\u0026amp; rand) { if (first == last) return; for (RandomAccessIterator i = first + 1; i != last; ++i) iter_swap(i, first + rand((i - first) + 1)); } template \u0026lt;class RandomAccessIterator, class Distance\u0026gt; void __random_shuffle(RandomAccessIterator first, RandomAccessIterator last, Distance*) { if (first == last) return; for (RandomAccessIterator i = first + 1; i != last; ++i) #ifdef __STL_NO_DRAND48 iter_swap(i, first + Distance(rand() % ((i - first) + 1))); #else iter_swap(i, first + Distance(lrand48() % ((i - first) + 1))); #endif }  看了这个代码，我瞬间明白这到底是怎么回事了，你能从中发现些什么吗？\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n我发现的是，前面的代码用的是rand，而之前我发现的，是数组里前32768个数都特别大，我的直觉是这个rand函数最大值就是32767从而导致以上问题，结果一查，还真的只有mingw的rand函数的最大值这么小，也就是说如果你希望代码跨平台，使用std::random_shuffle要慎重，当然最好是减少依赖。\n","date":1570338248,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570338248,"objectID":"17aa6d9424945fe4bb7e23edb81727e0","permalink":"/post/20191006-mingw-bug/","publishdate":"2019-10-06T13:04:08+08:00","relpermalink":"/post/20191006-mingw-bug/","section":"post","summary":"这个问题最早的时候是今年8月，我在测试排序算法的速度，发现mingw上总有点不一样，而linux下的gcc是正常的，也在群里问过人，没人明白到底怎么回事，先描述一下当时遇到的情况。\n一开始我使用std::random_shuffle打乱数组并用std::sort排序，在VS上并没有发现什么问题，gcc也正常。但在mingw上，这样打乱的数组排序所花的时间，比起其它打乱方式的，例如直接赋值一个随机数的方式，要明显慢了近1倍，这个诡异的问题一直没想通是为啥。当时觉得可能是std::sort对这种方式打乱的数据排序有点问题导致变慢。\n后来，为了和std函数脱钩，我自己重新写了随机数函数和random_shuffle函数，结果发现我的random_shuffle函数打乱的结果，std::sort的时间是完全正常的，非得std::random_shuffle才会出现两倍的情况，一时间我还以为是我写的有问题，还更换了不同随机函数，怎么也发现不了原因，终于把怀疑转向std::random_shuffle，我就对这个函数的执行结果输出到文件，这一输出立即把我搞懵了，输出的结果分布特别有规律，初值我用的是arr[i] = i，打乱后结果前32768个数都是数组里最大的数值，一时没明白怎么回事，难道它的实现很不寻常吗？我就去翻了一下源代码，在cppreference下源代码长下面这样：\n","tags":["stl","c++","mingw","random_shuffle"],"title":"Mingw 的 Bug","type":"post"},{"authors":null,"categories":["杂谈"],"content":"第一次使用这个hugo就遇到一堆坑，主题并不是随便用，会有SHA-256校验，而在windows平台下用git，clone下来会把\\n自动换成\\r\\n从而导致主题应用失败，服了。\n另一个坑就是hugo的表格，你不能像以下这么写\na|b|c -|-|- 1|2|3  这样hugo的引擎是不认为这是表格，正确的做法是改成下面这样\na | b | c ---|---|--- 1 | 2 | 3  显示结果就是这样\n   a b c     1 2 3    区别是什么呢？在表格的第二行是---|---|---，这一行是用来描述对齐方式的，不过hugo的引擎要求每列至少3个字符，所以刚好3个字符时只能是\n--- :-- --: :-:  中四选一，任何一个只剩下两个字符就不算是表格。\n本博客计划是发布我的研究成果，当然主要是算法方面，而且主要是网上不会轻易搜索到的东西。\n更多的东西可以关注我的 Github 账号。\n #define _CRT_SECURE_NO_WARNINGS #include \u0026lt;stdio.h\u0026gt; int g_eof; int get_lv(char c) { return !(c == '+' || c == '-'); } double get_val(double v[], char op) { if (op == '+') return v[0] + v[1]; if (op == '-') return v[0] - v[1]; if (op == '*') return v[0] * v[1]; if (op == '/') return v[0] / v[1]; return v[0]; } double calc(char* op, int level, double val, char o, int i) { char c[2] = { o }; double v[2] = { val }; if ((g_eof = scanf(\u0026quot;%lf\u0026quot;, \u0026amp;v[i])) != EOF) scanf(\u0026quot;%c\u0026quot;, \u0026amp;c[i]); if (c[i] == '(') { v[i] = calc(\u0026amp;c[i], 0, 0, 0, 0); scanf(\u0026quot;%c\u0026quot;, \u0026amp;c[i]); } if (i \u0026gt; 0) { if (!(c[i] == '\\n' || c[i] == ')' || get_lv(c[0]) \u0026gt;= get_lv(c[1]))) v[i] = calc(\u0026amp;c[1], get_lv(c[1]), v[1], c[1], get_lv(c[1]) \u0026gt; 0); v[0] = get_val(v, c[0]); c[0] = c[1]; } if (c[0] == '\\n' || c[0] == ')' || get_lv(c[0]) \u0026lt; level) { *op = c[0]; return v[0]; } return calc(op, level, v[0], c[0], 1); } int main(void) { char op; while (g_eof != EOF) printf(\u0026quot;= %.15g\\n\u0026quot;, calc(\u0026amp;op, 0, 0, '\\n', 0)); return 0; } ","date":1570288330,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570288330,"objectID":"458f89e40dd9bc6cb64d4e2c297e6a93","permalink":"/post/20191005-first-post/","publishdate":"2019-10-05T23:12:10+08:00","relpermalink":"/post/20191005-first-post/","section":"post","summary":"第一次使用这个hugo就遇到一堆坑，主题并不是随便用，会有SHA-256校验，而在windows平台下用git，clone下来会把\\n自动换成\\r\\n从而导致主题应用失败，服了。\n另一个坑就是hugo的表格，你不能像以下这么写\na|b|c -|-|- 1|2|3  这样hugo的引擎是不认为这是表格，正确的做法是改成下面这样\n","tags":["算法","hugo","表格"],"title":"博客第一文，附hugo表格的坑","type":"post"}]